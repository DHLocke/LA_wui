---
title: "02_Woosley_combine_data"
author: "Dexter H. Locke, PhD"
date: "`r format(Sys.time())`"
output: html_document
editor_options: 
  chunk_output_type: console
---

year 2008 is important for policy reasons.
  Consider a before and after variable. 



TODO: 
Variable selection  
1. Per buffered landscape characteristic, which one has the greatest association with the outcome (binary)
  *Deviance* explained will be called the most important. 
    Would be a great supplement for a paper on its own.





suggest delete from here
Done
Get descriptive statistics
  cross-tabulations with the binary outcome - which ones? (boxplots?)
  sort by variable (like group all soils together.)
  
look at importance values for an all-variables random forest
  (do not use variable selection)
=

# https://www.titleadvantage.com/mdocs/LA%20County%20Use%20Codes%20nm.pdf
# See parcel_UseType, parcel_UseDescription, parcel_Roll_ImpValue, and
# parcel_Roll_HomeOwnersExemp 
to here


Next steps
  - Census data
    * multi-level logistic regression
  - analyses of just those affected/ damaged/ destroyed/ major/ minor


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



## 0 set up: load libraries, custom functions, set defaults
```{r}
# load libraries
# packages we'll be using
packs <- c('tidyverse'        # a must have!
           , 'tidylog'        # makes things very verbose for 2x checking 
           , 'magrittr'       # all of the pipes
           , 'janitor'        # cleans things up
           , 'sf'             # simple features
           , 'mapview'        # quick webmaps for zoom/pan viz
           #'tidycensus',     # access to Census data in a tidy way 
           #'party',          # random forests
           , 'tictoc'         # times things
           , 'beepr'          # makes noises
           , 'psych'          # describe is very useful for descriptive statistics
           , 'sjPlot')        # useful plotting and regression support

# check for all of the libraries
if (length(setdiff(packs, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packs, rownames(installed.packages())))  
}

lapply(packs, library, character.only = TRUE)


# changing from tidyr v0.8.3 -> v1.0.0 broke things for nest and unnest!
# https://tidyr.tidyverse.org/articles/in-packages.html#tidyr-v0-8-3---v1-0-0
library(tidyr)
#nest <- nest_legacy                     # Why Hadley, WHY!
#unnest <- unnest_legacy


# set custom function for getting spatial data
see_sf <- function(){
# what's in memory that are sf - spatial features?
keep(eapply(.GlobalEnv, class),      # gets the objects in the global environment
     ~ any(str_detect(., "sf"))) %>% # selects elements with sf in them
names(.) %>% as.character(.)       # my simple features
}

see_sf() -> sf_in_memory

## what are the spatial references of those SF classes?
mget(sf_in_memory) %>%
purrr::map(~st_crs(.x)$epsg) %>% unlist() #%>% View()

# NOT IN
`%nin%` <- Negate(`%in%`) # custom function

# where are we?
list.files()
list.files('data')

# parameter to keep in general, for later..
pxl_to_ft_conversion <- 0.75
# pxl_to_ft_conversion <- 0.2286004572

set.seed(19870630)

## Make a 'figures' subdirectory if one doesn't exist
# ifelse(!dir.exists(file.path('figures')), dir.create(file.path('figures')), FALSE)
```


## 1 bring in new GIS data from Miranda, this will be the base from now on (August, 2020)
### a. GIS data
```{r eval=FALSE, include=FALSE}
# GIS DATA from MIRANDA
st_layers(paste0(getwd(), '/data/Outgoing_BuildingSumms_DHL20200423.gdb'))

# this will be the main building layer!
# left-most columns are building-specific summaries
# then there are building attributes for select buildings (from Alex' DINS data)
# already done by M Mockrin - Thank you!
# next attributes will be joined from  Jarlath's building info
# after we can add parcel-level variables
# eventually we'll get block group-level data into the buildings, too.
build <- read_sf(dsn = paste0(getwd(), '/data/Outgoing_BuildingSumms_DHL20200423.gdb'),
                      layer = 'Buildings_ParcelID_DINS',
                      quiet = FALSE) %>% 
  tidylog::select(ID_Build : Mean_distall_road,
                  structures_DAMAGE = Buildings_ParcelID_DINS_intersects_DAMAGE, # renaming
                  starts_with('NEAR_'),
                  Shape_Length, Shape_Area) %>% 
  mutate(damage_cat =
           as.factor(
           case_when(is.na(structures_DAMAGE) ~ 'Survived',
                     structures_DAMAGE == 'Affected (1-9%)' ~ 'Survived',
                     structures_DAMAGE == 'Minor (10-25%)' ~ 'Survived',
                     structures_DAMAGE == 'Major (26-50%)' ~ 'Destroyed',
                     structures_DAMAGE == 'Destroyed (>50%)' ~ 'Destroyed')),
         damage_binary = ifelse(damage_cat == 'Destroyed', 1, 0),
         damage_severity = 
           case_when(
               is.na(structures_DAMAGE) ~ 1,
                     structures_DAMAGE == 'Affected (1-9%)' ~ 2,
                     structures_DAMAGE == 'Minor (10-25%)' ~ 3,
                     structures_DAMAGE == 'Major (26-50%)' ~ 4,
                     structures_DAMAGE == 'Destroyed (>50%)' ~ 5),
         area = as.double(st_area(.))) %>% 
  distinct(ID_Build, Shape, .keep_all = TRUE) %>% #9/20/21 - how many is this dropping, this is only when ID_Build and Shape are the same?
  rename_at(vars(-starts_with('ID'), -starts_with('damage_')), ~paste0('build_',.)) %>% glimpse()

# define & refine the dependent variable versions: numeric (0/1), categorical (survived/destroyed),
# and severity?
build %>% st_drop_geometry() %>% tabyl(build_structures_DAMAGE) #%>% 
#  write.csv(., paste0(getwd(), '/output_data/damage_cats.csv'), row.names = FALSE)

build %>% st_drop_geometry() %>% tabyl(build_structures_DAMAGE, damage_binary) #%>% 
  #write.csv(., paste0(getwd(), '/output_data/damage_cats_binary.csv'), row.names = FALSE)

build %>% st_drop_geometry() %>% tabyl(build_structures_DAMAGE, damage_binary) #%>%
  # adorn_percentages('col') %>% adorn_pct_formatting() %>% 
  # write.csv(., paste0(getwd(), '/output_data/damage_cats_binary_pct_form.csv'),
  #           row.names = FALSE)

build %>% st_drop_geometry() %>% tabyl(damage_binary)
build %>% st_drop_geometry() %>% tabyl(damage_severity)

build %>% st_drop_geometry() %>% tabyl(damage_severity, damage_binary) #%>% 
  #write.csv(., paste0(getwd(), '/output_data/damage_binary_severity.csv'), row.names = FALSE)

glimpse(build)

```

### b. WUI data
```{r}
# looking to see if buildings are in WUI, for JEM reviews July 6 2023

#bring in WUI data for LA County
wui<- read_sf(dsn = paste0(getwd(), '/data/LA_County_WUI_block_1990_2020_change_v4.gdb'),
                      layer = 'LA_County_WUI_block_1990_2020_change_v4',
                      quiet = FALSE) 

wui <-st_transform(wui, crs=2229) #have to put in same CRS as build (below)
 
# IDs for final data set (n= 10901)
build_IDs <- read_csv(paste0(getwd(), '/output_data/building_2022-06-10.csv')) %>%
  tidylog::select(
    ID_Build)

#geospatial data for DINS data (n=11,140), but filter to only those with build_IDs for final data set (n=10901)
build <- read_sf(dsn = paste0(getwd(), '/data/Outgoing_BuildingSumms_DHL20200423.gdb'),
                      layer = 'Buildings_ParcelID_DINS',
                      quiet = FALSE) %>% 
  tidylog::select(ID_Build : Mean_distall_road,
                  structures_DAMAGE = Buildings_ParcelID_DINS_intersects_DAMAGE, # renaming
                  starts_with('NEAR_'),
                  Shape_Length, Shape_Area) %>% 
  mutate(damage_cat =
           as.factor(
           case_when(is.na(structures_DAMAGE) ~ 'Survived',
                     structures_DAMAGE == 'Affected (1-9%)' ~ 'Survived',
                     structures_DAMAGE == 'Minor (10-25%)' ~ 'Survived',
                     structures_DAMAGE == 'Major (26-50%)' ~ 'Destroyed',
                     structures_DAMAGE == 'Destroyed (>50%)' ~ 'Destroyed')),
         damage_binary = ifelse(damage_cat == 'Destroyed', 1, 0),
         damage_severity = 
           case_when(
               is.na(structures_DAMAGE) ~ 1,
                     structures_DAMAGE == 'Affected (1-9%)' ~ 2,
                     structures_DAMAGE == 'Minor (10-25%)' ~ 3,
                     structures_DAMAGE == 'Major (26-50%)' ~ 4,
                     structures_DAMAGE == 'Destroyed (>50%)' ~ 5),
         area = as.double(st_area(.))) %>% 
  distinct(ID_Build, Shape, .keep_all = TRUE) %>% #9/20/21 - how many is this dropping, this is only when ID_Build and Shape are the same?
  rename_at(vars(-starts_with('ID'), -starts_with('damage_')), ~paste0('build_',.)) %>% 
  right_join(build_IDs, by = c('ID_Build' = 'ID_Build'))

head(build)

wui_table <- build |>
 st_centroid () |> # makes points
 st_join(wui) |> # does the intersection/spatial join
 st_drop_geometry() |> # pulls the attribute table out
  janitor::tabyl(WUICLASS2020, damage_binary) # cross tabulates, where destroyed is the destroyed or not and wui_cat is the wui category.

wui_table %>% 
janitor::adorn_totals() #here here here, figure out the exact way you want to present this

 
```





## 2 bring in building attributes --from Jarlath-- (start simple at first) 
### a building distance to building
```{r eval=FALSE, include=FALSE}
# BUILDING DISTANCE TO BUILDING
(data_path <- 'data/WoosleyFire_eCogOuput_06Dec2019/Building_dist_Building') # building dist build

# update? https://twitter.com/kc_analytics/status/1345434428059881480/photo/2
files <- dir(data_path, recursive = TRUE, pattern = "*.csv"); files # get file names


build_dist_to_build <-
  tibble(filename = files) %>% # create a data frame, holding the file names
  mutate(file_contents = map(filename,          # read files into
                             ~ read.csv(file.path(data_path, .),
                                              #fileEncoding='latin1',
                                        colClasses = c('character',
                                                       'character',
                                                       'factor',
                                                       'factor',
                                                       'character',
                                                       'character'),
                                        sep = ';'))) %>%  # a new data column
 # unnest() %>%
  unnest_legacy() %>% 
  clean_names() %>%
  mutate(dist_to_build_ft = pxl_to_ft_conversion*as.numeric(distance_to_buildings_pxl),
         dist_to_build_ft = ifelse(is.na(dist_to_build_ft), 0, dist_to_build_ft),
         ID_Build = as.numeric(id_build_buildings)) %>%
  tidylog::select(ID_Build,
         dist_to_build_ft) %>%
  filter(!is.na(ID_Build)) %>% 
  distinct() %>% 
  group_by(ID_Build) %>% 
  arrange(dist_to_build_ft) %>%    # sorting by shortest distance to building
  slice(1) %>%                  # grabs the first record
  ungroup()

# No NA's woohooo
build_dist_to_build; summary(build_dist_to_build)

length(unique(build_dist_to_build$ID_Build)); dim(build_dist_to_build)
build_dist_to_build %>% 
  group_by(ID_Build) %>%
  tally() %>%
  filter(n > 1) %>% 
  arrange(desc(n)) -> dup_build_ids # success!
  # View()

sum(dup_build_ids$n) # no duplicates, nice


# build_dist_to_build %>% 
#   filter(ID_Build %in% dup_build_ids$ID_Build) %>% View()

# LEFT
build %<>% 
  left_join(build_dist_to_build, by = c('ID_Build' = 'ID_Build')) # 47 bad matches.. 
```



### b building distance veg
```{r eval=FALSE, include=FALSE}

min_dist_shrub <- read_csv('output_data/min_dist_shrub_2021-04-23.csv')
min_dist_tree  <- read_csv('output_data/min_dist_tree_2021-04-26.csv') %>% 
    mutate(min_dist_tree = ifelse(min_dist_tree == Inf, 0.75, min_dist_tree))


build %<>% 
  left_join(., min_dist_tree, by = c('ID_Build' = 'polygon_id')) %>% 
  left_join(., min_dist_shrub, by = c('ID_Build' = 'polygon_id'))

```



### c building tree overhang
```{r eval=FALSE, include=FALSE}
(data_path <- 'data/WoosleyFire_eCogOuput_06Dec2019/Building_TreeOverhang') # building tree overhang

files <- dir(data_path, recursive = TRUE, pattern = "*.csv"); files # get file names

build_tree_overhang <-
  tibble(filename = files) %>% # create a data frame, holding the file names
  mutate(file_contents = map(filename,  # read files into
                             ~ read.csv(file.path(data_path, .),
                                        colClasses = c('character',
                                                       'character',
                                                       'character',
                                                       'character',
                                                       'character',
                                                       'numeric',
                                                       'character'),
                                        sep = ';'))) %>%  # a new data column
  # unnest() %>%
  unnest_legacy() %>% 
  clean_names() %>% 
  mutate(has_tree_overhang = ifelse(mean_n_dsm_tree_canopy_sub_objects == 'undefined',
                                    0, 1),
         overhang_ht = as.numeric(ifelse(mean_n_dsm_tree_canopy_sub_objects != 'undefined',
                                         mean_n_dsm_tree_canopy_sub_objects, NA)),
         overhang_ht = ifelse(is.na(overhang_ht), 0, overhang_ht),
         perc_overhang = rel_area_of_sub_objects_tree_canopy_1) %>% 
  tidylog::select(ID_Build = id_build_buildings,
         has_tree_overhang,
         overhang_ht,
         perc_overhang) %>% 
  filter(ID_Build != 'undefined') %>% 
  mutate(ID_Build = as.numeric(ID_Build)) %>% # could move this up, save some code.. like the chunck above.
  group_by(ID_Build) %>% 
  arrange(desc(perc_overhang)) %>%    # sorting to get the most overhang. See ID_Build == 6
  slice(1) %>%                        # grabs the first record
  ungroup()

# unnecesary if last chunk ends with "distinct"
build_tree_overhang %>% 
  group_by(ID_Build) %>% 
  tally() %>% 
  filter(n > 1) %>% 
  arrange(desc(n)) -> dup_build_tree_overhang # no dups because the largest % overhang chosen

# build_tree_overhang %>% 
#   filter(ID_Build %in% dup_build_tree_overhang$ID_Build) %>% View()

# semi-join because of duplicates here
# in building distance to building its ok to take the shortest, as was done above
build %<>% 
  left_join(build_tree_overhang, by = c('ID_Build' = 'ID_Build')) %>% 
  rename_at(vars(dist_to_build_ft : perc_overhang), ~paste0('build_', .))

```


### d building land cover buffer
```{r eval=FALSE, include=FALSE}
(data_path <- 'data/WoosleyFire_eCogOuput_06Dec2019/Building_LandCoverBuff') # building dist build

files <- dir(data_path, recursive = TRUE, pattern = "*.csv"); files # get file names

build_tree_landcover_buff <-
  tibble(filename = files) %>% # create a data frame, holding the file names
  mutate(file_contents = map(filename,  # read files into
                             ~ read.csv(file.path(data_path, .),
                                        colClasses = c('character'),
                                        sep = ';'))) %>%  # a new data column
  unnest_legacy() %>% 
  # unnest() %>%
  clean_names() %>% 
  select(ID_Build = id_build_building_centroids, 
         ID_Parcel = id_parcel_parcels,
         treecan10 = rel_area_of_tree_canopy_13, #tree
         treecan100 = rel_area_of_tree_canopy_133,
         treecan200 = rel_area_of_tree_canopy_267,
         treecan300 = rel_area_of_tree_canopy_400,
         grass10 = rel_area_of_grass_13,       #grass
         grass_100= rel_area_of_grass_133,
         grass_200= rel_area_of_grass_267,
         grass_300= rel_area_of_grass_400,
         soil_10 = rel_area_of_bare_soil_13,   # soil
         soil_100= rel_area_of_bare_soil_133,
         soil_200= rel_area_of_bare_soil_267,
         soil_300= rel_area_of_bare_soil_400,
         water_10= rel_area_of_water_13,       # water
         water_100=rel_area_of_water_133, 
         water_200=rel_area_of_water_267,
         water_300=rel_area_of_water_400,
         build_10 = rel_area_of_buildings_13,   # building
         build_100= rel_area_of_buildings_133,
         build_200= rel_area_of_buildings_267,
         build_300= rel_area_of_buildings_400,
         road_10 = rel_area_of_roads_13,       # road
         road_100= rel_area_of_roads_133,
         road_200= rel_area_of_roads_267,
         road_300= rel_area_of_roads_400,
         oth_imp_10 = rel_area_of_other_impervious_13, #other impervious
         oth_imp_100= rel_area_of_other_impervious_133,
         oth_imp_200= rel_area_of_other_impervious_267,
         oth_imp_300= rel_area_of_other_impervious_400,
         shrub_10 = rel_area_of_shrub_13,       # shrub
         shrub_100= rel_area_of_shrub_133,
         shrub_200= rel_area_of_shrub_267,
         shrub_300= rel_area_of_shrub_400) %>% 
   # filter(ID_Build != 'undefined') %>% 
  mutate_if(is.character, as.numeric) %>% 
  mutate_at(vars(-ID_Build, -ID_Parcel), list(~. * 100)) %>% # filter(ID_Build != 'undefined')
  select(-ID_Parcel)

build %<>% 
  left_join(build_tree_landcover_buff,
            by = c('ID_Build' = 'ID_Build')) %>% 
  rename_at(vars(starts_with('Mean_')), ~(str_replace(., 'Mean_', 'build_Mean'))) %>% 
  #rename_at(vars(starts_with('damage_')), ~(str_replace(., 'damage_', 'structures_damage_'))) %>% 
  rename_at(vars(treecan10 : shrub_300), ~paste0('build_', .))


glimpse(build)
```



### d ALT building land cover buffer
```{r eval=FALSE, include=FALSE}
#build %>% distinct(ID_Build)

(data_path <- 'output_data') # donut buffer land cover summaries

files <- dir(data_path, recursive = TRUE, pattern = "^donut"); files # get file names

#(files <- files[-1]) # drop the 10

build_tree_landcover_buff <- tibble(filename = files) %>% # create a data frame, holding the file names
  mutate(file_contents = map(filename,  # read files into
                             ~ read.csv(file.path(data_path, .), sep = ','))) %>%  # a new data column
  # unnest() %>%
  unnest_legacy() %>% 
  clean_names() %>% 
  arrange(polygon_id) %>% # cosmetic
  tidylog::select(filename, polygon_id, starts_with('p_')) %>% 
  mutate(buff_distance = # FIXME kind of sloppy
           as.integer(str_remove(str_remove(filename, '_summaries_2021-03-16.csv'), 'donut_'))) %>%
  pivot_wider(id_cols = polygon_id, names_from = buff_distance, values_from = p_tree:p_shrub) %>% 
  rename_at(vars(starts_with('p_')), ~(str_replace(., 'p_', 'build_p_'))) %>% 
  glimpse


build %<>% 
  left_join(., build_tree_landcover_buff, by = c('ID_Build' = 'polygon_id'))

```




## 3 parcels
```{r}
# <!-- Effective Year 1 -->
# <!--   zero and NA should become NA. (random forest can handel this, regression maybe not.) -->
# <!--   need to investigate -->
# <!--   make a most recent year built var? -->
# <!--   Include Year Built IN ADDITION to Effective Year built -->
#   
#   Roll_ImpValue - might indicate
#   Roll_HomeOwnersExempt - owner occupied?


# Miranda's parcels
parcel_complete_atts     <- read_sf(dsn = paste0(getwd(), '/data/Outgoing_BuildingSumms_DHL20200423.gdb'),
                  layer = 'Parcels_fireperim_LC',
                  quiet = FALSE)

parcel <- read_sf(dsn = paste0(getwd(), '/data/Outgoing_BuildingSumms_DHL20200423.gdb'),
                  layer = 'Parcels_fireperim_LC',
                  quiet = FALSE) %>% # glimpse
  tidylog::select(AIN, UseType, UseDescription, Roll_ImpValue, Roll_HomeOwnersExemp,
         Can_P : Imperv_P, # ) %>%  #,
         starts_with('EffectiveYear'),
         #starts_with('YearBuilt')
         ) %>%         # FIXME ? Do we want area, too?
  mutate_at(vars(starts_with("EffectiveYear")), as.numeric) %>% 
  # mutate_at(vars(starts_with("EffectiveYear")), ~ifelse(. == 0, NA, .)) %>% 
  # mutate_at(vars(starts_with("YearBuilt")),     as.numeric) %>% 
  # mutate_at(vars(starts_with("YearBuilt")),     ~ifelse(. == 0, NA, .)) %>% 
  rename_at(vars(-Shape), ~paste0('parcel_',.)) %>% # glimpse()
  distinct(parcel_AIN, Shape, .keep_all = TRUE) %>%
  st_make_valid() %>%
  mutate(parcel_area = st_area(.)) %>% glimpse() 


parcel %>% 
  tidylog::select(parcel_AIN,
         starts_with("parcel_EffectiveYear")) %>% 
         #starts_with("parcel_YearBuilt")) %>%
  st_drop_geometry() #%>% View()

# parcel %>% filter(parcel_EffectiveYear1 == parcel_YearBuilt1)
# parcel %>% filter(parcel_EffectiveYear1  > parcel_YearBuilt1)
# parcel %>% filter(parcel_EffectiveYear1  < parcel_YearBuilt1)

# create most-recent year build column
(
  parcel %>% 
  tidylog::select(parcel_AIN,
         starts_with("parcel_EffectiveYear") #, starts_with("parcel_YearBuilt")
         ) %>%
  st_drop_geometry() %>% 
  pivot_longer(cols = -parcel_AIN, names_to = 'year') %>% #arrange(desc(value))
  group_by(parcel_AIN) %>% 
  summarise(parcel_recent = value[which.max(value)]) %>% 
  ungroup() -> parcel_recent
)

# join that back
parcel %<>% left_join(., parcel_recent, by = "parcel_AIN")


system.time(                     # about 30 seconds for DHL
build %<>% st_join(parcel,       # spatial join
                   left = FALSE, # if FALSE, only intersection be returned, instead of all
                   largest = TRUE))
```



### a year built headache
```{r eval=FALSE, include=FALSE}

# which ones didn't join completely?
parcel_na_recent <- parcel %>% filter(is.na(parcel_recent)) %>% 
  tidylog::select(parcel_AIN:parcel_Roll_HomeOwnersExemp, parcel_Build_P) # these records don't have year built info


# where are they?
# parcel_na_recent %>% mapview()

# what do they look like
#parcel_na_recent %>% st_drop_geometry() %>% View()

# of those witihout year built info
# how many also have no buildings or tax info that might indicate building?
# make these zero for year built?
parcel_na_recent %>%
  filter(parcel_Roll_ImpValue == 0 &
           parcel_Roll_HomeOwnersExemp == 0 &
           parcel_Build_P == 0) -> parcel_na_recent_zeros  # year built should be zero for these


# Where are they located?
parcel_na_recent %>%
  filter(parcel_AIN %nin% parcel_na_recent_zeros$parcel_AIN) %>% # SUPPOSED TO HAVE YEAR BUILT
  mapview()

# # using all of the attribute data for additional clues
# parcel_complete_atts %>% 
#   filter(AIN %in% parcel_na_recent_zeros$parcel_AIN) %>% 
#   mapview()

# what are the land uses of these that plaussibly ought to be zeros?
parcel_na_recent %>%
  filter(parcel_AIN %nin% parcel_na_recent_zeros$parcel_AIN) %>% # SUPPOSED TO HAVE YEAR BUILT
  tabyl(parcel_UseDescription) %>% 
  as_tibble() %>% 
  arrange(desc(n))


(parcel_na_recent %>%
  filter(parcel_AIN %in% parcel_na_recent_zeros$parcel_AIN) %>% # ok to have not year built, in theory
  tabyl(parcel_UseDescription) %>% 
  as_tibble() %>% 
  arrange(desc(n)) -> parcel_use_type_freqs)

parcel_use_type_freqs %>% 
  ggplot(aes(reorder(parcel_UseDescriptionShape, valid_percent), valid_percent)) +
  geom_bar(stat = 'identity') + 
  coord_flip() + 
  theme_bw()


parcel %>% 
  tidylog::select(starts_with("parcel_Effective"),
         #starts_with("parcel_YearBuilt"),
         parcel_recent) %>% # are these NA parcels undeveloped
  map(., ~sum(is.na(.)))

# missing years do occure in the residential land uses.
parcel %>% st_drop_geometry() %>%  tabyl(parcel_UseType, parcel_recent)

parcel %>% st_drop_geometry() %>%  filter(parcel_Roll_ImpValue == 0)
parcel %>% st_drop_geometry() %>%  tabyl(parcel_Roll_ImpValue, parcel_recent)
parcel %>% filter(parcel_Roll_ImpValue == 0) %>% mapview()


# join buildings to their containing parcel
# takes about 1 minute!
system.time(
build %<>% st_join(parcel, # spatial join
                   left = FALSE, # if FALSE, only intersection be returned, instead of all
                   largest = TRUE) %>% 
  mutate(parcel_recent = ifelse(parcel_AIN %in% parcel_na_recent_zeros, 0, parcel_recent)))  # and attributes of intersection
                      # largest = TRUE is AMAZING, but makes things much slower.
glimpse(build)
```



## 4 DINS data
```{r}
# GIS DATA from MIRANDA this will be the base from now on (August, 2020)
st_layers(paste0(getwd(), '/data/Outgoing_BuildingSumms_DHL20200423.gdb'))

#create DINS
dins <- read_sf(dsn = paste0(getwd(), '/data/Outgoing_BuildingSumms_DHL20200423.gdb'),
                      layer = 'Buildings_ParcelID_DINS',
                      quiet = FALSE)

```


### a explore DINS
```{r}

# Past Syphard et al papers had roof, exterior, window pane, window frame
# More recent ones include wider range of information in DINS

dins %>% 
  st_drop_geometry() %>% names()

dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>% View()

#Variables to include
#reclass unknowns or blanks to NA
#1. EXTERIORSI exterior siding materials 
#2. FENCEATTAC fence materials 
#3. DECKPORCHO deck/porch materials  
#4  DECKPORCHE deck/porch materials 
#5. ROOFCONSTR roof materials
#6. PATIOCOVER patio/cover materials  
#7. PROPANETAN propane tank distance #reclass others are in order,  
#8. WINDOWPANE window panes #reclass  
#9. VEGCLEARAN vegetation clearance #VEGCLEARAN #reclass missing to Unknown, put in order
#10.EAVES      eaves, has data for ~33% only. 
#11.VENTSCREEN vents - 


#1
dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
  tabyl(Buildings_ParcelID_DINS_intersects_EXTERIORSI) #exterior siding, have data for 75% of sample; categories ok

#2
dins %>%
st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>% 
   tabyl(Buildings_ParcelID_DINS_intersects_FENCEATTAC) #fence materials, have data for 70% of sample, although 50% had no fence;  

#3
#DECKPORCHO is a deck that is on grade, data for approx 31% of sample 
dins %>% 
 st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
 tabyl(Buildings_ParcelID_DINS_intersects_DECKPORCHO) #deck and porch --ongrade
 
#4
# DECKPORCHE is a deck that is elevated off the ground, there is data here for less than 10% of the same
dins %>% 
 st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
 tabyl(Buildings_ParcelID_DINS_intersects_DECKPORCHE) #deck and porch --elevated vs ongrade

#5
dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
  tabyl(Buildings_ParcelID_DINS_intersects_ROOFCONSTR) #roof, have data for 65% sample, should drop 'other' bc only 18 observations?

#6
dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>% 
  tabyl(Buildings_ParcelID_DINS_intersects_PATIOCOVER) # materials on covered patio or carport, have data for 65% of sample although
 #44% have no carport or patio cover;  
#7 
dins %>% 
 st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
  tabyl(Buildings_ParcelID_DINS_intersects_PROPANETAN) #propane tank, has data for 56% of sample; #reclass categories so blank is
#unknown and others are in order, N/A = no   tank


#8
dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
  tabyl(Buildings_ParcelID_DINS_intersects_WINDOWPANE) #windowpane, have data for 40% of sample, categories ok
#reclass No windows  

#9
dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
  tabyl(Buildings_ParcelID_DINS_intersects_VEGCLEARAN)

#10
dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
   tabyl(Buildings_ParcelID_DINS_intersects_EAVES) #eaves, has data for ~33% only.   
#11
dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
   tabyl(Buildings_ParcelID_DINS_intersects_VENTSCREEN) #only data on 29% of sample, and 11% of sample had no vents. 
#No Vents  

#exploring fence; about half the data has 'No Fence', and that's the same for util misc and single residence
#no real pattern in who has a fence or who doesn't
dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>% 
     tabyl(Buildings_ParcelID_DINS_intersects_STRUCTUREC,Buildings_ParcelID_DINS_intersects_FENCEATTAC)%>%  adorn_totals()%>%adorn_percentages()

 

#exploring cross walk - if you have unk for exterior siding, you do know carport sometimes and vice versa
  dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
  tabyl(Buildings_ParcelID_DINS_intersects_EXTERIORSI,Buildings_ParcelID_DINS_intersects_PATIOCOVER) %>% adorn_totals()

#exploring cross walk 
# DECKPORCHE is a deck that is elevated off the ground
# DECKPORCHO is a deck that is on grade 
#there are some cases where information was entered for both, indicating that part of a deck was elevated and part on grade?
  dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
  tabyl(Buildings_ParcelID_DINS_intersects_DECKPORCHE,Buildings_ParcelID_DINS_intersects_DECKPORCHO) %>% adorn_totals()

#exploring more on deckporch - most of the Nos are on single family residential
dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>% 
     tabyl(Buildings_ParcelID_DINS_intersects_DECKPORCHE,Buildings_ParcelID_DINS_intersects_STRUCTUREC)%>%  adorn_totals()  
    
  
#exploring cross walk - if you have No for window do you also have no eaves; yes abt half with no windows also have no eaves
  dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
  tabyl(Buildings_ParcelID_DINS_intersects_EAVES,Buildings_ParcelID_DINS_intersects_WINDOWPANE) %>% adorn_totals()

#exploring cross walk more - most of those buildings with out eaves or windows are Misc Utility and were destroyed.
  #34 builds with no windows and no eaves, 29 of which are misc utility (26 destroyed)
  dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
     filter(Buildings_ParcelID_DINS_intersects_WINDOWPANE=='No Windows'&Buildings_ParcelID_DINS_intersects_EAVES=='No Eaves')%>% 
     tabyl(Buildings_ParcelID_DINS_intersects_STRUCTUREC,Buildings_ParcelID_DINS_intersects_DAMAGE) 
  

#exploring cross walk - if you have No for attached fence also no for elevated deck porch; yes 542 have both
  dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
  tabyl(Buildings_ParcelID_DINS_intersects_FENCEATTAC,Buildings_ParcelID_DINS_intersects_DECKPORCHE) %>% adorn_totals()
  
  #exploring cross walk more - most of those buildings with out eaves or windows are Misc Utility and were destroyed.
  #34 builds with no windows and no eaves, 29 of which are misc utility (26 destroyed)
  dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
     filter(Buildings_ParcelID_DINS_intersects_FENCEATTAC=='No Fence'&Buildings_ParcelID_DINS_intersects_DECKPORCHE=='No Deck/Porch')%>% 
     tabyl(Buildings_ParcelID_DINS_intersects_STRUCTUREC,Buildings_ParcelID_DINS_intersects_DAMAGE) 
  
#defensive action-Drop
  #drop this one - email from Steve Hawks CALFIRE on 11/2/21 said the blanks are maybe unknown maybe nos, and that the field was new
  #for Woolsey
  dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
  tabyl(Buildings_ParcelID_DINS_intersects_DEFENSIVEA)

#UTILITYMIS-Drop
# distance to a utility or misc structure that is over 120 s q. ft.  This is the threshold where a building permit is required.  It
# also is currently the sq. ft. thresholds for the California Building Code Chapter 7A where certain standards apply.  If there are mor
# than one qualifying utility/misc structure, it is the distance to the one that is the closest.  
# don't know what to do with blank fields, even after Steve Hawks email. Drop
dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
  tabyl(Buildings_ParcelID_DINS_intersects_UTILITYMIS)





```
### b reclass DINS
```{r}

dins %>% 
  st_drop_geometry() %>% names()

dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>% View()

#for random forest blank and unknown need to be NA; when no fence etc, can remain a character 
subdins<-dins %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Buildings_ParcelID_DINS_intersects_INCIDENTST)) %>%
  filter(!(ID_Build==4681)) %>% #removed this off investig below, is three mobile homes w diff features assigned to same point
  filter(!(ID_Build==5543)) %>% #removed this off investig below, is three mobile homes w diff features assigned to same point
  tidylog::select(ID_Build,
                  build_EXTERIORSI = Buildings_ParcelID_DINS_intersects_EXTERIORSI,
                  build_FENCEATTAC = Buildings_ParcelID_DINS_intersects_FENCEATTAC, 
                  build_DECKPORCHO = Buildings_ParcelID_DINS_intersects_DECKPORCHO,
                  build_DECKPORCHE = Buildings_ParcelID_DINS_intersects_DECKPORCHE,
                  build_ROOFCONSTR = Buildings_ParcelID_DINS_intersects_ROOFCONSTR,
                  build_PATIOCOVER = Buildings_ParcelID_DINS_intersects_PATIOCOVER,
                  build_PROPANETAN = Buildings_ParcelID_DINS_intersects_PROPANETAN,
                  build_WINDOWPANE = Buildings_ParcelID_DINS_intersects_WINDOWPANE,
                  build_VEGCLEARAN = Buildings_ParcelID_DINS_intersects_VEGCLEARAN,
                  build_EAVES = Buildings_ParcelID_DINS_intersects_EAVES,
                  build_VENTSCREEN = Buildings_ParcelID_DINS_intersects_VENTSCREEN) %>% 
  mutate_at(vars(c(2:12)), list(~ ifelse( . == "Unknown", NA, .)))%>% #if unknown, make missing or NA
  mutate_at(vars(c(2:12)), list(~ ifelse( . == " ", NA, .)))%>%  #if blank, make missing or NA
  mutate_at(vars(c(2:12)), list(~ ifelse( . == "N/A", "None", .)))%>% #if not applicable, turn into 'none'
  mutate(build_PROPANETAN =as.factor(case_when(
                     build_PROPANETAN == "0-10" ~ "1. 0-10",
                     build_PROPANETAN == "11-20" ~ "2. 11-20",
                     build_PROPANETAN == "21-30" ~ "3. 21-30",
                     build_PROPANETAN == ">30'" ~ "4.>30",
                     build_PROPANETAN == "None" ~ "None")))%>% 
mutate(build_VEGCLEARAN =as.factor(case_when(
                     build_VEGCLEARAN == "0-30'" ~ "1. 0-30",
                     build_VEGCLEARAN == "30-100'" ~ "2. 30-100",
                     build_VEGCLEARAN == ">100'" ~ "3. >100"))) %>% #this will change 6 n/as into blank - I think appropriate
  mutate(build_DINS=1)%>% #create a variable to say had a record in DINS
unique() #at this point keeping only unique based on ID build does not remove any data, just deletes repeated lines

#looking at duplicate data; appears that for two ID_Build (4681,5543) there are duplicated and conflicting data; delete these obs
#for all other dupes, the data are the same, so we should just delete repeats
# # length(unique(subdins$ID_Build))
# test<-subset(subdins,duplicated(subdins$ID_Build))
# View(test)
# length(unique(test$ID_Build))
# test2<-subset(test,duplicated(test$ID_Build))

subdins %>%tabyl(build_DECKPORCHO)
subdins %>%tabyl(build_DECKPORCHE)
subdins %>%tabyl(build_EAVES)
subdins %>%tabyl(build_EXTERIORSI)
subdins %>%tabyl(build_FENCEATTAC)
subdins %>%tabyl(build_PATIOCOVER)
tabyl(subdins$build_PROPANETAN)  
subdins %>%tabyl(build_ROOFCONSTR)
tabyl(subdins$build_VEGCLEARAN) 
tabyl(subdins$build_VENTSCREEN) 
tabyl(subdins$build_WINDOWPANE) 

```



## 5 merge DINS with full data set & write
```{r}

build %>% glimpse() #84 variables
length(build)
subdins %>% glimpse()

build_exp <- build %>% # drops 10, this is what we want to export from build
  # st_drop_geometry() %>%
  tidylog::select(ID_Build, ID_Parcel, parcel_AIN, #ok
                  damage_cat : damage_severity, build_structures_DAMAGE, #ok
                  build_Mean_elev_30m : build_Mean_distall_road, #ok
                  build_min_dist_tree : build_perc_overhang, #ok 
                  build_near_dest:build_near_exp,#building distance to destroyed and exposed #ok
                  build_dist_to_build_ft_jod = build_dist_to_build_ft, #unclear to me why named   jod but will keep name 12/2/21 #ok
                  build_p_tree_10: build_p_shrub_300, # looks good for building and veg data 11/16/2021 #ok
                  build_area, #ok
                  parcel_UseType : parcel_Imperv_P, #ok
                  parcel_year_built = parcel_recent, #ok
                  parcel_area) #ok
   
build_exp %<>% 
  left_join(., subdins, by = c('ID_Build' = 'ID_Build'))

build_exp %>% 
  write_csv(., paste0(getwd(), '/output_data/building_', Sys.Date(), '.csv'))#building_2021-12-22.csv' 

```



## 6 CORRECT building distance to destroyed and exposed by fire, redone Feb 2022
```{r} 

# rather than re-run all of the above building dataset, importing latest (Dec 2021 data above) and 
# deleting incorrect columns. will add correct ones below.

# next to final build data, 11,181 observations, 82 cols
build <- read_csv(paste0(getwd(), '/output_data/building_2021-12-22.csv')) %>% 
select(!c(build_dist_to_build_ft_jod, build_near_dest, build_near_exp))%>%  glimpse()

#are some duplicate building IDs, #Dexter what else to do about these duplicates??
duplicated(build$ID_Build) %>% tabyl()
test<-build[duplicated(build$ID_Build), ]
View(test)

#this is removing duplicates based on ID_Build, but I don't know if more thoughful approach is needed, #Dexter
build<-build[!duplicated(build$ID_Build), ] #11,134 observations


# processing to get to min distance to destroyed, has repeats and 5 dists, remove dupes
min_dest2 <- read_csv('data/Near_dest220131_2.csv') %>%  #distance to destroyed building;
  # if this is 0, it is distance to self, value 2
  dplyr::select(c(ID_Build=Buildings_ParcelID_DINS_ID_Build
                  , near_dest=NEAR_DIST
                  , Rank=NEAR_RANK)) %>%
  filter(near_dest != 0) %>% #removes zeroes bc that is measuring distance to self
  group_by(ID_Build) %>%
  filter(near_dest == min(near_dest)) %>% #keeps smallest distance to building
  # filter(near_dest == near_dest[which.min(near_dest)]) %>% #keeps smallest distance to building
  ungroup() %>% 
  dplyr::select(ID_Build, near_dest) %>% 
  distinct()
  
# # older processing on min_dest2 to check number of duplicates
# min_dest2 %>% duplicated() %>% tabyl() # 011140 are not duplicates
# min_dest2 %>% distinct() %>% glimpse() # keeps only the 11140 that are unique


# processing to get to min distance to exposed, has repeats and 5 dists, remove dupes
min_exp2 <- read_csv('data/Near_exp220131_2.csv') %>%  #distance to exposed building;
  # if this is 0, it is distance to self, delete
  dplyr::select(c(  ID_Build = Buildings_ParcelID_DINS_ID_Build
                  , near_exp = NEAR_DIST
                  , Rank = NEAR_RANK)) %>%
  filter(near_exp != 0) %>%
  group_by(ID_Build) %>%
  filter(near_exp == min(near_exp)) %>%
  ungroup() %>% 
  dplyr::select(ID_Build, near_exp)%>% 
  distinct()

 
# older processing on min_exp2 to check number of duplicates
# min_exp2 %>% duplicated() %>% tabyl() #11140 are not duplicates
# min_exp2 %>% distinct()%>%glimpse()#keeps only the 11140 that are unique

# processing to get to min distance to any building has repeats and 5 dists, remove dupes
min_build <- read_csv('data/near_allbuild220131.csv') %>%  #distance to destroyed building;
  # if this is 0, it is distance to self, delete
  dplyr::select(c(  ID_Build = Buildings_ParcelID_DINS_ID_Build
                  , dist_build = NEAR_DIST
                  , Rank = NEAR_RANK)) %>%
  filter(dist_build != 0) %>%
  group_by(ID_Build) %>%
  filter(dist_build == min(dist_build)) %>%
  ungroup() %>% 
  dplyr::select(ID_Build, dist_build) %>% 
  distinct()

# older processing on min_exp2 to check number of duplicates
# min_build %>% duplicated() %>% tabyl() #11140 are not duplicates
# min_build %>% distinct()%>%glimpse()#keeps only the 11140 that are unique


build %<>% 
  left_join(., min_dest2, by = c('ID_Build' = 'ID_Build')) %>% 
  left_join(., min_exp2, by = c('ID_Build' = 'ID_Build')) %>% 
  left_join(., min_build, by = c('ID_Build' = 'ID_Build')) %>% 
  rename(build_near_dest  = near_dest, #nearest distance to destroyed building in feet
         build_near_exp   = near_exp, #nearest distance to exposed building in feet
         build_near_build = dist_build) #nearest distance to any building in feet

#testing to see if any NAs for near_dest or near_exp - are none
# test <-
#   build %>%
#   filter_at(vars(starts_with("build_near")), any_vars(is.na(.)))

#tables and figures to explore different building distance measures
table(build$build_near_exp>build$build_near_dest) #build_near_dest is always equal to or bigger than build_near_exp
plot(build$build_near_exp,build$build_near_dest) #highly correlated 
 
plot(build$build_near_build,build$build_near_exp)  
build |> 
  ggplot(aes(build_near_build, build_near_exp)) + 
  geom_point() + 
  geom_abline() + 
  coord_fixed() + 
  NULL

# Phew, there are no exposed buildings closer than near_build 
test<-build %>% 
  filter(build_near_exp < build_near_build)

 
```

### a read out/ read in
```{r}
# # exporting new build data set 11,134 obs, Columns: 85
build %>% glimpse()
 build %>%
   write_csv(., paste0(getwd(), '/output_data/building_', Sys.Date(), '.csv')) #output_data/building_2022-02-01.csv



```


## 7 CLEANED building fragments and corrected proportion, redone June 2022
```{r} 

# rather than re-run all of the above building dataset, importing latest (Feb 2022 data above) and 
# removing building fragments identified in Arc

# read in dataset with fragmented  buildings
frag <- read_csv(paste0(getwd(), '/data/Table_fragbuild_20220608.csv')) #11214 obs
frag2<-frag %>% filter(Fragment==1) %>% #if fragment =1, it's a fragmented building
    tidylog::select(ID_Build,Fragment)

build <- read_csv(paste0(getwd(), '/output_data/building_2022-02-01.csv')) #11134 obs #read in buildings data
names(build)
build %<>% 
  left_join(., frag2, by = c('ID_Build' = 'ID_Build'))%>% 
  filter(is.na(Fragment) | Fragment != "1") %>%  #keep only those buildings that are not fragments
  mutate(build_perc_overhang=build_perc_overhang*100) %>% #rescale percent overhang from 0-1
  tidylog::select(!Fragment) #end up with 10901 buildings

# min(build$build_area) #checked on minimum building size in remaining data set, this is correct
# [1] 37.19921

```

### a read out/ read in
```{r}
# # exporting new build data set 10,901 obs, Columns: 85
build %>% glimpse()
 build %>%
   write_csv(., paste0(getwd(), '/output_data/building_', Sys.Date(), '.csv')) #output_data/building_2022-06-10.csv



```
```{r, citations}
lapply(packages, citation)
```


Last knit on `r format(Sys.time())`


```{r}
system.time(save.image(file = paste0('saved_sessions/wui_r_',
                                     gsub('[[:punct:]]', '-', Sys.time()), '.RData')))
```

