---
title: "04_fit_models.Rmd"
author: "Dexter H. Locke, PhD"
date: "`r format(Sys.time())`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This assumes "02_Woosley_combine_data.Rmd" was run

## 0 set up: load libraries, custom functions, set defaults

```{r}
# load libraries
# packages we'll be using
packs <- c('tidyverse'        # a must have!
           , 'tidylog'        # makes things very verbose for 2x checking 
           , 'magrittr'       # all of the pipes
           , 'janitor'        # cleans things up
           # , 'sf'             # simple features
           # , 'mapview'        # quick webmaps for zoom/pan viz
           #'tidycensus',     # access to Census data in a tidy way
           #'party',          # random forests
           , 'modEvA'         # contains D-squared function
           , 'randomForest'  #'rfUtilities', 'verification'
           , 'tictoc'         # times things
           , 'beepr'          # makes noises
           ,  'ggpubr'        #for scatter plot
           # , 'broom'          # tidy up regression models
           # , 'performance'    # nice regression diagnostics
           # , 'psych'          # describe is very useful for descriptive statistics
           # , 'sjPlot'         # useful plotting and regression support
           # , 'rpart'          # for random forests
           # # , pROC           # for AUC calculation
           , 'doParallel'     # make partial dependency plots less-slow
           , 'pdp'            # partial dep plots
           , 'vip'            # Variable Importance Plots (and extracting vip vals)
           # , 'caret'          #random forest work
           , 'party'          # for random forests using cforest
           , 'sf'             # for spatial data
           )        

# check for all of the libraries
if (length(setdiff(packs, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packs, rownames(installed.packages())))  
}

# lapply(packs, library, character.only = TRUE)
vapply(packs, library, character.only = TRUE, logical(1),
       logical.return = TRUE, quietly = TRUE)


# custom function for "Not In"
`%nin%` <- Negate(`%in%`)

# for reproducibility, we should have the same random draws. setting the seed ensures that is the case.
set.seed(19870630)
```

## 1 read in data

### A main `build` file

```{r}

# build <- read_csv(paste0(getwd(), '/output_data/building_2022-02-01.csv')) %>% glimpse

# one 'main' data frame
build <- read_csv(paste0(getwd(), '/output_data/building_2022-06-10.csv')) %>%
  tidylog::select(
      ID_Build
    , damage_binary
    , damage_cat         # binary outcome encoded as categorical (Destroyed / Survived)
    , damage_severity    # five levels
    , build_area   
    # build_DECKPORCHE    , #drop this on 12/20/21
    , build_DECKPORCHO
    , build_EAVES
    , build_EXTERIORSI
    , build_FENCEATTAC
    , build_PATIOCOVER
    , build_PROPANETAN
    , build_ROOFCONSTR
    , build_VEGCLEARAN 
    , build_VENTSCREEN 
    , build_WINDOWPANE 
    , parcel_year_built 
    , build_near_build 
    , build_has_tree_overhang 
    , build_min_dist_shrub 
    , build_min_dist_tree 
    , build_overhang_ht 
    , build_perc_overhang 
    , parcel_Build_P 
    , parcel_Can_P 
    , parcel_Grass_P 
    #, parcel_Imperv_P    #inverse of perv surface; shld we just drop bc we don't have for other measures?
    , parcel_Paved_P    
    #  parcel_Perv_P    ,#inverse of imp, just need one
    , parcel_Road_P
    , parcel_Shrub_P  
    , parcel_Soil_P  
    , parcel_Water_P  
    , build_near_dest  
    , build_p_building_10  
    , build_p_building_100  
    , build_p_building_200  
    , build_p_building_300  
    , build_p_grass_10  
    , build_p_grass_100  
    , build_p_grass_200  
    , build_p_grass_300  
    , build_p_otherpaved_10  
    , build_p_otherpaved_100  
    , build_p_otherpaved_200  
    , build_p_otherpaved_300  
    , build_p_road_10  
    , build_p_road_100  
    , build_p_road_200  
    , build_p_road_300  
    , build_p_shrub_10  
    , build_p_shrub_100  
    , build_p_shrub_200  
    , build_p_shrub_300  
    , build_p_soil_10  
    , build_p_soil_100  
    , build_p_soil_200  
    , build_p_soil_300  
    , build_p_tree_10  
    , build_p_tree_100  
    , build_p_tree_200  
    , build_p_tree_300  
    , build_p_water_10  
    , build_p_water_100  
    , build_p_water_200  
    , build_p_water_300  
    , parcel_area  
    , build_Mean_builddens  
    , build_Mean_distall_road  
    , build_Mean_distroad   
    , build_Mean_aspect_100m_DEM  
    , build_Mean_aspect_30m_DEM  
    , build_Mean_elev_100m  
    , build_Mean_elev_30m  
    , build_Mean_distroad  
    , build_Mean_slope_30m_DEM
    , build_DINS
    ) %>%
  mutate_if(is.character, as.factor) %>% # turns characters into factors
  droplevels() %>% 
  data.frame() # some of the random forest functions do not 'like' tibbles
               # since the non-dins and dins data will be pulled from here
               # we change here so that the subsets are already formatted as data.frames

# Miranda: do these NA's surprise you? OK to drop non-DINS-associated NA's?
#  2/23/22 Dexter: As long as it does not also discard DINS observations. I don't see the harm in keeping them, given that we do have many NAs in DINS.

build %>% 
  map(~sum(is.na(.))) %>% # map is like for loop but vectorized, meaning its faster uses dif. syntax help(purrr::map)
  bind_rows() %>%         # the output of purrr::map is a list, this makes a tibble
  t()#  %>% View() # check for NA's ("t" is for Transpose, just makes it easier to read)


# spatial data 
(build_gis <- read_sf(dsn = paste0(getwd(),
                                  '/data/Outgoing_BuildingSumms_DHL20200423.gdb'),
                     layer = 'Buildings_ParcelID_DINS',
                     quiet = FALSE) |> 
  tidylog::select (ID_Build) |> 
  distinct(ID_Build, Shape) |> 
  right_join(build |> select(ID_Build), by = 'ID_Build')) # filtering GIS to match table

```

### B non-DINS data (larger dataset, fewer predictors)

```{r}

# a subset for non-DINS-associated data
build_no_dins <- build %>% 
  tidylog::select(# dropping columns containing specific DINS data
                  # very detailed but sparse (lots of NAs)
    !c(  build_DECKPORCHO
       , build_EAVES
       , build_EXTERIORSI
       , build_FENCEATTAC
       , build_PATIOCOVER
       , build_PROPANETAN
       , build_ROOFCONSTR
       , build_VEGCLEARAN
       , build_VENTSCREEN
       , build_WINDOWPANE
       , build_DINS
       , damage_severity # dropping the DV for the smaller model
       )
    )

# NAs are expected
build_no_dins %>% 
  map(~sum(is.na(.))) %>% 
  bind_rows() %>% 
  t() # %>% View() # check for NA's

# how is the outcome distributed?
build         %>% tabyl(damage_cat) # good double check
build_no_dins %>% tabyl(damage_cat)

# damage_binary is useful for glms - same data different values
build         %>% tabyl(damage_cat, damage_binary) # good double check
build_no_dins %>% tabyl(damage_cat, damage_binary)

```

### C DINS data (smaller dataset, more predictors)

```{r}
# get data for DINS analyses
build %>% tabyl(build_DINS)

# subset
build_dins <- build %>% 
  filter(build_DINS == 1) %>% 
  tidylog::select(-build_DINS, -damage_cat)
  # dropping the DV for the smaller model


build_dins %>% 
  map(~sum(is.na(.))) %>% 
  bind_rows() %>% 
  t() # %>% View() # check for NA's


dim(build_dins)
build_dins %>% drop_na() %>% dim() # not going to be practical for randomForest::randomForest

build_dins %>% tabyl(damage_severity)

# 10/13/2022 looking at class balance with windows, eaves, and vents
build_dins %>% 
  tidylog::select(build_VENTSCREEN,build_WINDOWPANE,build_EAVES) %>% 
  tabyl(build_WINDOWPANE) -> window_prop

build_dins %>% 
  tidylog::select(build_VENTSCREEN,build_WINDOWPANE,build_EAVES) %>% 
  tabyl(build_EAVES) -> eaves_prop

build_dins %>% 
  tidylog::select(build_VENTSCREEN,build_WINDOWPANE,build_EAVES) %>% 
  tabyl(build_VENTSCREEN) -> ventscreen_prop

window_prop; eaves_prop; ventscreen_prop

build_dins %>% 
  filter(build_VENTSCREEN == "Unscreened") %>% View()

```

### D compile data - export for A. Syphard Oct 2022

```{r eval=FALSE, include=FALSE}
#data to export for Alex Syphard
#October 31, 2022

#this is final data layer we used for statistical analyses and models
#read in
build_join <- read_csv(paste0(getwd(), '/output_data/building_2022-06-10.csv')) %>% glimpse()

# create building spatial data for sharing 
# read in spatial data
st_layers(paste0(getwd(), '/data/Outgoing_BuildingSumms_DHL20200423.gdb'))
build_gis <- read_sf(dsn = paste0(getwd(), '/data/Outgoing_BuildingSumms_DHL20200423.gdb'),
                      layer = 'Buildings_ParcelID_DINS',
                      quiet = FALSE) %>% 
  tidylog::select (ID_Build) %>% 
  glimpse()

# tested to ensure can join to GIS -- this works
# build_gis2 <-build_gis %>% 
#   tidylog::select(ID_Build) %>% 
#   full_join(build_join, by = c('ID_Build' = 'ID_Build')) #are some rows only in geospatial data, this join keeps all.

#export only ID Build and Geometries output_data
build_gis %>% 
  st_write(., paste0(getwd(), '/output_data/build_gis_ASyphard_', gsub("-", "_", Sys.Date()), '.gpkg')) 


# create final parcel geospatial data
# read in spatial data
parcel_gis<-read_sf(dsn = paste0(getwd(), '/data/Outgoing_BuildingSumms_DHL20200423.gdb'),
                      layer = 'Parcels_fireperim_LC',
                      quiet = FALSE) %>% 
  mutate (AIN = as.double (AIN)) %>%  #made a double to confirm joins w buildings
           glimpse()

#testing that AIN joins buildings and parcel data
# test <- parcel_gis %>%  
#          full_join (build_join, by = c('AIN'= 'parcel_AIN'))  %>% 
#           tidylog::select (parcel_AIN, AIN, Can_P, parcel_Can_P)
# 
# plot(test$Can_P, test$parcel_Can_P) #only one observation is off; thus AIN works to join



#export parcel data
parcel_gis %>% 
  st_write(., paste0(getwd(), '/output_data/parcel_gis_ASyphard_', gsub("-", "_", Sys.Date()), '.gpkg')) 

```

### E Examine correlations of predictors
```{r}

# pretty table for pub
build |> 
  tidylog::select_if(is_double) %>% # just numerically-encoded variables
  select(!build_DINS & !ID_Build) %>%
  sjPlot::tab_corr(.
                   , triangle = 'lower'
                   # , file = paste0(getwd(), '/output_data/correlations_',
                   #                 gsub('[[:punct:]]', '_', Sys.time()), '.html')
                   )

# find correlations
(cors_tibble <-
  build %>% 
  tidylog::select_if(is_double) %>% 
  select(!build_DINS) %>%
  cor(use = 'pairwise.complete.obs') %>% 
  data.frame() %>% 
  rownames_to_column(var = 'var1') %>% 
  as_tibble() %>%
  pivot_longer(-var1, names_to = 'var2') %>% 
  filter(var1 != var2) %>%
  arrange(desc(value)))

# find large correlations
cors_tibble |> 
  filter(value > .7) #|> View() # 70, highly correlated pairs, oof.

# many are from the same land cover variable but with a different buffer distance
# lets fit univariate glms and use the predictor per group (same var diff buffer)
# with greater predictive power
```


#### make var_redundancy_group to find potentially redundant variables within groups of variables.
```{r}


var_redundancy_group <- 
  tribble(
     ~group,                ~name,
        NA                  , 'build_area'
     ,  NA                  , 'parcel_year_built'
     ,  NA                  , 'build_near_build'
     ,  'overhang'          , 'build_has_tree_overhang'
     ,  NA                  , 'build_min_dist_shrub'
     ,  NA                  , 'build_min_dist_tree'
     ,  'overhang'          , 'build_overhang_ht'
     ,  'overhang'          , 'build_perc_overhang'
     , 'parcel lc'          , 'parcel_Build_P'
     , 'parcel lc'          , 'parcel_Can_P'
     , 'parcel lc'          , 'parcel_Grass_P'
     , 'parcel lc'          , 'parcel_Paved_P'
     , 'parcel lc'          , 'parcel_Road_P'
     , 'parcel lc'          , 'parcel_Shrub_P'
     , 'parcel lc'          , 'parcel_Soil_P'
     , 'parcel lc'          , 'parcel_Water_P'
     ,  NA                  , 'build_near_dest'
     , 'build_p_building'   , 'build_p_building_10'
     , 'build_p_building'   , 'build_p_building_100'
     , 'build_p_building'   , 'build_p_building_200'
     , 'build_p_building'   , 'build_p_building_300'
     , 'build_p_grass'      , 'build_p_grass_10'
     , 'build_p_grass'      , 'build_p_grass_100'
     , 'build_p_grass'      , 'build_p_grass_200'
     , 'build_p_grass'      , 'build_p_grass_300'
     , 'build_p_otherpaved' , 'build_p_otherpaved_10'
     , 'build_p_otherpaved' , 'build_p_otherpaved_100'
     , 'build_p_otherpaved' , 'build_p_otherpaved_200'
     , 'build_p_otherpaved' , 'build_p_otherpaved_300'
     , 'build_p_road'       , 'build_p_road_10'
     , 'build_p_road'       , 'build_p_road_100'
     , 'build_p_road'       , 'build_p_road_200'
     , 'build_p_road'       , 'build_p_road_300'
     , 'build_p_shrub'      , 'build_p_shrub_10'
     , 'build_p_shrub'      , 'build_p_shrub_100'
     , 'build_p_shrub'      , 'build_p_shrub_200'
     , 'build_p_shrub'      , 'build_p_shrub_300'
     , 'build_p_soil'       , 'build_p_soil_10'
     , 'build_p_soil'       , 'build_p_soil_100'
     , 'build_p_soil'       , 'build_p_soil_200'
     , 'build_p_soil'       , 'build_p_soil_300'
     , 'build_p_tree'       , 'build_p_tree_10'
     , 'build_p_tree'       , 'build_p_tree_100'
     , 'build_p_tree'       , 'build_p_tree_200'
     , 'build_p_tree'       , 'build_p_tree_300'
     , 'build_p_water'      , 'build_p_water_10'
     , 'build_p_water'      , 'build_p_water_100'
     , 'build_p_water'      , 'build_p_water_200'
     , 'build_p_water'      , 'build_p_water_300'
     ,  NA                  , 'parcel_area'
     ,  NA                  , 'build_Mean_builddens'
     , 'build_Mean_dist_rd' , 'build_Mean_distall_road'
     , 'build_Mean_dist_rd' , 'build_Mean_distroad'
     , 'build_Mean_aspect'  , 'build_Mean_aspect_100m_DEM'
     , 'build_Mean_aspect'  , 'build_Mean_aspect_30m_DEM'
     , 'build_Mean_elev'    , 'build_Mean_elev_100m'
     , 'build_Mean_elev'    , 'build_Mean_elev_30m'
     , 'build_Mean_slope'   , 'build_Mean_distroad'
     , 'build_Mean_slope'   , 'build_Mean_slope_30m_DEM'
     )


```


#### check deviance of individual predictors
```{r}

# (sample_ids <- build |> sample_n(1000) |> pull(ID_Build)) # creates dispersed data.. 
(sample_ids <- build |> slice(1:1500) |> pull(ID_Build))
build_gis |> filter(ID_Build %in% sample_ids) |> mapview::mapview()

library(sfdep)
# full_files = map(full_files, ~filter(., state == 'PA')),
tic(); glm_spatial_diag <- 
  build |> 
  tibble() |> # for sanity
  select(!c(damage_cat, damage_severity, build_DINS)) |> # drop distracting cols
  select(where(is.numeric)) |>                           # drop categorical preds (no cors)
  # filter(ID_Build %in% sample_ids) |>                    # filter down to test
  pivot_longer(cols = !c(ID_Build, damage_binary)) |>    # reshape
  left_join(build_gis, by = 'ID_Build') |>               # make spatial
  st_as_sf() |>                                          # make sf
  group_by(name) |>                                      # package up
  nest() |> 
  ungroup() |> 
  mutate(  data        = map(data,  ~drop_na(.x))
         , model       = map(data,  ~glm(damage_binary ~ value, family = binomial(), .x))
         , nbs         = map(data,  ~sfdep::st_knn(sf::st_geometry(.x), 5)),
         , wts         = map(nbs,   ~st_weights(.x, style = 'W', allow_zero = TRUE), .progress = TRUE)
         , performance = map(model, ~performance::performance(.x))
         , dsqr        = map(model, ~Dsquared(.x))
         , resids      = map(model, ~residuals(.x))
         , mi          = pmap(list(resids, nbs, wts), global_moran_test, .progress = TRUE)
         , mi          = map(mi,    ~rownames_to_column(data.frame(unlist(.x))))
         , mi          = map(mi,    ~filter(.x, rowname == 'p.value' | rowname == 'estimate.Moran I statistic'))
         ); toc(); beep() # ~2 mins


glm_spatial_diag # handsome object!

# get performance metrics
glm_spatial_diag |> 
  select(name, dsqr, performance) |> 
  unnest(dsqr) |> 
  unnest(performance) # helpful

# update deviance explained 
glm_spatial_diag |> 
  select(name, dsqr, data) |> 
  mutate(n = map(data, ~nrow(.))) |> 
  select(-data) |> 
  unnest(dsqr) |> 
  unnest(n) |> 
  mutate(`Deviance Explained` = 100*dsqr) |> 
  select(`Variable name` = name, n, `Deviance Explained`) |> 
  right_join(
    read_csv(paste0(getwd(), '/data/Table_Deviance_Explained_2022-06-13.csv')) |> 
      rename(old_n = n)
      # mutate(Type = fct_recode(factor(Type), 
      #                         Exposure               = 'EXP'
      #                       , Construction           = 'CON'
      #                       , 'Defensible Space'     = 'DEF'
      #                       , 'Landscape Attributes' = 'LAND'
      #                       , Topography             = 'TOPO')
    , by = 'Variable name'
    ) |> #View()
  mutate(`Deviance Explained (%)` = round(ifelse(is.na(`Deviance Explained`), Deviance, `Deviance Explained`), 2)
         , n= ifelse(is.na(n), old_n, n)
         ) |> 
  select(Theme = Type, `Variable name`, Description = Alias, `Deviance Explained (%)`, n, Source) |> 
  arrange(Theme) #|> 
  # write_csv(paste0(getwd(), '/data/Table_Deviance_Explained_2023-01-01.csv'))


# get performance metrics, among (potentially) redundant predictors
(top_perform <- 
  glm_spatial_diag |>
  select(name, dsqr, performance) |> 
  unnest(dsqr) |> 
  unnest(performance) |> 
  left_join(var_redundancy_group, by = 'name') |> 
  group_by(group) |> 
  summarise(  max_d    = name[which.max(dsqr)]
            , max_r    = name[which.max(R2_Tjur)]
            , min_AIC  = name[which.min(AIC)]
            , min_BIC  = name[which.min(BIC)]
            , min_rmse = name[which.min(RMSE)]
            ))

# get winning vars
(vars_to_include <- 
  bind_rows(
    var_redundancy_group |> # within group best
      filter(name %in% top_perform$max_d) |> # using deviance explained, could use other metric..
      filter(!is.na(group))
    , var_redundancy_group |> # those without a group
      filter(is.na(group))
    )
  )

# did we resolve our high-correlation issues?
# find correlations
(
  cors_tibble_reduced <-
  build %>% 
  select(all_of(vars_to_include$name)) %>%
  cor(use = 'pairwise.complete.obs') %>% 
  data.frame() %>% 
  rownames_to_column(var = 'var1') %>% 
  as_tibble() %>%
  pivot_longer(-var1, names_to = 'var2') %>% 
  filter(var1 != var2) %>%
  arrange(desc(value))
  )

# find large correlations
cors_tibble_reduced |> 
  filter(value > .7) #|> View() # parcel_Build_P, build_p_building_300 ugh

glm_spatial_diag |>
  filter(name == 'parcel_Build_P' | name == 'build_p_building_300') |> 
  select(name, dsqr, performance) |> 
  unnest(performance) |> 
  unnest(dsqr) 

# # cut build_p_building_300 since it has lower dsqr, higher AIC, AICc, BIC and lower R2
vars_to_include <-
  vars_to_include |>
  filter(name != 'build_p_building_300')

# are the residual spatially autocorrelated? 
glm_spatial_diag |>  
  select(name, mi) |>
  unnest(mi) |> 
  rename(stat = rowname, value = unlist..x.) |> 
  type_convert() |> 
  pivot_wider(names_from = stat, values_from = value) |> 
  left_join(vars_to_include |> select(name) |> mutate(keep = 1)
            , by = 'name') |> 
  # arrange(desc(`estimate.Moran I statistic`)) |>
  ggplot(aes(`estimate.Moran I statistic`, reorder(name, `estimate.Moran I statistic`))) +
  geom_col(aes(fill = keep)) + 
  theme_bw(12) + 
  scale_x_continuous(expand = c(0, 0), limits = c(0, .5)) +
  labs(title = 'bivariate models have lots of residual spatial autocorrelation') + 
  NULL

# # what does a maximal glm look like?
# max_glm <- glm(  damage_binary ~ .
#                , family = binomial()
#                , data = build |> select(damage_binary, vars_to_include$name) |> 
#                  drop_na())
# 
# max_glm |> sjPlot::plot_model() + xlim(.5, 2)
# 
# max_glm |> performance::performance() # ~84% accuracy?

```


# reprex for @JosiahParry (developer of sfdep) 
```{r eval=FALSE, include=FALSE}
install.packages("palmerpenguins")
dat <- palmerpenguins::penguins

library(sf)
library(sfdep)
library(tidyverse)
library(performance)

# make spatial data
spat <- 
  tibble(
    rowid = 1:344,
    lon = runif(344, 38.753907, 39.720585),
    lat = runif(344, -77.293825, -75.866819)
    ) |> 
  st_as_sf(coords = c('lat', 'lon'), crs = st_crs(4326))

spat |> mapview::mapview() # confirmed, random points in Baltimore region

# in the real project we have waaay too many redundant predictors. We are doing bivariate regression
# so that we can group predictors thematically, and pick the most predictive in that group. 
# Then we'll have a pruned-down set of predictors in a random forest model. This is all for 
# variable selection to prevent multicollinearity. But the workflow might be helpful in other 
# circumstances. Thanks for your interest and for taking a look

glm_spatial_diag <- 
  dat |> 
  select(sex, where(is.numeric)) |>            # exclude categorical data
  mutate(sex = ifelse(sex == 'male', 1, 0)) |> # dependent variable in logistic reg
  rowid_to_column() |>                         # pivot prep 
  pivot_longer(cols = !c(rowid, sex)) |> 
  left_join(spat, by = 'rowid') |>             # get spatial data joined in
  st_as_sf() |>                                # make sf
  group_by(name) |>                            # now we have packets of data in "data" listcol
  nest() |>                                    # rowid, dependent, independent, coords
  ungroup() |>                                 # and the dependent variable is in the "name" col
  mutate(  data        = map(data,  ~drop_na(.x))
         , model       = map(data,  ~glm(sex ~ value, family = binomial(), .x))
         , nbs         = map(data,  ~sfdep::st_knn(sf::st_geometry(.x), 5)),
         , wts         = map(nbs,   ~st_weights(.x, style = 'W', allow_zero = TRUE))
         , performance = map(model, ~performance::performance(.x))
         , resids      = map(model, ~residuals(.x))
         , mi          = pmap(list(resids, nbs, wts), global_moran_perm)
  )


# are the residual spatially autocorrelated? (no because the runif coords to make fake spatial data)
glm_spatial_diag |> 
  select(name, mi) |> 
  mutate(mi = map(mi, broom::tidy)) |> 
  unnest_wider(mi)

glm_spatial_diag # handsome

# get performance metrics
glm_spatial_diag |> 
  select(name, performance) |> 
  unnest(performance) # helpful

# are the residual spatially autocorrelated? (no because the runif coords to make fake spatial data)
glm_spatial_diag |> 
  select(name, mi) |> 
  unnest(mi) |> 
  rename(stat = rowname, value = unlist..x.) |> 
  type_convert() |> 
  pivot_wider(names_from = stat, values_from = value) |> 
  arrange(desc(`estimate.Moran I statistic`))

```


## 2 fit random forest models

### A non-DINS analyses (larger dataset, fewer predictors)

```{r}
# fit random forest models
# randomForest::randomForest is faster but requires full data
# party::cforest is slower but can handle missing data

# n_tree <- 10 # used for setting number of trees
# n_tree <- 2000 #3/24/2022 changed back to 2000 trees as Price paper uses 2000
n_tree <- 500 # May 20, 2022 because we want graphs this centry


# # random forest but has to drop NAs
# tic(); rf_no_dins <- randomForest::randomForest(
#   damage_cat ~ .
#   # need full dataset, can't keep NA's
#   , data = build_no_dins |> select(damage_cat, vars_to_include$name) |> drop_na()
#   , type = 'classification' # not regression
#   , mtry = 5
#   , ntree = n_tree # 10 ~.5 seconds,100 ~5s, 200 ~7.5s, 3 ~12s, ... 5 ~23s 
#                    # tested on a few smaller forests
#   ); toc()


# # since this takes a long time to run, I've commented the code off and just read-in
# # the completed model file in its "*.Rdata" format with the load() function.
# # sounds good - I had to rerun this on my machine on 3/24/22 so will see that date below
# # random forest via party::cforest which accepts missing data and is slower
# tic(); cf_no_dins <- party::cforest(
#   damage_cat ~ .
  # , data = build_no_dins |>                   # notice no drop_na here
  #   select(damage_cat, vars_to_include$name)  # this is new based on Todd Hawbaker's feedback
#   , controls =
#     cforest_control(
#         mtry = 5
#       , ntree = n_tree # 10 ~2 seconds, 100 ~25s, 200 ~50s, 300 ~75s ... 500 ~130 seconds
#       , mincriterion = 0
#       )
#   ); toc(); beepr::beep() # 12 mins with 500 trees, 2 mins w vars reduced and 500 trees

# # save out since it is slow
# # sounds good - I had to rerun this on my machine on 3/24/22 so will see that date below
# tic(); save(cf_no_dins, rf_no_dins
#             , file = paste0('../Massive_forests/cf_no_dins_', Sys.Date(), '.Rdata')); toc()

# read back in
# tic(); load(file = '../Massive_forests/cf_no_dins_2022-02-22.Rdata'); toc() # ~9s
# tic(); load(file = '../Massive_forests/cf_no_dins_2022-05-17.Rdata'); toc() # ~50s with 2000 trees!
# tic(); load(file = '../Massive_forests/cf_no_dins_2022-05-20.Rdata'); toc() # < 10s with 500 trees
# tic(); load(file = '../Massive_forests/cf_no_dins_2022-06-13.Rdata'); toc() # < 10s with 500 trees
tic(); load(file = '../Massive_forests/cf_no_dins_2023-02-02.Rdata'); toc() # ~5s with 500 trees

# MHM - last date I ran this was 3/24/22 so will see that date below
#tic(); load(file = '../Massive_forests/cf_no_dins_2022-03-24.Rdata'); toc() # 

```

### B DINS analyses (smaller dataset, more predictors)

```{r}

# predicting severity
n_tree <- 500

# random forest via party::cforest which accepts missing data and is slower
tic(); cf_dins <- party::cforest(
  damage_severity ~ . # severity, not binary
  , data = build_dins |>  # notice build_dins here, no "no" in the object name.
    select(  damage_severity
           , build_DECKPORCHO
           , build_EAVES
           , build_EXTERIORSI
           , build_FENCEATTAC
           , build_PATIOCOVER
           , build_PROPANETAN
           , build_ROOFCONSTR
           , build_VEGCLEARAN
           , build_VENTSCREEN
           , build_WINDOWPANE
           # , build_DINS
           , vars_to_include$name # this is new based on Todd Hawbaker's feedback
           )
  , controls =
    cforest_control(
        mtry = 5
      , ntree = n_tree # 10 ~0.52 seconds, 100 ~1.5s, 200 ~2.7s, 300 ~3.5s ... 500 ~7s
      , mincriterion = 0
      )
  ); toc() # ~9 seconds w reduced predictors

# 3/20/2022 - Dexter, I wanted to see if switching to categorial outcomes added anything extra to our findings so
# I also included a DINS model with a binary outcome. I then compared the variable importance (top 20 variables, importance scores) for both DINS outcomes (binary, categorical) in section 4A. Because the outcomes are so similar I want to keep DINS as binary outcome - I think it's easier for descriptive figures and the reader, and it's keeping story simpler overall
#keeping this as binary - with dins
# subset

n_tree <- 500
build_dins_binary <- build %>% 
  filter(build_DINS == 1) %>% 
  select(-build_DINS, -damage_severity)
  # dropping the DV for the smaller model
# random forest via party::cforest which accepts missing data and is slower
tic(); cf_dins_binary <- party::cforest(
  damage_cat ~ . # binary
  , data = build_dins_binary |>  # notice build_dins_binary here, no "no" in the object name.
    select(  damage_cat
           , build_DECKPORCHO
           , build_EAVES
           , build_EXTERIORSI
           , build_FENCEATTAC
           , build_PATIOCOVER
           , build_PROPANETAN
           , build_ROOFCONSTR
           , build_VEGCLEARAN
           , build_VENTSCREEN
           , build_WINDOWPANE
           # , build_DINS
           , vars_to_include$name # this is new based on Todd Hawbaker's feedback
    )
  , controls =
    cforest_control(
        mtry = 5
      , ntree = n_tree # 2000 is 80 sec - MHM
      , mincriterion = 0
      )
  ); toc() # ~6 seconds with 500 (<4 seconds with reduced predictors)


# tic(); save(cf_dins_binary
#             , file = paste0('../Massive_forests/cf_dins_binary_', Sys.Date(), '.Rdata')); toc()

load('../Massive_forests/cf_dins_2022-02-23.Rdata') # 
```


## add lat/long as predictors - ended up not needing :-(
```{r eval=FALSE, include=FALSE}



# tic(); cf_no_dins_ll <- party::cforest(
#   damage_cat ~ .
#   , data = build_no_dins |>                                 # notice no drop_na here
#     select(ID_Build, damage_cat, vars_to_include$name) |>   # this is new based on Todd Hawbaker's feedback
#     left_join(                                              # fold the x/y coordinates in 
#       build_gis |>
#         st_centroid() %>% # get building centroids
#         cbind(., st_coordinates(.)) %>%
#         st_drop_geometry()
#       , by = 'ID_Build') |> 
#     select(-ID_Build)
#   , controls =
#     cforest_control(
#         mtry = 5
#       , ntree = n_tree 
#       , mincriterion = 0
#       )
#   ); toc(); beepr::beep() # ~2 mins



# tic(); save(cf_no_dins_ll
#             , file = paste0('../Massive_forests/cf_no_dins_ll_', Sys.Date(), '.Rdata')); toc()
# 
# 
# tic(); predict_cf_no_dins_ll <- predict(cf_no_dins_ll); toc() # ~15 mins
# 
# # probability version (instead of hard class) used in ROC / AUC below
# tic(); predict_cf_no_dins_prob_ll <- predict(cf_no_dins_ll,  type = "prob"); toc() # ~15 mins
# 
# 
# tic(); save(predict_cf_no_dins_ll, predict_cf_no_dins_prob_ll
#             , file = paste0('output_data/predict_cf_no_dins_ll_', Sys.Date(), '.Rdata')); toc() # basically instant

load('../Massive_forests/cf_no_dins_ll_2023-02-02.Rdata') # gives us cf_no_dins_ll
load('output_data/predict_cf_no_dins_ll_2023-02-02.Rdata') # gives predict_cf_no_dins_ll, predict_cf_no_dins_prob_ll


table(build_no_dins$damage_cat) # truth
table(predict_cf_no_dins_ll)       # prediction

# compare observed (aka truth) with prediction
(table(  build_no_dins$damage_cat
      , predict_cf_no_dins_ll) %>%
  as.data.frame.matrix(row.names = c('true Destroyed', 'true Survived')) %>% 
  rownames_to_column() -> build_no_dins_ll_accuracy_table)

# accuracy = (TN + TP) / (TN + FP + FN + TP)

(TN <- build_no_dins_ll_accuracy_table$Destroyed[1]) # True Positive
(TP <- build_no_dins_ll_accuracy_table$Survived[2])  # True Negative

100*((TN + TP) / sum(build_no_dins_ll_accuracy_table$Destroyed,
                     build_no_dins_ll_accuracy_table$Survived))

build_no_dins_ll_accuracy_table %>% 
  adorn_percentages(denominator = 'all') %>%
  adorn_pct_formatting()

# variable importance

# tic(); vi_cf_no_dins_ll <- vi(cf_no_dins_ll, scale = TRUE) %>% mutate(Model = 'cf_no_dins_ll', n_tree = n_tree); toc() # ~4 mins

# vi_cf_no_dins_ll |> write_csv(paste0(getwd(), '/output_data/variable_importance_ll_', Sys.Date(), '.csv'))

(vi_cf_no_dins_ll <- read_csv('output_data/variable_importance_ll_2023-02-02.csv'))
```


## add lat/long as predictors - DINS - ended up not needing :-(
```{r eval=FALSE, include=FALSE}


tic(); cf_dins_binary_ll <- party::cforest(
  damage_cat ~ .
  , data = build_dins_binary |>         # notice build_dins_binary here, no "no" in the object name
    select(ID_Build
           , damage_cat
           , vars_to_include$name       # this is new based on Todd Hawbaker's feedback
           , build_DECKPORCHO
           , build_EAVES
           , build_EXTERIORSI
           , build_FENCEATTAC
           , build_PATIOCOVER
           , build_PROPANETAN
           , build_ROOFCONSTR
           , build_VEGCLEARAN
           , build_VENTSCREEN
           , build_WINDOWPANE
           ) |>   
    left_join(                           # fold the x/y coordinates in 
      build_gis |>
        st_centroid() %>%                # get building centroids
        cbind(., st_coordinates(.)) %>%
        st_drop_geometry()
      , by = 'ID_Build') |> 
    select(-ID_Build)
  , controls =
    cforest_control(
        mtry = 5
      , ntree = n_tree 
      , mincriterion = 0
      )
  ); toc(); beepr::beep() # ~8 seconds



# tic(); save(cf_dins_binary_ll
#             , file = paste0('../Massive_forests/cf_dins_binary_ll_', Sys.Date(), '.Rdata')); toc()
# 
# 
# tic(); predict_cf_dins_binary_ll <- predict(cf_dins_binary_ll); toc() # ~18 seconds
# 
# # probability version (instead of hard class) used in ROC / AUC below
# tic(); predict_cf_dins_binary_probs_ll <- predict(cf_dins_binary_ll,  type = "prob"); toc() # ~18 seconds
# 
# 
# tic(); save(predict_cf_dins_binary_ll, predict_cf_dins_binary_probs_ll
#             , file = paste0('output_data/predict_cf_dins_ll_', Sys.Date(), '.Rdata')); toc() # basically instant

# give us cf_dins_binary_ll
load('../Massive_forests/cf_dins_binary_ll_2023-02-03.Rdata')

# gives us predict_cf_dins_binary_ll, predict_cf_dins_binary_probs_ll
load('output_data/predict_cf_dins_ll_2023-02-03.Rdata') 



table(build_dins_binary$damage_cat) # truth
table(predict_cf_dins_binary_ll)    # prediction

# compare observed (aka truth) with prediction
(table(  build_dins_binary$damage_cat
      , predict_cf_dins_binary_ll) %>%
  as.data.frame.matrix(row.names = c('true Destroyed', 'true Survived')) %>% 
  rownames_to_column() -> build_dins_ll_accuracy_table)

# accuracy = (TN + TP) / (TN + FP + FN + TP)

(TN <- build_dins_ll_accuracy_table$Destroyed[1]) # True Positive
(TP <- build_dins_ll_accuracy_table$Survived[2])  # True Negative

100*((TN + TP) / sum(build_dins_ll_accuracy_table$Destroyed,
                     build_dins_ll_accuracy_table$Survived))

build_dins_ll_accuracy_table %>% 
  adorn_percentages(denominator = 'all') %>%
  adorn_pct_formatting()

# variable importance

# tic(); vi_cf_dins_ll <- vi(cf_dins_binary_ll, scale = TRUE) %>% 
#   mutate(Model = 'cf_dins_ll', n_tree = n_tree); toc() # ~40 seconds
# 
# vi_cf_dins_ll |>
#   write_csv(paste0(getwd(), '/output_data/variable_importance_vi_cf_dins_ll_', Sys.Date(), '.csv'))

(vi_cf_no_dins_ll <- read_csv('output_data/variable_importance_vi_cf_dins_ll_2023-02-03.csv'))

```


## 3 overall model accuracy
### A cf_no_dins
```{r}

# tic(); predict_cf_no_dins <- predict(cf_no_dins); toc(); # ~1 hr (now ~15 mins with reduced predictors)
# 
# # probability version (instead of hard class) used in ROC / AUC below
# tic(); predict_cf_no_dins_prob <- predict(cf_no_dins,  type = "prob"); toc()
# 
# 
# tic(); save(predict_cf_no_dins, predict_cf_no_dins_prob
#             , file = paste0('output_data/predict_cf_no_dins_', Sys.Date(), '.Rdata')); toc() # basically instant

# load('output_data/predict_cf_no_dins_2022-04-18.Rdata')
load('output_data/predict_cf_no_dins_2023-02-01.Rdata')


table(build_no_dins$damage_cat) # truth
table(predict_cf_no_dins)       # prediction

# compare observed (aka truth) with prediction
(table(  build_no_dins$damage_cat
      , predict_cf_no_dins) %>%
  as.data.frame.matrix(row.names = c('true Destroyed', 'true Survived')) %>% 
  rownames_to_column() -> build_no_dins_accuracy_table)

# accuracy = (TN + TP) / (TN + FP + FN + TP)

(TN <- build_no_dins_accuracy_table$Destroyed[1]) # True Positive
(TP <- build_no_dins_accuracy_table$Survived[2])  # True Negative

100*((TN + TP) / sum(build_no_dins_accuracy_table$Destroyed,
                     build_no_dins_accuracy_table$Survived))

build_no_dins_accuracy_table %>% 
  adorn_percentages(denominator = 'all') %>%
  adorn_pct_formatting()

```

#### i ROC curve (kinda useless - dang)
```{r eval=FALSE, include=FALSE}

# nice worked example of multiclass ROC
# https://rdrr.io/cran/pROC/man/multiclass.html

# but this one is better
# https://github.com/WandeRum/multiROC
# get response categories as one hot encoded-tibble
# naming with multiROC::multi_roc is really finicky
# column names cannot have dots and must end with 
# "_true" for the observed data and "_pred_xx" 
# for the predicted data, where "_xx" is a method (like 
# 'mn' for multinomial or 'rf' for random forest)
# (
model.matrix(~0 + build_no_dins$damage_cat) %>% # one hot encoding trick
  as_tibble() %>% #glimpse()
  mutate_all(., ~as.integer(.)) %>% 
  rename_all(., ~str_remove_all(., "build_no_dins\\$damage_cat")) %>%
  rename_all(., ~paste0(., '_true')) %>%
  bind_cols(., predict_probs_cf_no_dins %>% 
              map(.x, .f = as_tibble) %>% 
              bind_rows() %>% 
              rename_all(~str_remove_all(., 'damage_cat.')) %>% 
              rename_all(~paste0(., '_pred_cf'))
  ) %>% 
  data.frame() -> class_test_build_no_dins

class_test_build_no_dins %>% names
class_test_build_no_dins %>% glimpse



roc_res <- multiROC::multi_roc(class_test_build_no_dins, force_diag=TRUE)
plot_roc_df <- multiROC::plot_roc_data(roc_res)




# roc_res$AUC
(auc <- tibble(variable             = roc_res$AUC$cf %>% names()
               , multinomial_reg     =     roc_res$AUC$cf %>% unlist()
               # , multinomial_reg_idw = roc_res_idw$AUC$MNi %>% unlist()
               # , random_forest       =     roc_res$AUC$RFc %>% unlist()
               # , random_forest_idw   = roc_res_idw$AUC$RFi %>% unlist()
) #%>% mutate_if(is.double, round, 2)
  # arrange(desc(multinomial_reg))
)

auc %>% View()



# AUC contains a list of AUC for each group of different classifiers. Micro-average ROC-AUC was calculated by stacking all groups together, thus converting the multi-class classification into binary classification. Macro-average ROC-AUC was calculated by averaging all groups results (one vs rest) and linear interpolation was used between points of ROC.



(
  roc_all_facet <- plot_roc_df %>%
    ggplot(aes(x = 1-Specificity, y = Sensitivity)) +
    geom_path(aes(color = Group, linetype=Method), size = 1) + # , alpha = .5) +
    geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1),
                 colour='grey', linetype = 'dotdash') +
    scale_y_continuous(expand = c(0, 0)) +
    scale_x_continuous(expand = c(0, 0)) +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5),
          # legend.justification=c(1, 0), legend.position=c(.95, .05),
          legend.title=element_blank(),
          legend.background = element_rect(fill=NULL, size=0.5,
                                           linetype="solid", colour ="black")) +
    coord_fixed() +
    facet_wrap(~Method) +
    NULL
)

# ggsave(paste0(getwd(), '/figs/roc_all_facet_', Sys.Date(), '.png')
#        , width = 6.5, height = 6.5)

```


### B cf_dins_binary
```{r eval=FALSE, include=FALSE}
# REPEAT for cf_dins_binary

tic(); predict_cf_dins_binary <- predict(cf_dins_binary); toc() # ~75 secs (~20 seconds)

# used in ROC curve calcs
tic(); predict_cf_dins_binary_prob <- predict(cf_dins_binary, type = 'prob'); toc() # ~75 secs (~20 seconds)


table(build_dins_binary$damage_cat) # truth
table(predict_cf_dins_binary)       # prediction

# compare observed (aka truth) with prediction
(table( build_dins_binary$damage_cat
      , predict_cf_dins_binary) %>%
  as.data.frame.matrix(row.names = c('true Destroyed', 'true Survived')) %>% 
  rownames_to_column() -> cf_dins_binary_accuracy_table)

# accuracy = (TN + TP) / (TN + FP + FN + TP)

(TN <- cf_dins_binary_accuracy_table$Destroyed[1]) # True Positive
(TP <- cf_dins_binary_accuracy_table$Survived[2])  # True Negative

100*((TN + TP) / sum(cf_dins_binary_accuracy_table$Destroyed,
                     cf_dins_binary_accuracy_table$Survived))


cf_dins_binary_accuracy_table %>% 
  adorn_percentages(denominator = 'all') %>%
  adorn_pct_formatting()

```

#### i ROC curve (kinda useless - dang)
```{r eval=FALSE, include=FALSE}

# nice worked example of multiclass ROC
# https://rdrr.io/cran/pROC/man/multiclass.html

# but this one is better
# https://github.com/WandeRum/multiROC
# get response categories as one hot encoded-tibble
# naming with multiROC::multi_roc is really finicky
# column names cannot have dots and must end with 
# "_true" for the observed data and "_pred_xx" 
# for the predicted data, where "_xx" is a method (like 
# 'mn' for multinomial or 'rf' for random forest)
# (
model.matrix(~0 + build_dins_binary$damage_cat) %>% # one hot encoding trick
  as_tibble() %>% #glimpse()
  mutate_all(., ~as.integer(.)) %>% 
  rename_all(., ~str_remove_all(., "build_dins_binary\\$damage_ca")) %>%
  rename_all(., ~paste0(., '_true')) %>%
  bind_cols(., predict_cf_dins_binary_prob %>% 
              map(.x, .f = as_tibble) %>% 
              bind_rows() %>% 
              rename_all(~str_remove_all(., 'damage_cat.')) %>% 
              rename_all(~paste0(., '_pred_cf'))
  ) %>% 
  data.frame() -> class_test_build_dins_binary

class_test_build_dins_binary %>% names
class_test_build_dins_binary %>% glimpse



roc_res <- multiROC::multi_roc(class_test_build_dins_binary, force_diag=TRUE)
plot_roc_df <- multiROC::plot_roc_data(roc_res)




# roc_res$AUC
(auc <- tibble(variable             = roc_res$AUC$cf %>% names()
               , multinomial_reg     =     roc_res$AUC$cf %>% unlist()
               # , multinomial_reg_idw = roc_res_idw$AUC$MNi %>% unlist()
               # , random_forest       =     roc_res$AUC$RFc %>% unlist()
               # , random_forest_idw   = roc_res_idw$AUC$RFi %>% unlist()
) #%>% mutate_if(is.double, round, 2)
  # arrange(desc(multinomial_reg))
)

auc %>% View()



# AUC contains a list of AUC for each group of different classifiers. Micro-average ROC-AUC was calculated by stacking all groups together, thus converting the multi-class classification into binary classification. Macro-average ROC-AUC was calculated by averaging all groups results (one vs rest) and linear interpolation was used between points of ROC.

# (
#   roc_all <- plot_roc_df %>% 
#     bind_rows(plot_roc_df_idw) %>% 
#     ggplot(aes(x = 1-Specificity, y = Sensitivity)) +
#     geom_path(aes(color = Group, linetype=Method), size = 1) + # , alpha = .5) +
#     geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1), 
#                           colour='grey', linetype = 'dotdash') +
#     scale_y_continuous(expand = c(0, 0)) +
#     scale_x_continuous(expand = c(0, 0)) +
#     theme_bw() + 
#     theme(plot.title = element_text(hjust = 0.5), 
#                    legend.justification=c(1, 0), legend.position=c(.95, .05),
#                    legend.title=element_blank(), 
#                    legend.background = element_rect(fill=NULL, size=0.5, 
#                                                              linetype="solid", colour ="black")) + 
#     coord_fixed() + 
#     # facet_wrap(~Method) + 
#     NULL
# )

# ggsave(paste0(getwd(), '/figs/roc_all_', Sys.Date(), '.png')
#        , width = 6.5, height = 6.5)

(
  roc_all_facet <- plot_roc_df %>%
    ggplot(aes(x = 1-Specificity, y = Sensitivity)) +
    geom_path(aes(color = Group, linetype=Method), size = 1) + # , alpha = .5) +
    geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1),
                 colour='grey', linetype = 'dotdash') +
    scale_y_continuous(expand = c(0, 0)) +
    scale_x_continuous(expand = c(0, 0)) +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5),
          # legend.justification=c(1, 0), legend.position=c(.95, .05),
          legend.title=element_blank(),
          legend.background = element_rect(fill=NULL, size=0.5,
                                           linetype="solid", colour ="black")) +
    coord_fixed() +
    facet_wrap(~Method) +
    NULL
)

# ggsave(paste0(getwd(), '/figs/roc_all_facet_', Sys.Date(), '.png')
#        , width = 6.5, height = 6.5)

```



### C spatial autocorrelation in random forest models
```{r}

# we have predictions from four models, and hence can get four residuals
predict_cf_no_dins_prob    # no dins, without lat/long predictors
predict_cf_no_dins_prob_ll # no dins, WITH lat/long predictors

# predict_cf_dins_binary_probs <- predict(cf_dins_binary, type = 'prob') # no lat/long
predict_cf_dins_binary_probs
predict_cf_dins_binary_probs_ll # DINS, WITH lat/long predictions


# get residuals for model with and without lat long as predictors 
(spat_resids <- 
  build_no_dins |> 
  tibble() |> 
  select(ID_Build, damage_binary) |> 
  left_join(build_gis, by = 'ID_Build') |>               # make spatial
  st_as_sf() |> 
  bind_cols(
    predict_cf_no_dins_prob |> 
      unlist() |> 
      tibble() |> 
      select(pred_prob_dest = `unlist(predict_cf_no_dins_prob)`) |> 
      mutate(row = rep(1: 10901, each = 2)) |> # pay attention, a little dangerous.
      group_by(row) |> 
      slice(1) |> 
      ungroup() |> 
      select(pred_prob_dest)
    # ,
    #   
    #   predict_cf_no_dins_prob_ll |> 
    #   unlist() |> 
    #   tibble() |> 
    #   select(pred_prob_dest_ll = `unlist(predict_cf_no_dins_prob_ll)`) |> 
    #   mutate(row = rep(1: 10901, each = 2)) |> # pay attention, a little dangerous.
    #   group_by(row) |> 
    #   slice(1) |> 
    #   ungroup() |> 
    #   select(pred_prob_dest_ll)
    ) |> 
  # mutate(resid = damage_binary - pred_prob_dest)) # NOT CORRECT
  # https://stats.stackexchange.com/questions/166585/pearson-vs-deviance-residuals-in-logistic-regression
  # sign(y-pred_p) * ifelse(y==1,sqrt(-2*log(pred_p)),sqrt(-2*log(1-pred_p)))
  mutate(deviance_residuals = sign(damage_binary - pred_prob_dest) * ifelse(damage_binary == 1
                                                                            , sqrt(-2*log(pred_prob_dest))
                                                                            , sqrt(-2*log(1-pred_prob_dest)))
         # , 
         # deviance_residuals_ll = sign(damage_binary - pred_prob_dest_ll) * ifelse(damage_binary == 1
         #                                                                    , sqrt(-2*log(pred_prob_dest_ll))
         #                                                                    , sqrt(-2*log(1-pred_prob_dest_ll)))
         )
)
      


# MORANS I OF RESIDUALS  
spat_resids |> 
  st_drop_geometry() |>
  select(ID_Build, starts_with('deviance')) |> 
  pivot_longer(-ID_Build) |> 
  ggplot(aes(value)) + 
  geom_histogram() + 
  facet_wrap(~name)
  
# spat_resids |> mapview::mapview(zcol = 'deviance_residuals')

spat_resids <- 
  spat_resids |> 
  mutate(
      nbs = sfdep::st_knn(sf::st_geometry(Shape), 5)
    , wts = sfdep::st_weights(nbs, style = 'W', allow_zero = TRUE)
    )


(global_mi_test <- global_moran_test(spat_resids$deviance_residuals, spat_resids$nbs, spat_resids$wts))
(global_mi_perm <- global_moran_perm(spat_resids$deviance_residuals, spat_resids$nbs, spat_resids$wts))

(global_mi_test <- global_moran_test(spat_resids$deviance_residuals_ll, spat_resids$nbs, spat_resids$wts))
(global_mi_perm <- global_moran_perm(spat_resids$deviance_residuals_ll, spat_resids$nbs, spat_resids$wts))


# # THANKS Todd Hawbaker
# The basic idea was to sample model residuals (deviance for logistic regression), then fit and plot a variogram to the residuals.  Then fit 2 gls models to the residuals.  The first gls model is an intercept only model.  The second is also an intercept only model, but with spatial correlation structure added.  We determine if the spatial correlation is significant with an anova test between the models.

##########
# plot variogram for a given model and data
#   object = glm model object
#   x = dataframe with x and y coordinates
#   nsub = number of samples
#   maxd = maximum distance
##########
fit_and_plot_variogram <- function(object, x, nsub=1000, maxd=50) {
     resid <- residuals(object, type="deviance")

     # put the residuals into a grid or two dimmensional matrix
     resid_xy <- cbind(resid, x$x/1000, x$y/1000)

     # subsample residuals
     n<-length(resid)
     samp_res_xy <- resid_xy[ sample( seq(1,n),size=nsub ), ]
     colnames(samp_res_xy) <- c("resid","x","y")
     
     geo_resids <- as.geodata(samp_res_xy, coords.col = 2:3, data.col = 1)

     # plot a variogram of the deviance residuals
     geo_resid_var <- variog(geo_resids, uvec=50, max.dist=maxd)
     yplus <- geo_resid_var$v+1.96*sqrt(2)*geo_resid_var$v/sqrt(geo_resid_var$n)
     yminus <- geo_resid_var$v-1.96*sqrt(2)*geo_resid_var$v/sqrt(geo_resid_var$n)
     plot.variogram(geo_resid_var, main = "Deviance Residuals with Error Bars",xlim=c(0,maxd))
     errbar(geo_resid_var$u, geo_resid_var$v, yplus, yminus, add=T)
     
     # new code as of July 16th, 2008
     # fit intercept only model to residuals
     m1 <- gls(resid ~ 1,data=as.data.frame(samp_res_xy))
     
     # fit intercept + spatial errors
     m2 <- gls(resid ~ 1,data=as.data.frame(samp_res_xy),corr=corSpher(form=~x+y,nugget=T))
     
     # determine if the spatial model was an improvement over the non-spatial model
     aa <- anova(m1,m2)
     
     return(aa[2,"p-value"])
}

library(geoR) # for variog function
maxd <- 50

# put the residuals into a grid or two dimmensional matrix
resid_xy <- 
  spat_resids |> 
  st_centroid() %>% # get building centroids
  cbind(., st_coordinates(.)) %>%
  st_drop_geometry() |> 
  mutate(x = X / 1000, y = Y / 1000) |> 
  select(resid = deviance_residuals, x, y)

# resid_xy <- 
#   spat_resids |> 
#   st_centroid() %>% # get building centroids
#   cbind(., st_coordinates(.)) %>%
#   st_drop_geometry() |> 
#   mutate(x = X / 1000, y = Y / 1000) |> 
#   select(resid = deviance_residuals_ll, x, y) # HAS LAT LONG

# subsample residuals
n <- resid_xy |> nrow()
samp_res_xy <- resid_xy |> sample_n(1000)

geo_resids <- as.geodata(samp_res_xy, coords.col = 2:3, data.col = 1)

# plot a variogram of the deviance residuals
geo_resid_var <- variog(geo_resids, uvec=50, max.dist=maxd)
yplus <- geo_resid_var$v+1.96*sqrt(2)*geo_resid_var$v/sqrt(geo_resid_var$n)
yminus <- geo_resid_var$v-1.96*sqrt(2)*geo_resid_var$v/sqrt(geo_resid_var$n)
# plot.variogram(geo_resid_var, main = "Deviance Residuals with Error Bars",xlim=c(0,maxd))
plot(geo_resid_var, main = "Deviance Residuals with Error Bars",xlim=c(0,maxd))
Hmisc::errbar(geo_resid_var$u, geo_resid_var$v, yplus, yminus, add=T)


# new code as of July 16th, 2008
     # fit intercept only model to residuals
     m1 <- nlme::gls(resid ~ 1,data=as.data.frame(samp_res_xy))
     
     # fit intercept + spatial errors
     m2 <- nlme::gls(resid ~ 1,data=as.data.frame(samp_res_xy),corr = nlme::corSpher(form=~x+y,nugget=T))
     
     # determine if the spatial model was an improvement over the non-spatial model
     (aa <- anova(m1,m2))
     
     # return(aa[2,"p-value"])


# again for DINS
# get residuals for model with and without lat long as predictors 
(spat_resids_dins <- 
  build_dins |> 
  tibble() |> 
  select(ID_Build, damage_binary) |> 
  left_join(build_gis, by = 'ID_Build') |>               # make spatial
  st_as_sf() |> 
  bind_cols(
    predict_cf_dins_binary_probs |> 
      unlist() |> 
      tibble() |> 
      select(pred_prob_dest = `unlist(predict_cf_dins_binary_probs)`) |> 
      mutate(row = rep(1: 1485, each = 2)) |> # pay attention, a little dangerous.
      group_by(row) |> 
      slice(1) |> 
      ungroup() |> 
      select(pred_prob_dest)
    # ,
    #   
    #   predict_cf_dins_binary_probs_ll |> 
    #   unlist() |> 
    #   tibble() |> 
    #   select(pred_prob_dest_ll = `unlist(predict_cf_dins_binary_probs_ll)`) |> 
    #   mutate(row = rep(1: 1485, each = 2)) |> # pay attention, a little dangerous.
    #   group_by(row) |> 
    #   slice(1) |> 
    #   ungroup() |> 
    #   select(pred_prob_dest_ll)
    ) |> 
  # mutate(resid = damage_binary - pred_prob_dest)) # NOT CORRECT
  # https://stats.stackexchange.com/questions/166585/pearson-vs-deviance-residuals-in-logistic-regression
  # sign(y-pred_p) * ifelse(y==1,sqrt(-2*log(pred_p)),sqrt(-2*log(1-pred_p)))
  mutate(deviance_residuals = sign(damage_binary - pred_prob_dest) * ifelse(damage_binary == 1
                                                                            , sqrt(-2*log(pred_prob_dest))
                                                                            , sqrt(-2*log(1-pred_prob_dest)))
         # , 
         # deviance_residuals_ll = sign(damage_binary - pred_prob_dest_ll) * ifelse(damage_binary == 1
         #                                                                    , sqrt(-2*log(pred_prob_dest_ll))
         #                                                                    , sqrt(-2*log(1-pred_prob_dest_ll)))
         )
)
      


# put the residuals into a grid or two dimmensional matrix
resid_xy_dins <- 
  spat_resids_dins |> 
  st_centroid() %>% # get building centroids
  cbind(., st_coordinates(.)) %>%
  st_drop_geometry() |> 
  mutate(x = X / 1000, y = Y / 1000) |> 
  select(resid = deviance_residuals, x, y)

# subsample residuals
n <- resid_xy_dins |> nrow()
samp_res_xy_dins <- resid_xy_dins |> sample_n(1000)

geo_resids <- as.geodata(samp_res_xy_dins, coords.col = 2:3, data.col = 1)

# plot a variogram of the deviance residuals
geo_resid_var <- variog(geo_resids, uvec=50, max.dist=maxd)
yplus <- geo_resid_var$v+1.96*sqrt(2)*geo_resid_var$v/sqrt(geo_resid_var$n)
yminus <- geo_resid_var$v-1.96*sqrt(2)*geo_resid_var$v/sqrt(geo_resid_var$n)
# plot.variogram(geo_resid_var, main = "Deviance Residuals with Error Bars",xlim=c(0,maxd))
plot(geo_resid_var, main = "Deviance Residuals with Error Bars",xlim=c(0,maxd))
Hmisc::errbar(geo_resid_var$u, geo_resid_var$v, yplus, yminus, add=T)


# new code as of July 16th, 2008
     # fit intercept only model to residuals
     m1 <- nlme::gls(resid ~ 1,data=as.data.frame(samp_res_xy))
     
     # fit intercept + spatial errors
     m2 <- nlme::gls(resid ~ 1,data=as.data.frame(samp_res_xy),corr = nlme::corSpher(form=~x+y,nugget=T))
     
     # determine if the spatial model was an improvement over the non-spatial model
     (aa <- anova(m1,m2))
     
     # return(aa[2,"p-value"])
     
```


## 4 variable importance

```{r}
# # modified from first chunk here:
# # https://bgreenwell.github.io/pdp/articles/pdp.html#other-vignettes
# # Variable importance plot (compare to randomForest::varImpPlot(boston_rf))
# vip(boston_rf, bar = FALSE, horizontal = FALSE, size = 1.5)  # Figure 1

# # variable importance plot with random forest; fast
# vip_rf_no_dins <- vip(rf_no_dins
#     # , bar = FALSE       # doesn't seem to work "help(vip)" showed that it changed to "geom"
#     # , geom = 'point'    # try "col" instead
#     , geom = 'col'      # try "point" instead
#     , horizontal = TRUE # vignette example had this as FALSE (label easier rotated)
#     # , size = 1.5        # plausibly pertains to point size
#     # see "num_features"
#     # "Integer specifying the number of variable importance scores to plot. Default is 10."
#     ) + 
#   theme_bw(16)          # added some flare (ok just bigger axis text and black/white theme)
# 
# # check the plot
# vip_rf_no_dins



# if we want to use color/shapes or facets to indicate the variable TYPE
# like we did with the cforest object before, it looks like vip::vi can be used
# to calculate the variable importance scores, then we can re-purpose the old
# code to add the colors symbols, etc.. . 'help(vip)' has an example starting with 
# "# Better yet, store the variable importance scores and then plot
# # vi_scores <- vi(model, method = "firm")". That's how I learned to extract importance
# from randomForest::randomForest models

# # since the second one takes 10 minutes, this code is commented out. Instead of re-running, just read a *.csv backin
# # not sure about this scaling. When scale is FALSE the values are on totally different scales
# # `rank = TRUE`
# tic(); vi_cf_no_dins <- vi(cf_no_dins, scale = TRUE) %>% mutate(Model = 'cf_no_dins', n_tree = n_tree); toc() # 10 mins (actualy around 4 mins)
# tic(); vi_cf_dins    <- vi(cf_dins,    scale = TRUE) %>% mutate(Model =    'cf_dins', n_tree = n_tree); toc() # 1 min
# tic(); vi_cf_dins_binary<- vi(cf_dins_binary,scale = TRUE) %>% mutate(Model =    'cf_dins_binary', n_tree = n_tree); toc() # 1 min


# bind_rows(vi_cf_no_dins
#           , vi_cf_dins
#           , vi_cf_dins_binary) %>% # combines variable importance from each model
#     write_csv(., paste0(getwd(), '/output_data/variable_importance_', Sys.Date(), '.csv'))

# # now that we have updated the deviance explained with the new data, we have a new table
# # but that new table doesn't have the hand-created
# # so we fold those back in here
(old_labs <- read_csv(paste0(getwd(), '/data/Table_Deviance_Explained_2022-03-08.csv')) %>%
  tidylog::select(Variable = `Variable name`, Label, Type))


(variable_importance <- 
    read_csv('output_data/variable_importance_2023-02-03.csv') |> 
    group_by(Model) |> 
    mutate(rank = row_number(Model)) |> 
    ungroup() |> 
    left_join(old_labs, by = 'Variable')
  )

# 
# 
# # reading back in deviance explained
# (tab_labs <- 
#   # read_csv(paste0(getwd(), '/data/Table_Deviance_Explained_2022-03-08.csv')) %>%
#    # read_csv(paste0(getwd(), '/data/Table_Deviance_Explained_2022-06-13.csv')) %>%
#     read_csv(paste0(getwd(), '/data/Table_Deviance_Explained_2023-01-01.csv')) %>%
#    mutate(Type = fct_recode(factor(Type), 
#                               Exposure               = 'EXP'
#                             , Construction           = 'CON'
#                             , 'Defensible Space'     = 'DEF'
#                             , 'Landscape Attributes' = 'LAND'
#                             , Topography             = 'TOPO')
#           )
#  ) 
#  
# 
# # join in aliases and type, repurpose directly below.
#  #MHM -3/23/2022 - let's hold off on displaying scale in variable importance plots until we talk more w alex, I think theme is somewhat repeating this information and would like her take
# (
#   variable_importance <- read_csv(paste0(getwd()
#                                          # , '/data/variable_importance_2022-03-29.csv')) %>% 
#                                          # , '/output_data/variable_importance_2022-05-20.csv')) %>% 
#                                          , '/output_data/variable_importance_2022-06-13.csv')) %>% 
#     group_by(Model) %>% 
#     mutate(rank = row_number(Model)) %>% 
#     ungroup() %>%  
#     left_join(
#       tab_labs  %>%  tidylog::select(Variable = `Variable name`
#                                   , Alias #, Label
#                                   , Type
#                                   , Scale)
#       , by = 'Variable') %>% 
#     left_join(old_labs, by = 'Variable') %>% # is this join ok with one-extra row in the y table?
#     mutate(Variable = factor(Variable))
#   )


```


### A compare RForests and Uni- top 20 variables

Why are we doing this?
```{r eval=FALSE, include=FALSE}

# take variable_importance rank of 20 or higher
# assumes variable_importance already in, section 4 above run
# assumes already read in 
tab_labs2 <- 
# read_csv(paste0(getwd(), '/data/Table_Deviance_Explained_2022-06-13.csv'))
  read_csv(paste0(getwd(), '/data/Table_Deviance_Explained_2023-01-01.csv'))


top_n <- 20         # set n (can revise to 20 or any other value greater than zero and less than 71)
top_n <- 21         # we now only have 21.. so 

variable_importance %>% 
  group_by(Model) %>%
  filter(rank <= top_n) %>% 
  filter(Model != 'cf_dins_binary') %>% 
  tidylog::select(Variable, Model, Label, Type)  -> top_pdp

tab_labs2 %>% 
  mutate(Type = fct_recode(factor(Type), 
                              Exposure               = 'EXP'
                            , Construction           = 'CON'
                            , 'Defensible Space'     = 'DEF'
                            , 'Landscape Attributes' = 'LAND'
                            , Topography             = 'TOPO')
          ) %>% 
  mutate(Model = "Univariate") %>%  
  rename(Variable= 'Variable name')  %>% 
  arrange(desc(Deviance)) %>% 
  slice(1:top_n) %>% 
  tidylog::select(Variable, Model, Alias, Type) ->top_uni

bind_rows(top_pdp, top_uni) -> top_vars

table(top_vars$Type) #checking on, types are all correct
table(top_vars$Model) #checking on, retains top 20 from each


top_vars %>% 
  ungroup() %>% # just because it was stil grouped.. not needed.
  arrange(Model) %>% # cosmetic, helps with debugging, not really needed
  tidylog::select(Type, Variable, Alias, Model) %>% # reorder to match example below
  group_by(Variable) %>%
  mutate(count = n()) %>% # add count
  ungroup() %>%
  pivot_wider(names_from = Model, values_from = Model) %>%
  # mutate(models = paste0(cf_dins cf_no_dins Univariate, ))
  unite(cf_dins, cf_no_dins, Univariate, col = 'Models', sep = ', ')  %>%  
  mutate(Models = str_remove_all(Models, ', NA')
         , Models = str_remove_all(Models, 'NA, ')) %>% 
  arrange(Type,desc(count)) ->top_vars_group

top_vars_group %>%
   write_csv(., paste0(getwd(), '/output_data/top_vars_group_', Sys.Date(), '.csv')) #output_data/top_vars_group_2022-07-07.csv


```
### B compare DINS - class vs binary

```{r eval=FALSE, include=FALSE}
#compare variable importance outcomes for two ways of considering DINS outcomes - 
# DINS RF with binary outcome and categorial outcome
# 3/20/2022 - Dexter, I   compared the variable importance (top 20 variables, importance scores) for both DINS outcomes (binary, categorical) in section 4A. Because the outcomes are so similar I want to keep DINS as binary outcome - I think it's easier for descriptive figures and the reader, and it's keeping story simpler overall
#first, are same variables listed in top 20? #for most part, yes
variable_importance %>% 
  filter (rank <21)  %>% 
  filter (Model=='cf_dins' | Model== 'cf_dins_binary')  %>% 
      add_count(Variable) %>% 
        filter (n==1) 
#for the most part- there are two variables in top 2 for each model that are unique to that model
#cf_dins - categorial outcome includes  parcel_Paved_P & parcel_year_built but cf_dins_binary - binary outcome does not
#cf_dins_binary - binary outcome includes build_PATIOCOVER and build_p_building_2000 but cf_dins - categorial outcome does not
#second, are variable importances correlated?
#yes, highly correlated
variable_importance %>% 
 filter (Model=='cf_dins' | Model== 'cf_dins_binary') %>%
      dplyr::select(Variable, Importance, Model) %>% 
        pivot_wider(
          names_from = "Model",
          values_from = "Importance") ->Imp_wide
 
ggscatter(Imp_wide, x = "cf_dins", y = "cf_dins_binary", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Imp_cf_bins - Category", ylab = "Imp_cf_dins - Binary")
```


### C graph variable importance
```{r}
variable_importance %>% 
  tabyl(Model)

(
  variable_importance %>% 
    filter(Model == 'cf_no_dins') %>% 
    # filter(rank < 21) %>% # we have 21 now, totall. Cutting at 20 now seems strange. 
    ggplot(aes(  
        x = `Importance`
      , y = reorder(Label, `Importance`)
      , fill = Type
      )) +
    # geom_point(aes(shape = Type)) +
    geom_col() + 
    theme_bw(16) +
    # scale_fill_viridis_d(option = "A", end = .8, begin = .1) +
    scale_fill_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
      ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
      )
      , drop = FALSE
    ) +
    scale_x_continuous(expand = c(0, 0), limits = c(0, 101)) + 
    theme(axis.ticks.y = element_blank()) + 
    theme(legend.position = "bottom",
          legend.justification = "left",
          plot.title.position = "plot",
          plot.caption = element_text(hjust=0),
          plot.caption.position = "plot") + 
    labs(
        title = 'Variable Importance Scores for Random Forest with no DINS variables (n = 10,901)'
      , y = '') + 
    NULL -> a_importance_graph_no_dins
  )

(
  variable_importance %>% 
    filter(Model == 'cf_dins_binary') %>% 
    filter(rank < 21) %>% # we have 31 now, total. Cut at 20
    ggplot(aes(  
        x = `Importance`
      , y = reorder(Label, `Importance`)
      , fill  = Type
      )) +
    # geom_point(aes(shape = Type)) +
    geom_col() + 
    scale_y_discrete(drop=FALSE) + 
    # scale_fill_brewer(palette = 'Dark2') + 
    scale_fill_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
       ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
        )
      , drop = FALSE
      ) +
    scale_x_continuous(expand = c(0, 0), limits = c(0, 101)) + 
    theme_bw(16) +
    theme(axis.ticks.y = element_blank()) + 
    theme(legend.position = "bottom",
          legend.justification = "left",
          plot.title.position = "plot",
          plot.caption = element_text(hjust=0),
          plot.caption.position = "plot") + 
    labs(
        title = 'Variable Importance Scores for Random Forest with DINS variables (n = 1,487)'
      , y = '') + 
    NULL -> a_importance_graph_dins
  )

```

## 5 partial dependence plots

### A base-style graphs (example only)

```{r eval=FALSE, include=FALSE}
# single base-graphics partial dependency plot, modeled after Figure 2 here:
# https://bgreenwell.github.io/pdp/articles/pdp.html#other-vignettes
# partialPlot(boston_rf, pred.data = boston, x.var = "lstat")  # Figure 2
randomForest::partialPlot(rf_no_dins
                          , pred.data = build_no_dins
                          , x.var = "build_near_dest"
                          ) # ugly!
```

### B ggplot graphs

#### i test on a single predictor

```{r eval=FALSE, include=FALSE}
# # building off of the third chunk from
# # https://bgreenwell.github.io/pdp/articles/pdp.html#other-vignettes
# # AND third chunk from this vignette
# # https://bgreenwell.github.io/pdp/articles/pdp-computation.html
# # Switch to ggplot2
# p2 <- partial(boston_rf, pred.var = "lstat", plot = TRUE,
#               plot.engine = "ggplot2")

# THIS IS A SINGLE VARIBLE TEST
pdp::partial(rf_no_dins                      # random forest model
             , pred.var = "build_near_dest"  # predictor variable
             , plot = TRUE                   # if FALSE returns prediction data
             , plot.engine = "ggplot2"       # plot with ggplot2 or not?
             , rug = TRUE                    # adds the univariate y-axis summary (aka "rug")
             , progress = "text"             # prints progress, sets users expectations
             , quantiles = TRUE              # see help(pdp)
             , probs = 0:20/20               # probabilities, "0:20/20" gives 5% increments
             , ice = TRUE                    # Individual Conditional Expectations
             , center = TRUE                 # for graphical layout, pertains to ice
             , alpha = .1                    # line transparency
             ) + 
  theme_bw(16) +                             # ggplot adjustment for black/white & large text size 
  # scale_y_continuous(expand = c(0, 0)) +
  NULL -> test_pdp                           # makes the plot

test_pdp # accesses plot

variable <- "build_near_dest"
ggsave(file = paste0(getwd(), '/figures/cf_dins/', variable, '_', Sys.Date(), '.png')
       , width = 6.5*2
       , height = 6.5*1.5
       , dpi = 100)
```

#### ii non-DINS RF

```{r}
# TODO? naw
```

#### iii non-DINS CF
```{r eval=FALSE, include=FALSE}
# TODO Miranda, we can look at all plots, but maybe we just want to look at the top 10 or 20 top predictors
#2/23/22 Dexter I think top 10 seems fine, the Price MS only shows several in final MS.
## CF non-DINS
# loop through predictors to get PDP
# first get the iterator, here the variable names

# # testing on smaller model
# n_tree<- 500
# tic(); cf_no_dins <- party::cforest(
#   damage_cat ~ .
#   , data = build_no_dins # notice no drop_na here
#   , controls =
#     cforest_control(
#         mtry = 5
#       , ntree = n_tree # 10 ~2 seconds, 100 ~25s, 200 ~50s, 300 ~75s ... 500 ~130 seconds
#       , mincriterion = 0
#       )
#   ); toc() # ~2 mins with n_tree = 500

# using ALL predictors
(pdp_cf_no_dins_vars <- variable_importance %>% filter(Model == 'cf_no_dins') %>%                 pull(Variable))

# using top n predictors
top_n <- 9         # set n (can revise to 20 or any other value greater than zero and less than 71)
(pdp_cf_no_dins_vars <- variable_importance %>% filter(Model == 'cf_no_dins') %>% slice(1:top_n) %>% pull(Variable)) 


# detectCores(); # detect the number of cores of your cpu
# split <- 10
# 
# 
# cl<-makeCluster(split);
# registerDoParallel(cl);
# start.time = proc.time(); 
# 
# tic()
# pdp::partial(cf_no_dins               # the model
#              , pred.var = 'build_near_dest'
#              , plot = FALSE
#              # , plot.engine = "ggplot2"
#              # , rug = TRUE
#              # , progress = "text"
#              , quantiles = TRUE
#              , probs = 0:20/20
#               , ice = TRUE
#              # , center = TRUE
#              # , alpha = .1
#              , parallel = TRUE
#              ) %>% 
#   as_tibble() %>% 
#   group_by(build_near_dest) %>% 
#   summarise(ci = list(mean_cl_normal(yhat))) %>% 
#   unnest(ci) %>% 
#   rename(mean_pred = y, lower_ci = ymin, upper_ci = ymax) -> build_near_dest_pdp; toc(); stopCluster(cl) # ~1hr 10 mins (10 cores)

# 1
detectCores(); # detect the number of cores of your cpu
split <- 10


tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'build_near_dest'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) %>% 
  as_tibble() %>% 
  group_by(build_near_dest) %>% 
  summarise(ci = list(mean_cl_normal(yhat))) %>% 
  unnest(ci) %>% 
  rename(x = build_near_dest) %>% 
  mutate(iv = 'build_near_dest') %>% 
  write_csv(paste0(getwd(), '/output_data/pdp/build_near_dest_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~1 hr 15 mins w 10 cores, 95 mins w 8 cores




pdp_cf_no_dins_vars %>% tabyl()

 

# 2
tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'build_area'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) %>% 
  as_tibble() %>% 
  group_by(build_area) %>% 
  summarise(ci = list(mean_cl_normal(yhat))) %>% 
  unnest(ci) %>% 
  rename(x = build_area) %>% 
  mutate(iv = 'build_area') %>% 
  write_csv(paste0(getwd(), '/output_data/pdp/build_area_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~1 hr 13 mins, ~1.5 hr w 9 cores






# 3
tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'parcel_Build_P'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) %>% 
  as_tibble() %>% 
  group_by(parcel_Build_P) %>% 
  summarise(ci = list(mean_cl_normal(yhat))) %>% 
  unnest(ci) %>% 
  rename(x = parcel_Build_P) %>% 
  mutate(iv = 'parcel_Build_P') %>% 
  write_csv(paste0(getwd(), '/output_data/pdp/parcel_Build_P_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~1 hr 20 mins, 1:30 with 10
 
 
   

 
# 4
tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'build_p_otherpaved_300'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) %>% 
  as_tibble() %>% 
  group_by(build_p_otherpaved_300) %>% 
  summarise(ci = list(mean_cl_normal(yhat))) %>% 
  unnest(ci) %>% 
  rename(x = build_p_otherpaved_300) %>% 
  mutate(iv = 'build_p_otherpaved_300') %>% 
  write_csv(paste0(getwd(), '/output_data/pdp/build_p_otherpaved_300_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~1 hr 20 mins; ~1 hr 25 10 cores
 
 
 
 
 
 
 
# 5 
tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'build_Mean_builddens'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) %>% 
  as_tibble() %>% 
  group_by(build_Mean_builddens) %>% 
  summarise(ci = list(mean_cl_normal(yhat))) %>% 
  unnest(ci) %>% 
  rename(x = build_Mean_builddens) %>% 
  mutate(iv = 'build_Mean_builddens') %>% 
  write_csv(paste0(getwd(), '/output_data/pdp/build_Mean_builddens_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~1 hr 18 mins; ~1 hr with 12 cores
   
   

 
# 6    
 tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'build_Mean_distroad'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) %>% 
  as_tibble() %>% 
  group_by(build_Mean_distroad) %>% 
  summarise(ci = list(mean_cl_normal(yhat))) %>% 
  unnest(ci) %>% 
  rename(x = build_Mean_distroad) %>% 
  mutate(iv = 'build_Mean_distroad') %>% 
  write_csv(paste0(getwd(), '/output_data/pdp/build_Mean_distroad_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~1 hr 18 mins; ~1 hr with 12 cores

 
 

# 7 
 tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'build_Mean_elev_30m'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) %>% 
  as_tibble() %>% 
  group_by(build_Mean_elev_30m) %>% 
  summarise(ci = list(mean_cl_normal(yhat))) %>% 
  unnest(ci) %>% 
  rename(x = build_Mean_elev_30m) %>% 
  mutate(iv = 'build_Mean_elev_30m') %>% 
  write_csv(paste0(getwd(), '/output_data/pdp/build_Mean_elev_30m_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~53 mins, 12 cores
 

 
 
 
   

# 8
tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'build_p_grass_300'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) %>% 
  as_tibble() %>% 
  group_by(build_p_grass_300) %>% 
  summarise(ci = list(mean_cl_normal(yhat))) %>% 
  unnest(ci) %>% 
  rename(x = build_p_grass_300) %>% 
  mutate(iv = 'build_p_grass_300') %>% 
  write_csv(paste0(getwd(), '/output_data/pdp/build_p_grass_300_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~1 hr 12 mins w 10 cores, 50 mins 13 cores
 
#  
#  
#  
# tic()
# 
# cl<-makeCluster(split);
# registerDoParallel(cl);
# start.time = proc.time(); 
# 
# pdp::partial(cf_no_dins               # the model
#            , pred.var = 'build_Mean_elev_30m'
#            , plot = FALSE
#            # , plot.engine = "ggplot2"
#            # , rug = TRUE
#            # , progress = "text"
#            , quantiles = TRUE
#            , probs = 0:20/20
#            , ice = TRUE
#            , center = TRUE
#            # , alpha = .1
#            , parallel = TRUE
#            ) %>% 
#   as_tibble() %>% 
#   group_by(build_Mean_elev_30m) %>% 
#   summarise(ci = list(mean_cl_normal(yhat))) %>% 
#   unnest(ci) %>% 
#   rename(x = build_Mean_elev_30m) %>% 
#   mutate(iv = 'build_Mean_elev_30m') %>% 
#   write_csv(paste0(getwd(), '/output_data/pdp/build_Mean_elev_30m_', Sys.Date(), '.csv'))
# 
#  stopCluster(cl); toc(); beepr::beep() # ~1 hr 45 mins, 1 hr 15 mins with 10 cores
#  
#  
#  
  


 
# tic()
# 
# cl<-makeCluster(split);
# registerDoParallel(cl);
# start.time = proc.time(); 
# 
# pdp::partial(cf_no_dins               # the model
#            , pred.var = 'parcel_Can_P'
#            , plot = FALSE
#            # , plot.engine = "ggplot2"
#            # , rug = TRUE
#            # , progress = "text"
#            , quantiles = TRUE
#            , probs = 0:20/20
#            , ice = TRUE
#            , center = TRUE
#            # , alpha = .1
#            , parallel = TRUE
#            ) %>% 
#   as_tibble() %>% 
#   group_by(parcel_Can_P) %>% 
#   summarise(ci = list(mean_cl_normal(yhat))) %>% 
#   unnest(ci) %>% 
#   rename(x = parcel_Can_P) %>% 
#   mutate(iv = 'parcel_Can_P') %>% 
#   write_csv(paste0(getwd(), '/output_data/pdp/parcel_Can_P_', Sys.Date(), '.csv'))
# 
#  stopCluster(cl); toc(); beepr::beep() # ~53 mins, 12 cores
#  
#  
#  
#  
#  
# tic()
# 
# cl<-makeCluster(split);
# registerDoParallel(cl);
# start.time = proc.time(); 
# 
# pdp::partial(cf_no_dins               # the model
#            , pred.var = 'build_p_otherpaved_300'
#            , plot = FALSE
#            # , plot.engine = "ggplot2"
#            # , rug = TRUE
#            # , progress = "text"
#            , quantiles = TRUE
#            , probs = 0:20/20
#            , ice = TRUE
#            , center = TRUE
#            # , alpha = .1
#            , parallel = TRUE
#            ) %>% 
#   as_tibble() %>% 
#   group_by(build_p_otherpaved_300) %>% 
#   summarise(ci = list(mean_cl_normal(yhat))) %>% 
#   unnest(ci) %>% 
#   rename(x = build_p_otherpaved_300) %>% 
#   mutate(iv = 'build_p_otherpaved_300') %>% 
#   write_csv(paste0(getwd(), '/output_data/pdp/build_p_otherpaved_300_', Sys.Date(), '.csv'))
# 
#  stopCluster(cl); toc(); beepr::beep() # ~53 mins, 12 cores

 
```

#### iv DINS CF

```{r eval=FALSE, include=FALSE}
# TODO Miranda, we can look at all plots, but maybe we just want to look at the top 10 or 20 top predictors
#2/23/22 Dexter I think top 10 seems fine, the Price MS only shows several in final MS.

## CF DINS #these are categorical outcomes, 4/4/2022, let's replace with next section with binary outcomes
# loop through predictors to get PDP
# first get the iterator, here the variable names

# using ALL predictors
(pdp_cf_dins_vars <- variable_importance %>% filter(Model == 'cf_dins') %>%                 pull(Variable))

```

#### v DINS CF - binary outcome
See "calc_pdp.R" as a stand alone script so it couldu be run as background job (while testing spatial autocorrelation)
```{r eval=FALSE, include=FALSE}
# TODO Miranda, we can look at all plots, but maybe we just want to look at the top 10 or 20 top predictors
#2/23/22 Dexter I think top 10 seems fine, the Price MS only shows several in final MS.
#4/5/22 Dexter I ran this with 5 on my computer, just trying not to take too long. 



# using top n predictors
top_n <- 6          # set n (can revise to 20 or any other value greater than zero and less than 71)
(pdp_cf_dins_vars <- variable_importance %>% filter(Model == 'cf_dins_binary') %>% slice(1:top_n) %>% pull(Variable)) 

pdp_cf_dins_vars %>% tibble()

detectCores(); # detect the number of cores of your cpu
split <- 10


tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_dins_binary               # the model
           , pred.var = 'build_WINDOWPANE'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) %>% 
  as_tibble() %>% 
  group_by(build_WINDOWPANE) %>% 
  summarise(ci = list(mean_cl_normal(yhat))) %>% 
  unnest(ci) %>% 
  rename(x_chr = build_WINDOWPANE) %>% 
  mutate(iv = 'build_WINDOWPANE') %>% 
  write_csv(paste0(getwd(), '/output_data/pdp_dins/build_WINDOWPANE_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~45 seconds 500 trees and 10 cores.



 
 
 
 
 
 tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_dins_binary               # the model
           , pred.var = 'build_EAVES'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) %>% 
  as_tibble() %>% 
  group_by(build_EAVES) %>% 
  summarise(ci = list(mean_cl_normal(yhat))) %>% 
  unnest(ci) %>% 
  rename(x_chr = build_EAVES) %>% 
  mutate(iv = 'build_EAVES') %>% 
  write_csv(paste0(getwd(), '/output_data/pdp_dins/build_EAVES_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # 45s





tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_dins_binary               # the model
           , pred.var = 'build_near_dest'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) %>% 
  as_tibble() %>% 
  group_by(build_near_dest) %>% 
  summarise(ci = list(mean_cl_normal(yhat))) %>% 
  unnest(ci) %>% 
  rename(x = build_near_dest) %>% 
  mutate(iv = 'build_near_dest') %>% 
  write_csv(paste0(getwd(), '/output_data/pdp_dins/build_near_dest_', Sys.Date(), '.csv'))

stopCluster(cl); toc(); beepr::beep() # ~90 seconds





tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_dins_binary               # the model
           # , pred.var = 'build_p_otherpaved_200'
           , pred.var = 'build_p_otherpaved_300'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) %>% 
  as_tibble() %>% 
  group_by(build_p_otherpaved_300) %>% 
  summarise(ci = list(mean_cl_normal(yhat))) %>% 
  unnest(ci) %>% 
  rename(x = build_p_otherpaved_300) %>% 
  mutate(iv = 'build_p_otherpaved_300') %>% 
  write_csv(paste0(getwd(), '/output_data/pdp_dins/build_p_otherpaved_300_', Sys.Date(), '.csv'))

stopCluster(cl); toc(); beepr::beep() # ~100s





tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_dins_binary               # the model
           , pred.var = 'build_VENTSCREEN'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) %>% 
  as_tibble() %>% 
  group_by(build_VENTSCREEN) %>% 
  summarise(ci = list(mean_cl_normal(yhat))) %>% 
  unnest(ci) %>% 
  rename(x_chr = build_VENTSCREEN) %>% 
  mutate(iv = 'build_VENTSCREEN') %>% 
  write_csv(paste0(getwd(), '/output_data/pdp_dins/build_VENTSCREEN_', Sys.Date(), '.csv'))

stopCluster(cl); toc(); beepr::beep() # ~45s







# tic()
# 
# cl<-makeCluster(split);
# registerDoParallel(cl);
# start.time = proc.time(); 
# 
# pdp::partial(cf_dins_binary               # the model
#            , pred.var = 'build_min_dist_shrub'
#            , plot = FALSE
#            # , plot.engine = "ggplot2"
#            # , rug = TRUE
#            # , progress = "text"
#            , quantiles = TRUE
#            , probs = 0:20/20
#            , ice = TRUE
#            , center = TRUE
#            # , alpha = .1
#            , parallel = TRUE
#            ) %>% 
#   as_tibble() %>% 
#   group_by(build_min_dist_shrub) %>% 
#   summarise(ci = list(mean_cl_normal(yhat))) %>% 
#   unnest(ci) %>% 
#   rename(x = build_min_dist_shrub) %>% 
#   mutate(iv = 'build_min_dist_shrub') %>% 
#   write_csv(paste0(getwd(), '/output_data/pdp_dins/build_min_dist_shrub_', Sys.Date(), '.csv'))
# 
# stopCluster(cl); toc(); beepr::beep() # ~100s



tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_dins_binary               # the model
           , pred.var = 'build_Mean_distroad'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) %>% 
  as_tibble() %>% 
  group_by(build_Mean_distroad) %>% 
  summarise(ci = list(mean_cl_normal(yhat))) %>% 
  unnest(ci) %>% 
  rename(x = build_Mean_distroad) %>% 
  mutate(iv = 'build_Mean_distroad') %>% 
  write_csv(paste0(getwd(), '/output_data/pdp_dins/build_Mean_distroad_', Sys.Date(), '.csv'))

stopCluster(cl); toc(); beepr::beep() # ~100s


```




#### vi read in PDPs and graph
```{r}

top_n <- 9         # set n (can revise to 20 or any other value greater than zero and less than 71)
(pdp_cf_no_dins_vars <- variable_importance %>% filter(Model == 'cf_no_dins') %>% slice(1:top_n) %>% pull(Variable)) 


pdp_cf_no_dins_vars
pdp_cf_no_dins_vars %>% data_frame()

(
  pdp_cf_no_dins_tibble <- tibble(files = dir('output_data/pdp', full.names = TRUE)) |> 
    filter(files != 'output_data/pdp/dins') %>%
    mutate(file_contents = map(files, ~read_csv(., col_types = cols()))) %>% # col_types = cols() just to be quiet
    unnest(file_contents) %>% 
    select(-files) %>% 
    left_join(variable_importance %>% distinct(iv = Variable, Label, Type)
              , by = 'iv') %>% 
    mutate(Label = factor(
        Label
      , levels = c(
          'Dist. to destroyed building'
        , 'Building area'
        , 'Percent built, parcel'
        , 'Dist. to major road'
        , 'Elevation, 30 m around bldg.'
        , 'Percent paved, 300 ft'
        , 'Other paved, 300 ft'
        , 'Housing density'
        , 'Percent grass, 300 ft'
        , 'Percent tree, 100 ft'
        # , 'Elevation, 100 m around bldg.'
        # , 'Percent slope, 100 m around bldg.'
        # # , 'Elevation, 30 m around bldg.'
        # , 'Percent built, 200 ft'
        # # , 'Percent tree, parcel'
        # # , 'Percent paved, 300 ft'
        )
      , labels = c(
        'Dist. to destroyed building'
        , 'Building area'
        , 'Percent built, parcel'
        , 'Dist. to major road'
        , 'Elevation, 30 m around bldg.'
        , 'Percent paved, 300 ft'
        , 'Other paved, 300 ft'
        , 'Housing density'
        , 'Percent grass, 300 ft'
        , 'Percent tree, 100 ft'
        # , 'Elevation, 100 m\naround bldg.'
        # , 'Percent built,\n300 ft'
        # , 'Slope,\n100 m around bldg.'
        # # , 'Elevation, 30 m\naround bldg.'
        # , 'Percent built, 200 ft'
        # # , 'Percent tree, parcel'
        # # , 'Percent paved, 300 ft'
        )
      , ordered = TRUE)
      ) %>%
    # not really need anymore because we use Label instead
    mutate(iv = factor(iv, levels = pdp_cf_no_dins_vars, labels = pdp_cf_no_dins_vars, ordered = TRUE)) |> 
    droplevels()
  )


pdp_cf_no_dins_tibble %>% tabyl(iv)
pdp_cf_no_dins_tibble %>% tabyl(Label)
# pdp_cf_no_dins_tibble %>% tabyl(x)
bind_cols(pdp_cf_no_dins_tibble %>% tabyl(iv),  
pdp_cf_no_dins_tibble %>% tabyl(Label) |> drop_na())

(
  b_g_build <- pdp_cf_no_dins_tibble %>% 
    ggplot(aes(x, y, fill = Type)) + 
    geom_ribbon(aes(ymin = ymin, ymax = ymax)) +
    # geom_line(color = 'red') + 
    geom_line() + 
    # scale_fill_viridis_d(option = "A", end = .8) + 
    scale_fill_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
        )
      , labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
        )
      , drop = FALSE
    ) +
    geom_hline(yintercept = 0, col = 'dark gray') + 
    theme_bw(16) + 
    labs(y = 'Probability', x = '') + 
    scale_x_continuous(labels = scales::comma_format()) +
    # scale_x_continuous(labels = scales::label_number(suffix = " K", scale = 1e-6)) + # thousands
    theme(legend.position = 'none', axis.text.x = element_text(size = 8.25)) + 
    # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
    # facet_wrap(~str_wrap(Label, 20), scales = 'free_x') +
    facet_wrap(~Label, scales = 'free_x') +
    NULL
  )

library(patchwork)
# a_importance_graph_no_dins / b_g_build
(importance_pdp_1 <- a_importance_graph_no_dins + 
  inset_element(b_g_build , left = 0.17, bottom = 0.03, right = .98, top = .93))
  
# importance_pdp_1 %>%
# ggsave(file = paste0(getwd(), '/figures/importance_pdp_top_9_', Sys.Date(), '.png')
#          , height = 6.5*2, width = 6.5*2)

#   ggsave(file = paste0(getwd(), '/figures/cf_dins_binary/', variable, '_', Sys.Date(), '.png')
#          , width = 6.5*2
#          , height = 6.5*1.5
#          , dpi = resolution)


(pdp_cf_dins_vars <- variable_importance %>% filter(Model == 'cf_dins_binary') %>% slice(1:top_n) %>% pull(Variable)) 

pdp_cf_dins_vars

(
  pdp_cf_dins_tibble <- tibble(files = dir('output_data/pdp_dins', full.names = TRUE)) %>%
    mutate(file_contents = map(files,~read_csv(., col_types = cols()))) %>% #, col_types = 'fdddf'))) %>% 
    # mutate(file_contents = map(files, ~mutate(., ifelse(is.character(.$iv),))))
    unnest(file_contents) %>% 
    select(-files) %>% 
     left_join(variable_importance %>% distinct(iv = Variable, Label, Type)
    # left_join(variable_importance %>% distinct(iv = Variable, Alias, Label, Type)
              , by = 'iv') %>% 
    mutate(iv = factor(iv, levels = pdp_cf_dins_vars, labels = pdp_cf_dins_vars, ordered = TRUE)) 
  )

pdp_cf_dins_tibble %>% tabyl(iv)
pdp_cf_dins_tibble %>% tabyl(Label, iv)
# pdp_cf_no_dins_tibble %>% tabyl(x)



# # great start to graphs!
# pdp_cf_no_dins_tibble %>%
#   filter(is.na(x_chr)) %>%
#   ggplot(aes(x, y)) +
#   geom_ribbon(aes(ymin = ymin, ymax = ymax)) +
#   geom_line(color = 'red') +
#   geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
#   theme_bw(16) +
#   facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
#   NULL
# 
# pdp_cf_no_dins_tibble %>% 
#   filter(!is.na(x_chr)) %>%
#   # ggplot(aes(x_chr, y)) + 
#   ggplot(aes(y, x_chr)) + 
#   # geom_errorbar(aes(ymin = ymin, ymax = ymax), width = .1, size = 1) + 
#   geom_errorbarh(aes(xmin = ymin, xmax = ymax), size = 1) + 
#   geom_vline(xintercept = 0, col = 'gray', size = 1) + 
#   geom_point(color = 'red', size = 3) + 
#   theme_bw(16) + 
#   facet_wrap(~iv) +
#   NULL
# 
# pdp_cf_no_dins_tibble %>%
#   filter(!is.na(x_chr)) %>%
#   ggplot(aes(x_chr, y)) +
#   # ggplot(aes(y, x_chr)) +
#   geom_errorbar(aes(ymin = ymin, ymax = ymax), width = .1, size = 1) +
#   # geom_errorbarh(aes(xmin = ymin, xmax = ymax), size = 1) +
#   # geom_vline(xintercept = 0, col = 'gray', size = 1) +
#   geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
#   geom_point(color = 'red', size = 3) +
#   theme_bw(16) +
#   theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) +
#   facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
#   NULL



(
  b_build_WINDOWPANE <- pdp_cf_dins_tibble %>%
    filter(iv == 'build_WINDOWPANE') %>%
    ggplot(aes(x_chr, y)) +
    geom_hline(yintercept = 0, col = 'dark gray', linewidth = 1) +
    geom_errorbar(aes(ymin = ymin, ymax = ymax), width = .1, linewidth = 1) +
    geom_point(aes(color = Type), size = 3) +
    scale_color_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
      ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
      )
      # , drop = FALSE
    ) +
    theme_bw(16) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
          , axis.title.x = element_text(size = 12)
          , legend.position = 'none') +
    # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
    facet_wrap(~str_wrap(Label, 30), scales = 'free_x') +
    labs(y = 'Probability'
         , x = ''
         # , x = '(Multi Pane\nas ref.)'
         ) + 
    NULL
  )

(
  c_build_EAVES <- pdp_cf_dins_tibble %>%
    filter(iv == 'build_EAVES') %>%
    ggplot(aes(x_chr, y)) +
    geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
    geom_errorbar(aes(ymin = ymin, ymax = ymax), width = .1, size = 1) +
    geom_point(aes(color = Type), size = 3) +
    scale_color_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
      ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
      )
    ) +
    theme_bw(16) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
          , axis.title.x = element_text(size = 12)
          , legend.position = 'none') +
    # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
    facet_wrap(~str_wrap(Label, 30), scales = 'free_x') +
    labs(y = ''
         , x = ''
         # , x = '(Enclosed\nas ref.)'
         ) + 
    NULL
  )


(
  d_build_p_otherpaved_300 <- pdp_cf_dins_tibble %>%
    filter(iv == 'build_p_otherpaved_300') %>%
    ggplot(aes(x, y, fill = Type)) +
    geom_ribbon(aes(ymin = ymin, ymax = ymax)) +
    geom_line() +
    scale_color_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
      ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
      )
    ) +
    geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
    theme_bw(16) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
          , axis.title.x = element_text(size = 12)
          , legend.position = 'none') +
    # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
    facet_wrap(~str_wrap(Label, 12), scales = 'free_x') +
    labs(y = 'Probability'
         , x = ''
         # , x = '% cover'
         ) + 
    NULL
  )


(
  e_build_near_dest <- pdp_cf_dins_tibble %>%
    filter(iv == 'build_near_dest') %>%
    ggplot(aes(x, y, fill = Type)) +
    geom_ribbon(aes(ymin = ymin, ymax = ymax)) +
    geom_line() +
    scale_color_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
      ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
      )
    ) +
    geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
    theme_bw(16) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
          , axis.title.x = element_text(size = 12)
          , legend.position = 'none') +
    # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
    facet_wrap(~str_wrap(Label, 12), scales = 'free_x') +
    labs(y = ''
         , x = ''
         # , x = 'Distance'
         ) + 
    NULL
  )



(
  f_build_Mean_distroad <- pdp_cf_dins_tibble %>%
    filter(iv == 'build_Mean_distroad') %>%
    ggplot(aes(x, y, fill = Type)) +
    geom_ribbon(aes(ymin = ymin, ymax = ymax)) +
    geom_line() +
    scale_color_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
      ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
      )
    ) +
    geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
    theme_bw(16) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
          , axis.title.x = element_text(size = 12)
          , legend.position = 'none') +
    # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
    facet_wrap(~str_wrap(Label, 12), scales = 'free_x') +
    labs(y = ''
         , x = ''
         # , x = 'Distance'
         ) +
    NULL
  )


(
  g_build_VENTSCREEN <- pdp_cf_dins_tibble %>%
    filter(iv == 'build_VENTSCREEN') %>%
    ggplot(aes(x_chr, y)) +
    geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
    geom_errorbar(aes(ymin = ymin, ymax = ymax), width = .1, size = 1) +
    geom_point(aes(color = Type), size = 3) +
    scale_color_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
      ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
      )
    ) +
    theme_bw(16) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
          , axis.title.x = element_text(size = 12)
          , legend.position = 'none') +
    # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
    facet_wrap(~str_wrap(Label, 30), scales = 'free_x') +
    labs(y = ''
         , x = ''
         # , x = '(Unscreened\nas ref.)'
         ) +
    NULL
  )

# 
# 
# (
#   g_build_min_dist_shrub <- pdp_cf_dins_tibble %>%
#     filter(iv == 'build_min_dist_shrub') %>%
#     ggplot(aes(x, y, fill = Type)) +
#     geom_ribbon(aes(ymin = ymin, ymax = ymax)) +
#     geom_line() +
#     scale_color_manual(
#       values = c(
#           '#13082c' # purple
#         , '#4e0070'
#         , '#9d006e'
#         , '#f4264e'
#         , '#ff8650' # orange
#       ),
#       labels = c(
#           'Construction'
#         , 'Defensible Sapce'
#         , 'Exposure'
#         , 'Landscape Attributes'
#         , 'Topography'
#       )
#     ) +
#     geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
#     theme_bw(16) +
#     theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
#           , axis.title.x = element_text(size = 12)
#           , legend.position = 'none') +
#     # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
#     facet_wrap(~str_wrap(Label, 12), scales = 'free_x') +
#     labs(y = ''
#          , x = ''
#          # , x = 'Distance'
#          ) +
#     NULL
#   )

# (
#   e_build_p_otherpaved_200 <- pdp_cf_dins_tibble %>%
#     filter(iv == 'build_p_otherpaved_200') %>%
#     ggplot(aes(x, y, fill = Type)) +
#     geom_ribbon(aes(ymin = ymin, ymax = ymax)) +
#     geom_line() +
#     scale_color_manual(
#       values = c(
#           '#13082c' # purple
#         , '#4e0070'
#         , '#9d006e'
#         , '#f4264e'
#         , '#ff8650' # orange
#       ),
#       labels = c(
#           'Construction'
#         , 'Defensible Sapce'
#         , 'Exposure'
#         , 'Landscape Attributes'
#         , 'Topography'
#       )
#     ) +
#     geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
#     theme_bw(16) +
#     theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
#           , axis.title.x = element_text(size = 12)
#           , legend.position = 'none') +
#     # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
#     facet_wrap(~str_wrap(Label, 12), scales = 'free_x') +
#     labs(y = 'Probability'
#          , x = ''
#          # , x = '% cover'
#          ) + 
#     NULL
#   )













pdp_cf_no_dins_tibble %>% tabyl(iv)
# library(patchwork)
# a_importance_graph_dins / 
#   (b_build_WINDOWPANE + c_build_EAVES + d_build_near_dest) / 
#   (e_build_p_otherpaved_200 +  f_build_VENTSCREEN + g_build_min_dist_shrub) + 
#   plot_annotation(tag_levels = 'A')


insets <- (b_build_WINDOWPANE + c_build_EAVES + d_build_p_otherpaved_300) / 
  (#e_build_p_otherpaved_200 
    e_build_near_dest + f_build_Mean_distroad + g_build_VENTSCREEN
     # g_build_min_dist_shrub
     )

(importance_pdp_2 <- a_importance_graph_dins + 
  inset_element(insets, left = 0.27, bottom = 0.02, right = .95, top = .79))
  

importance_pdp_2 %>%
ggsave(file = paste0(getwd(), '/figures/importance_pdp_2_', Sys.Date(), '.png')
         , height = 6.5*2, width = 6.5*2)


```
 

```{r, citations}
lapply(packages, citation)
```

Last knit on `r format(Sys.time())`

```{r}
system.time(save.image(file = paste0('saved_sessions/wui_r_models_', gsub('[[:punct:]]', '-', Sys.time()), '.RData')))
```
