---
title: "04_fit_models.Rmd"
author: "Dexter H. Locke, PhD"
date: "`r format(Sys.time())`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This assumes "02_Woosley_combine_data.Rmd" was run

## 0 set up: load libraries, custom functions, set defaults

```{r}
# load libraries
# packages we'll be using
packs <- c('tidyverse'        # a must have!
           , 'tidylog'        # makes things very verbose for 2x checking 
           , 'magrittr'       # all of the pipes
           , 'janitor'        # cleans things up
           # , 'sf'             # simple features
           # , 'mapview'        # quick webmaps for zoom/pan viz
           #'tidycensus',     # access to Census data in a tidy way
           #'party',          # random forests
           , 'modEvA'         # contains D-squared function
           , 'randomForest'  #'rfUtilities', 'verification'
           , 'tictoc'         # times things
           , 'beepr'          # makes noises
            ,  'ggpubr'        #for scatter plot
           # , 'broom'          # tidy up regression models
           # , 'performance'    # nice regression diagnostics
           # , 'psych'          # describe is very useful for descriptive statistics
           # , 'sjPlot'         # useful plotting and regression support
           # , 'rpart'          # for random forests
           # # , pROC           # for AUC calculation
           , 'doParallel'     # make partial dependency plots less-slow
           , 'pdp'            # partial dep plots
           , 'vip'            # Variable Importance Plots (and extracting vip vals)
           # , 'caret'          #random forest work
           , 'party'          # for random forests using cforest
           )        

# check for all of the libraries
if (length(setdiff(packs, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packs, rownames(installed.packages())))  
}

# lapply(packs, library, character.only = TRUE)
vapply(packs, library, character.only = TRUE, logical(1),
       logical.return = TRUE, quietly = TRUE)


# custom function for "Not In"
`%nin%` <- Negate(`%in%`)

# for reproducibility, we should have the same random draws. setting the seed ensures that is the case.
set.seed(19870630)
```

## 1 read in data

### A main `build` file

```{r}

# build <- read_csv(paste0(getwd(), '/output_data/building_2022-02-01.csv')) %>% glimpse



# one 'main' data frame
build <- read_csv(paste0(getwd(), '/output_data/building_2022-06-10.csv')) %>%
  tidylog::select(
    # damage_binary
      damage_cat         # binary outcome encoded as categorical (Destroyed / Survived)
    , damage_severity    # five levels
    , build_area   
    # build_DECKPORCHE    , #drop this on 12/20/21
    , build_DECKPORCHO
    , build_EAVES
    , build_EXTERIORSI
    , build_FENCEATTAC
    , build_PATIOCOVER
    , build_PROPANETAN
    , build_ROOFCONSTR
    , build_VEGCLEARAN 
    , build_VENTSCREEN 
    , build_WINDOWPANE 
    , parcel_year_built 
    , build_near_build 
    , build_has_tree_overhang 
    , build_min_dist_shrub 
    , build_min_dist_tree 
    , build_overhang_ht 
    , build_perc_overhang 
    , parcel_Build_P 
    , parcel_Can_P 
    , parcel_Grass_P 
    #, parcel_Imperv_P    #inverse of perv surface; shld we just drop bc we don't have for other measures?
    , parcel_Paved_P    
    #  parcel_Perv_P    ,#inverse of imp, just need one
    , parcel_Road_P
    , parcel_Shrub_P  
    , parcel_Soil_P  
    , parcel_Water_P  
    , build_near_dest  
    , build_p_building_10  
    , build_p_building_100  
    , build_p_building_200  
    , build_p_building_300  
    , build_p_grass_10  
    , build_p_grass_100  
    , build_p_grass_200  
    , build_p_grass_300  
    , build_p_otherpaved_10  
    , build_p_otherpaved_100  
    , build_p_otherpaved_200  
    , build_p_otherpaved_300  
    , build_p_road_10  
    , build_p_road_100  
    , build_p_road_200  
    , build_p_road_300  
    , build_p_shrub_10  
    , build_p_shrub_100  
    , build_p_shrub_200  
    , build_p_shrub_300  
    , build_p_soil_10  
    , build_p_soil_100  
    , build_p_soil_200  
    , build_p_soil_300  
    , build_p_tree_10  
    , build_p_tree_100  
    , build_p_tree_200  
    , build_p_tree_300  
    , build_p_water_10  
    , build_p_water_100  
    , build_p_water_200  
    , build_p_water_300  
    , parcel_area  
    , build_Mean_builddens  
    , build_Mean_distall_road  
    , build_Mean_distroad   
    , build_Mean_aspect_100m_DEM  
    , build_Mean_aspect_30m_DEM  
    , build_Mean_elev_100m  
    , build_Mean_elev_30m  
    , build_Mean_slope_100m_DEM  
    , build_Mean_slope_30m_DEM
    , build_DINS
    ) %>%
  mutate_if(is.character, as.factor) %>% # turns characters into factors
  droplevels() %>% 
  data.frame() # some of the random forest functions do not 'like' tibbles
               # since the non-dins and dins data will be pulled from here
               # we change here so that the subsets are already formatted as data.frames

# Miranda: do these NA's surprise you? OK to drop non-DINS-associated NA's?
#  2/23/22 Dexter: As long as it does not also discard DINS observations. I don't see the harm in keeping them, given that we do have many NAs in DINS.
# where are the NA's
build %>% 
  map(~sum(is.na(.))) %>% # map is like for loop but vectorized, meaning its faster uses dif. syntax help(purrr::map)
  bind_rows() %>%         # the output of purrr::map is a list, this makes a tibble
  t()#  %>% View() # check for NA's ("t" is for Transpose, just makes it easier to read)

# Miranda, are these NA's expected? #  2/23/22Dexter, see line 159 above.
```

### B non-DINS data (larger dataset, fewer predictors)

```{r}

# a subset for non-DINS-associated data
build_no_dins <- build %>% 
  tidylog::select(# dropping columns containing specific DINS data
                  # very detailed but sparse (lots of NAs)
    !c(  build_DECKPORCHO
       , build_EAVES
       , build_EXTERIORSI
       , build_FENCEATTAC
       , build_PATIOCOVER
       , build_PROPANETAN
       , build_ROOFCONSTR
       , build_VEGCLEARAN
       , build_VENTSCREEN
       , build_WINDOWPANE
       , build_DINS
       , damage_severity # dropping the DV for the smaller model
       )
    )

# NAs are expected
build_no_dins %>% 
  map(~sum(is.na(.))) %>% 
  bind_rows() %>% 
  t() # %>% View() # check for NA's

# how is the outcome distributed?
build         %>% tabyl(damage_cat) # good double check
build_no_dins %>% tabyl(damage_cat)

```

### C DINS data (smaller dataset, more predictors)

```{r}
# get data for DINS analyses
build %>% tabyl(build_DINS)

# subset
build_dins <- build %>% 
  filter(build_DINS == 1) %>% 
  select(-build_DINS, -damage_cat)
  # dropping the DV for the smaller model

# Miranda, even after dropping the non-DINS data are there are a lot of NA's in the DINS columns
# do we need all of them?
# in other words, not even the DINS data are complete for DINS data
#  2/23/22 Dexter, please see line 195 above - these are expected.
build_dins %>% 
  map(~sum(is.na(.))) %>% 
  bind_rows() %>% 
  t() # %>% View() # check for NA's


# when we keep only complete cases (so remove all NA's) the file is really short (n = 172)
# is this a surprise?
#  2/23/22 Dexter, please see line 195 above - this is not a surprise.
dim(build_dins)
build_dins %>% drop_na() %>% dim() # not going to be practical for randomForest::randomForest

build_dins %>% tabyl(damage_severity)

```

## 2 fit random forest models

### A non-DINS analyses (larger dataset, fewer predictors)

```{r}
# fit random forest models
# randomForest::randomForest is faster but requires full data
# party::cforest is slower but can handle missing data

# n_tree <- 10 # used for setting number of trees
# n_tree <- 2000 #3/24/2022 changed back to 2000 trees as Price paper uses 2000
n_tree <- 500 # May 20, 2022 because we want graphs this centry


# # random forest but has to drop NAs
# tic(); rf_no_dins <- randomForest::randomForest(
#   damage_cat ~ .
#   # need full dataset, can't keep NA's
#   , data = build_no_dins %>% drop_na()
#   , type = 'classification' # not regression
#   , mtry = 5
#   , ntree = n_tree # 10 ~.5 seconds,100 ~5s, 200 ~7.5s, 3 ~12s, ... 5 ~23s 
#                    # tested on a few smaller forests
#   ); toc()


# # # since this takes a long time to run, I've commented the code off and just read-in
# # # the completed model file in its "*.Rdata" format with the load() function.
# # sounds good - I had to rerun this on my machine on 3/24/22 so will see that date below
# # # random forest via party::cforest which accepts missing data and is slower 
# tic(); cf_no_dins <- party::cforest(
#   damage_cat ~ .
#   , data = build_no_dins # notice no drop_na here
#   , controls =
#     cforest_control(
#         mtry = 5
#       , ntree = n_tree # 10 ~2 seconds, 100 ~25s, 200 ~50s, 300 ~75s ... 500 ~130 seconds
#       , mincriterion = 0
#       )
#   ); toc(); beepr::beep() # 12 mins with 500 trees

# # save out since it is slow
# # sounds good - I had to rerun this on my machine on 3/24/22 so will see that date below
# tic(); save(cf_no_dins
#             , file = paste0('../Massive_forests/cf_no_dins_', Sys.Date(), '.Rdata')); toc()

# read back in
# tic(); load(file = '../Massive_forests/cf_no_dins_2022-02-22.Rdata'); toc() # ~9s
# tic(); load(file = '../Massive_forests/cf_no_dins_2022-05-17.Rdata'); toc() # ~50s with 2000 trees!
# tic(); load(file = '../Massive_forests/cf_no_dins_2022-05-20.Rdata'); toc() # < 10s with 500 trees
tic(); load(file = '../Massive_forests/cf_no_dins_2022-06-13.Rdata'); toc() # < 10s with 500 trees

# MHM - last date I ran this was 3/24/22 so will see that date below
#tic(); load(file = '../Massive_forests/cf_no_dins_2022-03-24.Rdata'); toc() # 

```

### B DINS analyses (smaller dataset, more predictors)

```{r}

# # predicting severity
# 
# # random forest via party::cforest which accepts missing data and is slower
tic(); cf_dins <- party::cforest(
  damage_severity ~ . # severity, not binary
  , data = build_dins # notice build_dins here, no "no" in the object name.
  , controls =
    cforest_control(
        mtry = 5
      , ntree = n_tree # 10 ~0.52 seconds, 100 ~1.5s, 200 ~2.7s, 300 ~3.5s ... 500 ~7s
      , mincriterion = 0
      )
  ); toc() # ~6 seconds

# 3/20/2022 - Dexter, I wanted to see if switching to categorial outcomes added anything extra to our findings so
# I also included a DINS model with a binary outcome. I then compared the variable importance (top 20 variables, importance scores) for both DINS outcomes (binary, categorical) in section 4A. Because the outcomes are so similar I want to keep DINS as binary outcome - I think it's easier for descriptive figures and the reader, and it's keeping story simpler overall
#keeping this as binary - with dins
# subset

n_tree <- 500
build_dins_binary <- build %>% 
  filter(build_DINS == 1) %>% 
  select(-build_DINS, -damage_severity)
  # dropping the DV for the smaller model
# random forest via party::cforest which accepts missing data and is slower
tic(); cf_dins_binary <- party::cforest(
  damage_cat ~ . # binary
  , data = build_dins_binary # notice build_dins_binary here, no "no" in the object name.
  , controls =
    cforest_control(
        mtry = 5
      , ntree = n_tree # 2000 is 80 sec - MHM
      , mincriterion = 0
      )
  ); toc() # ~6 seconds with 500


# given rapid re-run times, saving is not needed..



```

## 3 overall model accuracy
### A cf_no_dins
```{r eval=FALSE, include=FALSE}
# tic(); predict_cf_no_dins <- predict(cf_no_dins); toc() # ~1 hr
# 
# tic(); save(predict_cf_no_dins
#             , file = paste0('output_data/predict_cf_no_dins_', Sys.Date(), '.Rdata')); toc() # basically instant

load('output_data/predict_cf_no_dins_2022-04-18.Rdata')


# # probability version (instead of hard class) used in ROC / AUC below
# tic(); predict_probs_cf_no_dins <- predict(cf_no_dins, type = 'prob'); toc() # ~1 hr
# 
# tic(); save(predict_probs_cf_no_dins
#             , file = paste0('output_data/predict_probs_cf_no_dins_', Sys.Date(), '.Rdata')); toc() # basically instant

load('output_data/predict_probs_cf_no_dins_2022-04-18.Rdata')


table(build_no_dins$damage_cat) # truth
table(predict_cf_no_dins)       # prediction

# compare observed (aka truth) with prediction
(table(  build_no_dins$damage_cat
      , predict_cf_no_dins) |>
  as.data.frame.matrix(row.names = c('true Destroyed', 'true Survived')) |> 
  rownames_to_column() -> build_no_dins_accuracy_table)

# accuracy = (TN + TP) / (TN + FP + FN + TP)

(TN <- build_no_dins_accuracy_table$Destroyed[1]) # True Positive
(TP <- build_no_dins_accuracy_table$Survived[2])  # True Negative

100*((TN + TP) / sum(build_no_dins_accuracy_table$Destroyed,
                     build_no_dins_accuracy_table$Survived))

build_no_dins_accuracy_table |> 
  adorn_percentages(denominator = 'all') |>
  adorn_pct_formatting()



```

#### i ROC curve (kinda useless - dang)
```{r eval=FALSE, include=FALSE}

# nice worked example of multiclass ROC
# https://rdrr.io/cran/pROC/man/multiclass.html

# but this one is better
# https://github.com/WandeRum/multiROC
# get response categories as one hot encoded-tibble
# naming with multiROC::multi_roc is really finicky
# column names cannot have dots and must end with 
# "_true" for the observed data and "_pred_xx" 
# for the predicted data, where "_xx" is a method (like 
# 'mn' for multinomial or 'rf' for random forest)
# (
model.matrix(~0 + build_no_dins$damage_cat) %>% # one hot encoding trick
  as_tibble() %>% #glimpse()
  mutate_all(., ~as.integer(.)) %>% 
  rename_all(., ~str_remove_all(., "build_no_dins\\$damage_cat")) %>%
  rename_all(., ~paste0(., '_true')) %>%
  bind_cols(., predict_probs_cf_no_dins |> 
              map(.x, .f = as_tibble) |> 
              bind_rows() |> 
              rename_all(~str_remove_all(., 'damage_cat.')) |> 
              rename_all(~paste0(., '_pred_cf'))
  ) |> 
  data.frame() -> class_test_build_no_dins

class_test_build_no_dins %>% names
class_test_build_no_dins %>% glimpse



roc_res <- multiROC::multi_roc(class_test_build_dins_binary, force_diag=TRUE)
plot_roc_df <- multiROC::plot_roc_data(roc_res)




# roc_res$AUC
(auc <- tibble(variable             = roc_res$AUC$cf %>% names()
               , multinomial_reg     =     roc_res$AUC$cf %>% unlist()
               # , multinomial_reg_idw = roc_res_idw$AUC$MNi %>% unlist()
               # , random_forest       =     roc_res$AUC$RFc %>% unlist()
               # , random_forest_idw   = roc_res_idw$AUC$RFi %>% unlist()
) #|> mutate_if(is.double, round, 2)
  # arrange(desc(multinomial_reg))
)

auc |> View()



# AUC contains a list of AUC for each group of different classifiers. Micro-average ROC-AUC was calculated by stacking all groups together, thus converting the multi-class classification into binary classification. Macro-average ROC-AUC was calculated by averaging all groups results (one vs rest) and linear interpolation was used between points of ROC.



(
  roc_all_facet <- plot_roc_df %>%
    ggplot(aes(x = 1-Specificity, y = Sensitivity)) +
    geom_path(aes(color = Group, linetype=Method), size = 1) + # , alpha = .5) +
    geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1),
                 colour='grey', linetype = 'dotdash') +
    scale_y_continuous(expand = c(0, 0)) +
    scale_x_continuous(expand = c(0, 0)) +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5),
          # legend.justification=c(1, 0), legend.position=c(.95, .05),
          legend.title=element_blank(),
          legend.background = element_rect(fill=NULL, size=0.5,
                                           linetype="solid", colour ="black")) +
    coord_fixed() +
    facet_wrap(~Method) +
    NULL
)

# ggsave(paste0(getwd(), '/figs/roc_all_facet_', Sys.Date(), '.png')
#        , width = 6.5, height = 6.5)

```


### B cf_dins_binary
```{r eval=FALSE, include=FALSE}
# REPEAT for cf_dins_binary

tic(); predict_cf_dins_binary <- predict(cf_dins_binary); toc() # ~75 secs

# used in ROC curve calcs
tic(); predict_probs_cf_dins_binary <- predict(cf_dins_binary, type = 'prob'); toc() # ~75 secs


table(build_dins_binary$damage_cat) # truth
table(predict_cf_dins_binary)       # prediction

# compare observed (aka truth) with prediction
(table( build_dins_binary$damage_cat
      , predict_cf_dins_binary) |>
  as.data.frame.matrix(row.names = c('true Destroyed', 'true Survived')) |> 
  rownames_to_column() -> cf_dins_binary_accuracy_table)

# accuracy = (TN + TP) / (TN + FP + FN + TP)

(TN <- cf_dins_binary_accuracy_table$Destroyed[1]) # True Positive
(TP <- cf_dins_binary_accuracy_table$Survived[2])  # True Negative

100*((TN + TP) / sum(cf_dins_binary_accuracy_table$Destroyed,
                     cf_dins_binary_accuracy_table$Survived))


cf_dins_binary_accuracy_table |> 
  adorn_percentages(denominator = 'all') |>
  adorn_pct_formatting()

```

#### i ROC curve (kinda useless - dang)
```{r eval=FALSE, include=FALSE}

# nice worked example of multiclass ROC
# https://rdrr.io/cran/pROC/man/multiclass.html

# but this one is better
# https://github.com/WandeRum/multiROC
# get response categories as one hot encoded-tibble
# naming with multiROC::multi_roc is really finicky
# column names cannot have dots and must end with 
# "_true" for the observed data and "_pred_xx" 
# for the predicted data, where "_xx" is a method (like 
# 'mn' for multinomial or 'rf' for random forest)
# (
model.matrix(~0 + build_dins_binary$damage_cat) %>% # one hot encoding trick
  as_tibble() %>% #glimpse()
  mutate_all(., ~as.integer(.)) %>% 
  rename_all(., ~str_remove_all(., "build_dins_binary\\$damage_ca")) %>%
  rename_all(., ~paste0(., '_true')) %>%
  bind_cols(., predict_probs_cf_dins_binary |> 
              map(.x, .f = as_tibble) |> 
              bind_rows() |> 
              rename_all(~str_remove_all(., 'damage_cat.')) |> 
              rename_all(~paste0(., '_pred_cf'))
  ) |> 
  data.frame() -> class_test_build_dins_binary

class_test_build_dins_binary %>% names
class_test_build_dins_binary %>% glimpse



roc_res <- multiROC::multi_roc(class_test_build_dins_binary, force_diag=TRUE)
plot_roc_df <- multiROC::plot_roc_data(roc_res)




# roc_res$AUC
(auc <- tibble(variable             = roc_res$AUC$cf %>% names()
               , multinomial_reg     =     roc_res$AUC$cf %>% unlist()
               # , multinomial_reg_idw = roc_res_idw$AUC$MNi %>% unlist()
               # , random_forest       =     roc_res$AUC$RFc %>% unlist()
               # , random_forest_idw   = roc_res_idw$AUC$RFi %>% unlist()
) #|> mutate_if(is.double, round, 2)
  # arrange(desc(multinomial_reg))
)

auc |> View()



# AUC contains a list of AUC for each group of different classifiers. Micro-average ROC-AUC was calculated by stacking all groups together, thus converting the multi-class classification into binary classification. Macro-average ROC-AUC was calculated by averaging all groups results (one vs rest) and linear interpolation was used between points of ROC.

# (
#   roc_all <- plot_roc_df %>% 
#     bind_rows(plot_roc_df_idw) |> 
#     ggplot(aes(x = 1-Specificity, y = Sensitivity)) +
#     geom_path(aes(color = Group, linetype=Method), size = 1) + # , alpha = .5) +
#     geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1), 
#                           colour='grey', linetype = 'dotdash') +
#     scale_y_continuous(expand = c(0, 0)) +
#     scale_x_continuous(expand = c(0, 0)) +
#     theme_bw() + 
#     theme(plot.title = element_text(hjust = 0.5), 
#                    legend.justification=c(1, 0), legend.position=c(.95, .05),
#                    legend.title=element_blank(), 
#                    legend.background = element_rect(fill=NULL, size=0.5, 
#                                                              linetype="solid", colour ="black")) + 
#     coord_fixed() + 
#     # facet_wrap(~Method) + 
#     NULL
# )

# ggsave(paste0(getwd(), '/figs/roc_all_', Sys.Date(), '.png')
#        , width = 6.5, height = 6.5)

(
  roc_all_facet <- plot_roc_df %>%
    ggplot(aes(x = 1-Specificity, y = Sensitivity)) +
    geom_path(aes(color = Group, linetype=Method), size = 1) + # , alpha = .5) +
    geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1),
                 colour='grey', linetype = 'dotdash') +
    scale_y_continuous(expand = c(0, 0)) +
    scale_x_continuous(expand = c(0, 0)) +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5),
          # legend.justification=c(1, 0), legend.position=c(.95, .05),
          legend.title=element_blank(),
          legend.background = element_rect(fill=NULL, size=0.5,
                                           linetype="solid", colour ="black")) +
    coord_fixed() +
    facet_wrap(~Method) +
    NULL
)

# ggsave(paste0(getwd(), '/figs/roc_all_facet_', Sys.Date(), '.png')
#        , width = 6.5, height = 6.5)

```

## 4 variable importance

```{r}
# # modified from first chunk here:
# # https://bgreenwell.github.io/pdp/articles/pdp.html#other-vignettes
# # Variable importance plot (compare to randomForest::varImpPlot(boston_rf))
# vip(boston_rf, bar = FALSE, horizontal = FALSE, size = 1.5)  # Figure 1

# # variable importance plot with random forest; fast
# vip_rf_no_dins <- vip(rf_no_dins
#     # , bar = FALSE       # doesn't seem to work "help(vip)" showed that it changed to "geom"
#     # , geom = 'point'    # try "col" instead
#     , geom = 'col'      # try "point" instead
#     , horizontal = TRUE # vignette example had this as FALSE (label easier rotated)
#     # , size = 1.5        # plausibly pertains to point size
#     # see "num_features"
#     # "Integer specifying the number of variable importance scores to plot. Default is 10."
#     ) + 
#   theme_bw(16)          # added some flare (ok just bigger axis text and black/white theme)
# 
# # check the plot
# vip_rf_no_dins



# if we want to use color/shapes or facets to indicate the variable TYPE
# like we did with the cforest object before, it looks like vip::vi can be used
# to calculate the variable importance scores, then we can re-purpose the old
# code to add the colors symbols, etc.. . 'help(vip)' has an example starting with 
# "# Better yet, store the variable importance scores and then plot
# # vi_scores <- vi(model, method = "firm")". That's how I learned to extract importance
# from randomForest::randomForest models

# # since the second one takes 10 minutes, this code is commented out. Instead of re-running, just read a *.csv backin
# # not sure about this scaling. When scale is FALSE the values are on totally different scales
# # `rank = TRUE`
# tic(); vi_cf_no_dins <- vi(cf_no_dins, scale = TRUE) %>% mutate(Model = 'cf_no_dins', n_tree = n_tree); toc() # 10 mins
# tic(); vi_cf_dins    <- vi(cf_dins,    scale = TRUE) %>% mutate(Model =    'cf_dins', n_tree = n_tree); toc() # 1 min
# tic(); vi_cf_dins_binary<- vi(cf_dins_binary,scale = TRUE) %>% mutate(Model =    'cf_dins_binary', n_tree = n_tree); toc() # 1 min
# 
# 
# bind_rows(vi_cf_no_dins
#           , vi_cf_dins
#           , vi_cf_dins_binary) %>% # combines variable importance from each model
#     write_csv(., paste0(getwd(), '/output_data/variable_importance_', Sys.Date(), '.csv'))

 

# reading back in deviance explained
(tab_labs <- 
  # read_csv(paste0(getwd(), '/data/Table_Deviance_Explained_2022-03-08.csv')) |>
   read_csv(paste0(getwd(), '/data/Table_Deviance_Explained_2022-06-13.csv')) |>
   mutate(Type = fct_recode(factor(Type), 
                              Exposure               = 'EXP'
                            , Construction           = 'CON'
                            , 'Defensible Space'     = 'DEF'
                            , 'Landscape Attributes' = 'LAND'
                            , Topography             = 'TOPO')
          )
 ) 
 
# now that we have updated the deviance explained with the new data, we have a new table
# but that new table doesn't have the hand-created
# so we fold those back in here
(old_labs <- read_csv(paste0(getwd(), '/data/Table_Deviance_Explained_2022-03-08.csv')) |> 
  tidylog::select(Variable = `Variable name`, Label))

# join in aliases and type, repurpose directly below.
 #MHM -3/23/2022 - let's hold off on displaying scale in variable importance plots until we talk more w alex, I think theme is somewhat repeating this information and would like her take
(
  variable_importance <- read_csv(paste0(getwd()
                                         # , '/data/variable_importance_2022-03-29.csv')) %>% 
                                         # , '/output_data/variable_importance_2022-05-20.csv')) %>% 
                                         , '/output_data/variable_importance_2022-06-13.csv')) %>% 
    group_by(Model) %>% 
    mutate(rank = row_number(Model)) %>% 
    ungroup() |> 
    left_join(
      tab_labs |> tidylog::select(Variable = `Variable name`
                                  , Alias #, Label
                                  , Type
                                  , Scale)
      , by = 'Variable') |> 
    left_join(old_labs, by = 'Variable') |> # is this join ok with one-extra row in the y table?
    mutate(Variable = factor(Variable))
  )


```

### A compare DINS - class vs binary

```{r}
#compare variable importance outcomes for two ways of considering DINS outcomes - 
# DINS RF with binary outcome and categorial outcome
# 3/20/2022 - Dexter, I   compared the variable importance (top 20 variables, importance scores) for both DINS outcomes (binary, categorical) in section 4A. Because the outcomes are so similar I want to keep DINS as binary outcome - I think it's easier for descriptive figures and the reader, and it's keeping story simpler overall
#first, are same variables listed in top 20? #for most part, yes
variable_importance %>% 
  filter (rank <21)  %>% 
  filter (Model=='cf_dins' | Model== 'cf_dins_binary')  %>% 
      add_count(Variable) %>% 
        filter (n==1) 
#for the most part- there are two variables in top 2 for each model that are unique to that model
#cf_dins - categorial outcome includes  parcel_Paved_P & parcel_year_built but cf_dins_binary - binary outcome does not
#cf_dins_binary - binary outcome includes build_PATIOCOVER and build_p_building_2000 but cf_dins - categorial outcome does not
#second, are variable importances correlated?
#yes, highly correlated
variable_importance %>% 
 filter (Model=='cf_dins' | Model== 'cf_dins_binary') %>%
      dplyr::select(Variable, Importance, Model) %>% 
        pivot_wider(
          names_from = "Model",
          values_from = "Importance") ->Imp_wide
 
ggscatter(Imp_wide, x = "cf_dins", y = "cf_dins_binary", 
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Imp_cf_bins - Category", ylab = "Imp_cf_dins - Binary")
```


### B graph variable importance
```{r}
variable_importance |> 
  tabyl(Model)

(
  variable_importance |> 
    filter(Model == 'cf_no_dins') |> 
    filter(rank < 21) |> 
    ggplot(aes(  
        x = `Importance`
      , y = reorder(Label, `Importance`)
      , fill = Type
      )) +
    # geom_point(aes(shape = Type)) +
    geom_col() + 
    theme_bw(16) +
    # scale_fill_viridis_d(option = "A", end = .8, begin = .1) +
    scale_fill_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
      ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
      )
      , drop = FALSE
    ) +
    scale_x_continuous(expand = c(0, 0), limits = c(0, 101)) + 
    theme(axis.ticks.y = element_blank()) + 
    theme(legend.position = "bottom",
          legend.justification = "left",
          plot.title.position = "plot",
          plot.caption = element_text(hjust=0),
          plot.caption.position = "plot") + 
    labs(
        title = 'Variable Importance Scores for Random Forest with no DINS variables (n = 11,134)'
      , y = '') + 
    NULL -> a_importance_graph_no_dins
  )

(
  variable_importance |> 
    filter(Model == 'cf_dins_binary') |> 
    filter(rank < 21) |> 
    ggplot(aes(  
        x = `Importance`
      , y = reorder(Label, `Importance`)
      , fill  = Type
      )) +
    # geom_point(aes(shape = Type)) +
    geom_col() + 
    scale_y_discrete(drop=FALSE) + 
    # scale_fill_brewer(palette = 'Dark2') + 
    scale_fill_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
       ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
        )
      , drop = FALSE
      ) +
    scale_x_continuous(expand = c(0, 0), limits = c(0, 101)) + 
    theme_bw(16) +
    theme(axis.ticks.y = element_blank()) + 
    theme(legend.position = "bottom",
          legend.justification = "left",
          plot.title.position = "plot",
          plot.caption = element_text(hjust=0),
          plot.caption.position = "plot") + 
    labs(
        title = 'Variable Importance Scores for Random Forest with DINS variables (n = 1,487)'
      , y = '') + 
    NULL -> a_importance_graph_dins
  )

```

## 5 partial dependence plots

### A base-style graphs (example only)

```{r eval=FALSE, include=FALSE}
# single base-graphics partial dependency plot, modeled after Figure 2 here:
# https://bgreenwell.github.io/pdp/articles/pdp.html#other-vignettes
# partialPlot(boston_rf, pred.data = boston, x.var = "lstat")  # Figure 2
randomForest::partialPlot(rf_no_dins
                          , pred.data = build_no_dins
                          , x.var = "build_near_dest"
                          ) # ugly!
```

### B ggplot graphs

#### i test on a single predictor

```{r eval=FALSE, include=FALSE}
# # building off of the third chunk from
# # https://bgreenwell.github.io/pdp/articles/pdp.html#other-vignettes
# # AND third chunk from this vignette
# # https://bgreenwell.github.io/pdp/articles/pdp-computation.html
# # Switch to ggplot2
# p2 <- partial(boston_rf, pred.var = "lstat", plot = TRUE,
#               plot.engine = "ggplot2")

# THIS IS A SINGLE VARIBLE TEST
pdp::partial(rf_no_dins                      # random forest model
             , pred.var = "build_near_dest"  # predictor variable
             , plot = TRUE                   # if FALSE returns prediction data
             , plot.engine = "ggplot2"       # plot with ggplot2 or not?
             , rug = TRUE                    # adds the univariate y-axis summary (aka "rug")
             , progress = "text"             # prints progress, sets users expectations
             , quantiles = TRUE              # see help(pdp)
             , probs = 0:20/20               # probabilities, "0:20/20" gives 5% increments
             , ice = TRUE                    # Individual Conditional Expectations
             , center = TRUE                 # for graphical layout, pertains to ice
             , alpha = .1                    # line transparency
             ) + 
  theme_bw(16) +                             # ggplot adjustment for black/white & large text size 
  # scale_y_continuous(expand = c(0, 0)) +
  NULL -> test_pdp                           # makes the plot

test_pdp # accesses plot

variable <- "build_near_dest"
ggsave(file = paste0(getwd(), '/figures/cf_dins/', variable, '_', Sys.Date(), '.png')
       , width = 6.5*2
       , height = 6.5*1.5
       , dpi = 100)
```

#### ii non-DINS RF

```{r}
# TODO? naw
```

#### iii non-DINS CF
```{r eval=FALSE, include=FALSE}
# TODO Miranda, we can look at all plots, but maybe we just want to look at the top 10 or 20 top predictors
#2/23/22 Dexter I think top 10 seems fine, the Price MS only shows several in final MS.
## CF non-DINS
# loop through predictors to get PDP
# first get the iterator, here the variable names

# # testing on smaller model
# n_tree<- 500
# tic(); cf_no_dins <- party::cforest(
#   damage_cat ~ .
#   , data = build_no_dins # notice no drop_na here
#   , controls =
#     cforest_control(
#         mtry = 5
#       , ntree = n_tree # 10 ~2 seconds, 100 ~25s, 200 ~50s, 300 ~75s ... 500 ~130 seconds
#       , mincriterion = 0
#       )
#   ); toc() # ~2 mins with n_tree = 500

# using ALL predictors
(pdp_cf_no_dins_vars <- variable_importance %>% filter(Model == 'cf_no_dins') %>%                 pull(Variable))

# using top n predictors
top_n <- 9         # set n (can revise to 20 or any other value greater than zero and less than 71)
(pdp_cf_no_dins_vars <- variable_importance %>% filter(Model == 'cf_no_dins') %>% slice(1:top_n) %>% pull(Variable)) 


# detectCores(); # detect the number of cores of your cpu
# split <- 10
# 
# 
# cl<-makeCluster(split);
# registerDoParallel(cl);
# start.time = proc.time(); 
# 
# tic()
# pdp::partial(cf_no_dins               # the model
#              , pred.var = 'build_near_dest'
#              , plot = FALSE
#              # , plot.engine = "ggplot2"
#              # , rug = TRUE
#              # , progress = "text"
#              , quantiles = TRUE
#              , probs = 0:20/20
#               , ice = TRUE
#              # , center = TRUE
#              # , alpha = .1
#              , parallel = TRUE
#              ) |> 
#   as_tibble() |> 
#   group_by(build_near_dest) |> 
#   summarise(ci = list(mean_cl_normal(yhat))) |> 
#   unnest(ci) |> 
#   rename(mean_pred = y, lower_ci = ymin, upper_ci = ymax) -> build_near_dest_pdp; toc(); stopCluster(cl) # ~1hr 10 mins (10 cores)


detectCores(); # detect the number of cores of your cpu
split <- 8


tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'build_near_dest'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) |> 
  as_tibble() |> 
  group_by(build_near_dest) |> 
  summarise(ci = list(mean_cl_normal(yhat))) |> 
  unnest(ci) |> 
  rename(x = build_near_dest) |> 
  mutate(iv = 'build_near_dest') |> 
  write_csv(paste0(getwd(), '/output_data/pdp/build_near_dest_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~1 hr 15 mins w 10 cores, 95 mins w 8 cores




pdp_cf_no_dins_vars |> tabyl()

 


tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'build_area'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) |> 
  as_tibble() |> 
  group_by(build_area) |> 
  summarise(ci = list(mean_cl_normal(yhat))) |> 
  unnest(ci) |> 
  rename(x = build_area) |> 
  mutate(iv = 'build_area') |> 
  write_csv(paste0(getwd(), '/output_data/pdp/build_area_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~1 hr 13 mins, ~1.5 hr w 9 cores







tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'build_Mean_distroad'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) |> 
  as_tibble() |> 
  group_by(build_Mean_distroad) |> 
  summarise(ci = list(mean_cl_normal(yhat))) |> 
  unnest(ci) |> 
  rename(x = build_Mean_distroad) |> 
  mutate(iv = 'build_Mean_distroad') |> 
  write_csv(paste0(getwd(), '/output_data/pdp/build_Mean_distroad_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~1 hr 20 mins, 1:30 with 10
 
 
   

 
 
tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'build_Mean_elev_100m'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) |> 
  as_tibble() |> 
  group_by(build_Mean_elev_100m) |> 
  summarise(ci = list(mean_cl_normal(yhat))) |> 
  unnest(ci) |> 
  rename(x = build_Mean_elev_100m) |> 
  mutate(iv = 'build_Mean_elev_100m') |> 
  write_csv(paste0(getwd(), '/output_data/pdp/build_Mean_elev_100m_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~1 hr 20 mins; ~1 hr 25 10 cores
 
 
 
 
 
 
 
 
   
tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'build_p_building_300'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) |> 
  as_tibble() |> 
  group_by(build_p_building_300) |> 
  summarise(ci = list(mean_cl_normal(yhat))) |> 
  unnest(ci) |> 
  rename(x = build_p_building_300) |> 
  mutate(iv = 'build_p_building_300') |> 
  write_csv(paste0(getwd(), '/output_data/pdp/build_p_building_300_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~1 hr 18 mins; ~1 hr with 12 cores
   
   

 
    
 tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'build_Mean_slope_100m_DEM'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) |> 
  as_tibble() |> 
  group_by(build_Mean_slope_100m_DEM) |> 
  summarise(ci = list(mean_cl_normal(yhat))) |> 
  unnest(ci) |> 
  rename(x = build_Mean_slope_100m_DEM) |> 
  mutate(iv = 'build_Mean_slope_100m_DEM') |> 
  write_csv(paste0(getwd(), '/output_data/pdp/build_Mean_slope_100m_DEM_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~1 hr 18 mins; ~1 hr with 12 cores

 
 

 
 tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'parcel_Build_P'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) |> 
  as_tibble() |> 
  group_by(parcel_Build_P) |> 
  summarise(ci = list(mean_cl_normal(yhat))) |> 
  unnest(ci) |> 
  rename(x = parcel_Build_P) |> 
  mutate(iv = 'parcel_Build_P') |> 
  write_csv(paste0(getwd(), '/output_data/pdp/parcel_Build_P_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~53 mins, 12 cores
 

 
 
 
   

 
tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'build_p_building_200'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) |> 
  as_tibble() |> 
  group_by(build_p_building_200) |> 
  summarise(ci = list(mean_cl_normal(yhat))) |> 
  unnest(ci) |> 
  rename(x = build_p_building_200) |> 
  mutate(iv = 'build_p_building_200') |> 
  write_csv(paste0(getwd(), '/output_data/pdp/build_p_building_200_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~1 hr 12 mins w 10 cores, 50 mins 13 cores
 
 
 
 
tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_no_dins               # the model
           , pred.var = 'build_Mean_elev_30m'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) |> 
  as_tibble() |> 
  group_by(build_Mean_elev_30m) |> 
  summarise(ci = list(mean_cl_normal(yhat))) |> 
  unnest(ci) |> 
  rename(x = build_Mean_elev_30m) |> 
  mutate(iv = 'build_Mean_elev_30m') |> 
  write_csv(paste0(getwd(), '/output_data/pdp/build_Mean_elev_30m_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~1 hr 45 mins, 1 hr 15 mins with 10 cores
 
 
 
  


 
# tic()
# 
# cl<-makeCluster(split);
# registerDoParallel(cl);
# start.time = proc.time(); 
# 
# pdp::partial(cf_no_dins               # the model
#            , pred.var = 'parcel_Can_P'
#            , plot = FALSE
#            # , plot.engine = "ggplot2"
#            # , rug = TRUE
#            # , progress = "text"
#            , quantiles = TRUE
#            , probs = 0:20/20
#            , ice = TRUE
#            , center = TRUE
#            # , alpha = .1
#            , parallel = TRUE
#            ) |> 
#   as_tibble() |> 
#   group_by(parcel_Can_P) |> 
#   summarise(ci = list(mean_cl_normal(yhat))) |> 
#   unnest(ci) |> 
#   rename(x = parcel_Can_P) |> 
#   mutate(iv = 'parcel_Can_P') |> 
#   write_csv(paste0(getwd(), '/output_data/pdp/parcel_Can_P_', Sys.Date(), '.csv'))
# 
#  stopCluster(cl); toc(); beepr::beep() # ~53 mins, 12 cores
#  
#  
#  
#  
#  
# tic()
# 
# cl<-makeCluster(split);
# registerDoParallel(cl);
# start.time = proc.time(); 
# 
# pdp::partial(cf_no_dins               # the model
#            , pred.var = 'build_p_otherpaved_300'
#            , plot = FALSE
#            # , plot.engine = "ggplot2"
#            # , rug = TRUE
#            # , progress = "text"
#            , quantiles = TRUE
#            , probs = 0:20/20
#            , ice = TRUE
#            , center = TRUE
#            # , alpha = .1
#            , parallel = TRUE
#            ) |> 
#   as_tibble() |> 
#   group_by(build_p_otherpaved_300) |> 
#   summarise(ci = list(mean_cl_normal(yhat))) |> 
#   unnest(ci) |> 
#   rename(x = build_p_otherpaved_300) |> 
#   mutate(iv = 'build_p_otherpaved_300') |> 
#   write_csv(paste0(getwd(), '/output_data/pdp/build_p_otherpaved_300_', Sys.Date(), '.csv'))
# 
#  stopCluster(cl); toc(); beepr::beep() # ~53 mins, 12 cores

 
```

#### iv DINS CF

```{r eval=FALSE, include=FALSE}
# TODO Miranda, we can look at all plots, but maybe we just want to look at the top 10 or 20 top predictors
#2/23/22 Dexter I think top 10 seems fine, the Price MS only shows several in final MS.

## CF DINS #these are categorical outcomes, 4/4/2022, let's replace with next section with binary outcomes
# loop through predictors to get PDP
# first get the iterator, here the variable names

# using ALL predictors
(pdp_cf_dins_vars <- variable_importance %>% filter(Model == 'cf_dins') %>%                 pull(Variable))

```

#### v DINS CF - binary outcome

```{r eval=FALSE, include=FALSE}
# TODO Miranda, we can look at all plots, but maybe we just want to look at the top 10 or 20 top predictors
#2/23/22 Dexter I think top 10 seems fine, the Price MS only shows several in final MS.
#4/5/22 Dexter I ran this with 5 on my computer, just trying not to take too long. 



# using top n predictors
top_n <- 6          # set n (can revise to 20 or any other value greater than zero and less than 71)
(pdp_cf_dins_vars <- variable_importance %>% filter(Model == 'cf_dins_binary') %>% slice(1:top_n) %>% pull(Variable)) 

pdp_cf_dins_vars |> tibble()

detectCores(); # detect the number of cores of your cpu
split <- 10


tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_dins_binary               # the model
           , pred.var = 'build_WINDOWPANE'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) |> 
  as_tibble() |> 
  group_by(build_WINDOWPANE) |> 
  summarise(ci = list(mean_cl_normal(yhat))) |> 
  unnest(ci) |> 
  rename(x_chr = build_WINDOWPANE) |> 
  mutate(iv = 'build_WINDOWPANE') |> 
  write_csv(paste0(getwd(), '/output_data/pdp_dins/build_WINDOWPANE_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # ~45 seconds 500 trees and 10 cores.



 
 
 
 
 
 tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_dins_binary               # the model
           , pred.var = 'build_EAVES'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) |> 
  as_tibble() |> 
  group_by(build_EAVES) |> 
  summarise(ci = list(mean_cl_normal(yhat))) |> 
  unnest(ci) |> 
  rename(x_chr = build_EAVES) |> 
  mutate(iv = 'build_EAVES') |> 
  write_csv(paste0(getwd(), '/output_data/pdp_dins/build_EAVES_', Sys.Date(), '.csv'))

 stopCluster(cl); toc(); beepr::beep() # 45s





tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_dins_binary               # the model
           , pred.var = 'build_near_dest'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) |> 
  as_tibble() |> 
  group_by(build_near_dest) |> 
  summarise(ci = list(mean_cl_normal(yhat))) |> 
  unnest(ci) |> 
  rename(x = build_near_dest) |> 
  mutate(iv = 'build_near_dest') |> 
  write_csv(paste0(getwd(), '/output_data/pdp_dins/build_near_dest_', Sys.Date(), '.csv'))

stopCluster(cl); toc(); beepr::beep() # ~90 seconds





tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_dins_binary               # the model
           # , pred.var = 'build_p_otherpaved_200'
           , pred.var = 'build_p_otherpaved_300'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) |> 
  as_tibble() |> 
  group_by(build_p_otherpaved_300) |> 
  summarise(ci = list(mean_cl_normal(yhat))) |> 
  unnest(ci) |> 
  rename(x = build_p_otherpaved_300) |> 
  mutate(iv = 'build_p_otherpaved_300') |> 
  write_csv(paste0(getwd(), '/output_data/pdp_dins/build_p_otherpaved_300_', Sys.Date(), '.csv'))

stopCluster(cl); toc(); beepr::beep() # ~100s





tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_dins_binary               # the model
           , pred.var = 'build_VENTSCREEN'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) |> 
  as_tibble() |> 
  group_by(build_VENTSCREEN) |> 
  summarise(ci = list(mean_cl_normal(yhat))) |> 
  unnest(ci) |> 
  rename(x_chr = build_VENTSCREEN) |> 
  mutate(iv = 'build_VENTSCREEN') |> 
  write_csv(paste0(getwd(), '/output_data/pdp_dins/build_VENTSCREEN_', Sys.Date(), '.csv'))

stopCluster(cl); toc(); beepr::beep() # ~45s







# tic()
# 
# cl<-makeCluster(split);
# registerDoParallel(cl);
# start.time = proc.time(); 
# 
# pdp::partial(cf_dins_binary               # the model
#            , pred.var = 'build_min_dist_shrub'
#            , plot = FALSE
#            # , plot.engine = "ggplot2"
#            # , rug = TRUE
#            # , progress = "text"
#            , quantiles = TRUE
#            , probs = 0:20/20
#            , ice = TRUE
#            , center = TRUE
#            # , alpha = .1
#            , parallel = TRUE
#            ) |> 
#   as_tibble() |> 
#   group_by(build_min_dist_shrub) |> 
#   summarise(ci = list(mean_cl_normal(yhat))) |> 
#   unnest(ci) |> 
#   rename(x = build_min_dist_shrub) |> 
#   mutate(iv = 'build_min_dist_shrub') |> 
#   write_csv(paste0(getwd(), '/output_data/pdp_dins/build_min_dist_shrub_', Sys.Date(), '.csv'))
# 
# stopCluster(cl); toc(); beepr::beep() # ~100s



tic()

cl<-makeCluster(split);
registerDoParallel(cl);
start.time = proc.time(); 

pdp::partial(cf_dins_binary               # the model
           , pred.var = 'build_Mean_distroad'
           , plot = FALSE
           # , plot.engine = "ggplot2"
           # , rug = TRUE
           # , progress = "text"
           , quantiles = TRUE
           , probs = 0:20/20
           , ice = TRUE
           , center = TRUE
           # , alpha = .1
           , parallel = TRUE
           ) |> 
  as_tibble() |> 
  group_by(build_Mean_distroad) |> 
  summarise(ci = list(mean_cl_normal(yhat))) |> 
  unnest(ci) |> 
  rename(x = build_Mean_distroad) |> 
  mutate(iv = 'build_Mean_distroad') |> 
  write_csv(paste0(getwd(), '/output_data/pdp_dins/build_Mean_distroad_', Sys.Date(), '.csv'))

stopCluster(cl); toc(); beepr::beep() # ~100s


```


top
TODO add in next three predictors?

bottom
TODO wrap text
TODO reduce text on categorical



#### vi read in PDPs and graph
```{r}

top_n <- 9         # set n (can revise to 20 or any other value greater than zero and less than 71)
(pdp_cf_no_dins_vars <- variable_importance %>% filter(Model == 'cf_no_dins') %>% slice(1:top_n) %>% pull(Variable)) 


pdp_cf_no_dins_vars
pdp_cf_no_dins_vars |> data_frame()

(
  pdp_cf_no_dins_tibble <- tibble(files = dir('output_data/pdp', full.names = TRUE)) %>%
    mutate(file_contents = map(files, ~read_csv(., col_types = cols()))) |> # col_types = cols() just to be quiet
    unnest(file_contents) |> 
    select(-files) |> 
    left_join(variable_importance |> distinct(iv = Variable, Alias, Label, Type)
              , by = 'iv') |> 
    mutate(Label = factor(
        Label
      , levels = c(
          'Dist. to destroyed building'
        , 'Building area'
        , 'Dist. to major road'
        , 'Elevation, 100 m around bldg.'
        , 'Percent built, 300 ft'
        , 'Percent slope, 100 m around bldg.'
        # , 'Elevation, 30 m around bldg.'
        , 'Percent built, parcel'
        , 'Percent built, 200 ft'
        , 'Elevation, 30 m around bldg.'
        # , 'Percent tree, parcel'
        # , 'Percent paved, 300 ft'
        )
      , labels = c(
          'Dist. to destroyed\nbuilding'
        , 'Building area'
        , 'Dist. to major road'
        , 'Elevation, 100 m\naround bldg.'
        , 'Percent built,\n300 ft'
        , 'Slope,\n100 m around bldg.'
        # , 'Elevation, 30 m\naround bldg.'
        , 'Percent built, parcel'
        , 'Percent built, 200 ft'
        , 'Elevation, 30 m around bldg.'
        # , 'Percent tree, parcel'
        # , 'Percent paved, 300 ft'
        )
      , ordered = TRUE)
      ) |> 
    mutate(iv = factor(iv, levels = pdp_cf_no_dins_vars, labels = pdp_cf_no_dins_vars, ordered = TRUE)) # not really need anymore because we use Label instead
  )


pdp_cf_no_dins_tibble |> tabyl(iv)
pdp_cf_no_dins_tibble |> tabyl(Label)
# pdp_cf_no_dins_tibble |> tabyl(x)
bind_cols(pdp_cf_no_dins_tibble |> tabyl(iv),  
pdp_cf_no_dins_tibble |> tabyl(Label))

(
  b_g_build <- pdp_cf_no_dins_tibble |> 
    ggplot(aes(x, y, fill = Type)) + 
    geom_ribbon(aes(ymin = ymin, ymax = ymax)) +
    # geom_line(color = 'red') + 
    geom_line() + 
    # scale_fill_viridis_d(option = "A", end = .8) + 
    scale_fill_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
        )
      , labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
        )
      , drop = FALSE
    ) +
    geom_hline(yintercept = 0, col = 'dark gray') + 
    theme_bw(16) + 
    labs(y = 'Probability', x = '') + 
    scale_x_continuous(labels = scales::comma_format()) +
    # scale_x_continuous(labels = scales::label_number(suffix = " K", scale = 1e-6)) + # thousands
    theme(legend.position = 'none', axis.text.x = element_text(size = 8.25)) + 
    # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
    # facet_wrap(~str_wrap(Label, 20), scales = 'free_x') +
    facet_wrap(~Label, scales = 'free_x') +
    NULL
  )

library(patchwork)
# a_importance_graph_no_dins / b_g_build
(importance_pdp_1 <- a_importance_graph_no_dins + 
  inset_element(b_g_build , left = 0.15, bottom = 0.03, right = .95, top = .93))
  
# importance_pdp_1 |>
# ggsave(file = paste0(getwd(), '/figures/importance_pdp_top_9_', Sys.Date(), '.png')
#          , height = 6.5*2, width = 6.5*2)

#   ggsave(file = paste0(getwd(), '/figures/cf_dins_binary/', variable, '_', Sys.Date(), '.png')
#          , width = 6.5*2
#          , height = 6.5*1.5
#          , dpi = resolution)


(pdp_cf_dins_vars <- variable_importance %>% filter(Model == 'cf_dins_binary') %>% slice(1:top_n) %>% pull(Variable)) 

pdp_cf_dins_vars

(
  pdp_cf_dins_tibble <- tibble(files = dir('output_data/pdp_dins', full.names = TRUE)) %>%
    mutate(file_contents = map(files,~read_csv(., col_types = cols()))) |> #, col_types = 'fdddf'))) |> 
    # mutate(file_contents = map(files, ~mutate(., ifelse(is.character(.$iv),))))
    unnest(file_contents) |> 
    select(-files) |> 
    left_join(variable_importance |> distinct(iv = Variable, Alias, Label, Type)
              , by = 'iv') |> 
    mutate(iv = factor(iv, levels = pdp_cf_dins_vars, labels = pdp_cf_dins_vars, ordered = TRUE)) 
  )

pdp_cf_dins_tibble |> tabyl(iv)
pdp_cf_dins_tibble |> tabyl(Alias, iv)
# pdp_cf_no_dins_tibble |> tabyl(x)



# # great start to graphs!
# pdp_cf_no_dins_tibble |>
#   filter(is.na(x_chr)) |>
#   ggplot(aes(x, y)) +
#   geom_ribbon(aes(ymin = ymin, ymax = ymax)) +
#   geom_line(color = 'red') +
#   geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
#   theme_bw(16) +
#   facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
#   NULL
# 
# pdp_cf_no_dins_tibble |> 
#   filter(!is.na(x_chr)) |>
#   # ggplot(aes(x_chr, y)) + 
#   ggplot(aes(y, x_chr)) + 
#   # geom_errorbar(aes(ymin = ymin, ymax = ymax), width = .1, size = 1) + 
#   geom_errorbarh(aes(xmin = ymin, xmax = ymax), size = 1) + 
#   geom_vline(xintercept = 0, col = 'gray', size = 1) + 
#   geom_point(color = 'red', size = 3) + 
#   theme_bw(16) + 
#   facet_wrap(~iv) +
#   NULL
# 
# pdp_cf_no_dins_tibble |>
#   filter(!is.na(x_chr)) |>
#   ggplot(aes(x_chr, y)) +
#   # ggplot(aes(y, x_chr)) +
#   geom_errorbar(aes(ymin = ymin, ymax = ymax), width = .1, size = 1) +
#   # geom_errorbarh(aes(xmin = ymin, xmax = ymax), size = 1) +
#   # geom_vline(xintercept = 0, col = 'gray', size = 1) +
#   geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
#   geom_point(color = 'red', size = 3) +
#   theme_bw(16) +
#   theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) +
#   facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
#   NULL



(
  b_build_WINDOWPANE <- pdp_cf_dins_tibble |>
    filter(iv == 'build_WINDOWPANE') |>
    ggplot(aes(x_chr, y)) +
    geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
    geom_errorbar(aes(ymin = ymin, ymax = ymax), width = .1, size = 1) +
    geom_point(aes(color = Type), size = 3) +
    scale_color_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
      ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
      )
      # , drop = FALSE
    ) +
    theme_bw(16) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
          , axis.title.x = element_text(size = 12)
          , legend.position = 'none') +
    # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
    facet_wrap(~str_wrap(Label, 30), scales = 'free_x') +
    labs(y = 'Probability'
         , x = ''
         # , x = '(Multi Pane\nas ref.)'
         ) + 
    NULL
  )

(
  c_build_EAVES <- pdp_cf_dins_tibble |>
    filter(iv == 'build_EAVES') |>
    ggplot(aes(x_chr, y)) +
    geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
    geom_errorbar(aes(ymin = ymin, ymax = ymax), width = .1, size = 1) +
    geom_point(aes(color = Type), size = 3) +
    scale_color_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
      ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
      )
    ) +
    theme_bw(16) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
          , axis.title.x = element_text(size = 12)
          , legend.position = 'none') +
    # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
    facet_wrap(~str_wrap(Label, 30), scales = 'free_x') +
    labs(y = ''
         , x = ''
         # , x = '(Enclosed\nas ref.)'
         ) + 
    NULL
  )

(
  d_build_near_dest <- pdp_cf_dins_tibble |>
    filter(iv == 'build_near_dest') |>
    ggplot(aes(x, y, fill = Type)) +
    geom_ribbon(aes(ymin = ymin, ymax = ymax)) +
    geom_line() +
    scale_color_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
      ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
      )
    ) +
    geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
    theme_bw(16) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
          , axis.title.x = element_text(size = 12)
          , legend.position = 'none') +
    # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
    facet_wrap(~str_wrap(Label, 12), scales = 'free_x') +
    labs(y = ''
         , x = ''
         # , x = 'Distance'
         ) + 
    NULL
  )


# (
#   e_build_p_otherpaved_200 <- pdp_cf_dins_tibble |>
#     filter(iv == 'build_p_otherpaved_200') |>
#     ggplot(aes(x, y, fill = Type)) +
#     geom_ribbon(aes(ymin = ymin, ymax = ymax)) +
#     geom_line() +
#     scale_color_manual(
#       values = c(
#           '#13082c' # purple
#         , '#4e0070'
#         , '#9d006e'
#         , '#f4264e'
#         , '#ff8650' # orange
#       ),
#       labels = c(
#           'Construction'
#         , 'Defensible Sapce'
#         , 'Exposure'
#         , 'Landscape Attributes'
#         , 'Topography'
#       )
#     ) +
#     geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
#     theme_bw(16) +
#     theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
#           , axis.title.x = element_text(size = 12)
#           , legend.position = 'none') +
#     # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
#     facet_wrap(~str_wrap(Label, 12), scales = 'free_x') +
#     labs(y = 'Probability'
#          , x = ''
#          # , x = '% cover'
#          ) + 
#     NULL
#   )



(
  e_build_p_otherpaved_300 <- pdp_cf_dins_tibble |>
    filter(iv == 'build_p_otherpaved_300') |>
    ggplot(aes(x, y, fill = Type)) +
    geom_ribbon(aes(ymin = ymin, ymax = ymax)) +
    geom_line() +
    scale_color_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
      ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
      )
    ) +
    geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
    theme_bw(16) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
          , axis.title.x = element_text(size = 12)
          , legend.position = 'none') +
    # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
    facet_wrap(~str_wrap(Label, 12), scales = 'free_x') +
    labs(y = 'Probability'
         , x = ''
         # , x = '% cover'
         ) + 
    NULL
  )


(
  f_build_VENTSCREEN <- pdp_cf_dins_tibble |>
    filter(iv == 'build_VENTSCREEN') |>
    ggplot(aes(x_chr, y)) +
    geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
    geom_errorbar(aes(ymin = ymin, ymax = ymax), width = .1, size = 1) +
    geom_point(aes(color = Type), size = 3) +
    scale_color_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
      ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
      )
    ) +
    theme_bw(16) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
          , axis.title.x = element_text(size = 12)
          , legend.position = 'none') +
    # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
    facet_wrap(~str_wrap(Label, 30), scales = 'free_x') +
    labs(y = ''
         , x = ''
         # , x = '(Unscreened\nas ref.)'
         ) + 
    NULL
  )



# (
#   g_build_min_dist_shrub <- pdp_cf_dins_tibble |>
#     filter(iv == 'build_min_dist_shrub') |>
#     ggplot(aes(x, y, fill = Type)) +
#     geom_ribbon(aes(ymin = ymin, ymax = ymax)) +
#     geom_line() +
#     scale_color_manual(
#       values = c(
#           '#13082c' # purple
#         , '#4e0070'
#         , '#9d006e'
#         , '#f4264e'
#         , '#ff8650' # orange
#       ),
#       labels = c(
#           'Construction'
#         , 'Defensible Sapce'
#         , 'Exposure'
#         , 'Landscape Attributes'
#         , 'Topography'
#       )
#     ) +
#     geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
#     theme_bw(16) +
#     theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
#           , axis.title.x = element_text(size = 12)
#           , legend.position = 'none') +
#     # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
#     facet_wrap(~str_wrap(Label, 12), scales = 'free_x') +
#     labs(y = ''
#          , x = ''
#          # , x = 'Distance'
#          ) +
#     NULL
#   )


(
  g_build_Mean_distroad <- pdp_cf_dins_tibble |>
    filter(iv == 'build_Mean_distroad') |>
    ggplot(aes(x, y, fill = Type)) +
    geom_ribbon(aes(ymin = ymin, ymax = ymax)) +
    geom_line() +
    scale_color_manual(
      values = c(
          '#13082c' # purple
        , '#4e0070'
        , '#9d006e'
        , '#f4264e'
        , '#ff8650' # orange
      ),
      labels = c(
          'Construction'
        , 'Defensible Sapce'
        , 'Exposure'
        , 'Landscape Attributes'
        , 'Topography'
      )
    ) +
    geom_hline(yintercept = 0, col = 'dark gray', size = 1) +
    theme_bw(16) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5, size = 8)
          , axis.title.x = element_text(size = 12)
          , legend.position = 'none') +
    # facet_wrap(~str_wrap(Alias, 30), scales = 'free_x') +
    facet_wrap(~str_wrap(Label, 12), scales = 'free_x') +
    labs(y = ''
         , x = ''
         # , x = 'Distance'
         ) +
    NULL
  )


pdp_cf_no_dins_tibble |> tabyl(iv)
# library(patchwork)
# a_importance_graph_dins / 
#   (b_build_WINDOWPANE + c_build_EAVES + d_build_near_dest) / 
#   (e_build_p_otherpaved_200 +  f_build_VENTSCREEN + g_build_min_dist_shrub) + 
#   plot_annotation(tag_levels = 'A')


insets <- (b_build_WINDOWPANE + c_build_EAVES + d_build_near_dest) / 
  (#e_build_p_otherpaved_200 
    e_build_p_otherpaved_300
    +  f_build_VENTSCREEN + g_build_Mean_distroad
     # g_build_min_dist_shrub
     )

(importance_pdp_2 <- a_importance_graph_dins + 
  inset_element(insets, left = 0.3, bottom = 0.05, right = .95, top = .8))
  

importance_pdp_2 |>
ggsave(file = paste0(getwd(), '/figures/importance_pdp_2_', Sys.Date(), '.png')
         , height = 6.5*2, width = 6.5*2)


```



```{r, citations}
lapply(packages, citation)
```

Last knit on `r format(Sys.time())`

```{r}
system.time(save.image(file = paste0('saved_sessions/wui_r_models_', gsub('[[:punct:]]', '-', Sys.time()), '.RData')))
```
