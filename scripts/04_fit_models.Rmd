---
title: "04_fit_models"
author: "Dexter H. Locke, PhD"
date: "`r format(Sys.time())`"
output: html_document
editor_options: 
  chunk_output_type: console
---

# TODO fit model with 'best' land cover instead of distance

# TODO focus only on residential



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This assumes "02_Woosley_combine_data.Rmd" was run



## 0 set up: load libraries, custom functions, set defaults
```{r}
# load libraries
# packages we'll be using
packs <- c('tidyverse'        # a must have!
           , 'tidylog'        # makes things very verbose for 2x checking 
           , 'magrittr'       # all of the pipes
           , 'janitor'        # cleans things up
           , 'sf'             # simple features
           , 'mapview'        # quick webmaps for zoom/pan viz
           #'tidycensus',     # access to Census data in a tidy way
           #'party',          # random forests
           , 'modEvA'         # contains D-squared function
           , 'randomForest', 'rfUtilities', 'verification'
           , 'tictoc'         # times things
           , 'beepr'          # makes noises
           , 'broom'          # tidy up regression models
           , 'performance'    # nice regression diagnostics
           , 'psych'          # describe is very useful for descriptive statistics
           , 'sjPlot'         # useful plotting and regression support
           , 'rpart'          # for random forests
           # , pROC           # for AUC calculation
           )        

# check for all of the libraries
if (length(setdiff(packs, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packs, rownames(installed.packages())))  
}

# lapply(packs, library, character.only = TRUE)
vapply(packs, library, character.only = TRUE, logical(1),
       logical.return = TRUE, quietly = TRUE)


# custom function for "Not In"
`%nin%` <- Negate(`%in%`)


set.seed(19870630)
```



## 1 read in the data
```{r}
# build <- read_csv(paste0(getwd(), '/output_data/building_2021-04-26.csv')) %>% glimpse
# build <- read_csv(paste0(getwd(), '/output_data/building_2021-09-27.csv')) %>% glimpse
# build <- read_csv(paste0(getwd(), '/output_data/building_2021-10-05.csv')) %>% glimpse
# build <- read_csv(paste0(getwd(), '/output_data/building_2021-11-03.csv')) %>% glimpse

build <- read_csv(paste0(getwd(), '/output_data/building_2021-12-02.csv')) %>% glimpse

build %>%
  mutate_if(is.character, as.factor) #need factors for analyses to come
```

## 2 fit models
### A univariate-logistic regression 
```{r}

tic(); uni_log_mods <- build %>%
  filter(parcel_UseType == 'Residential') %>% 
  nest(data=everything()) %>%
  # nest()%>%
  mutate(
    # ~landscape position
    log_build_Mean_elev_30 = map(., ~glm(damage_binary ~ build_Mean_elev_30m, family = binomial, data = data.frame(.))),
    log_build_Mean_elev_100= map(., ~glm(damage_binary ~ build_Mean_elev_100m,family = binomial, data = data.frame(.))),
    
    log_build_Mean_slope_30 = map(., ~glm(damage_binary ~ build_Mean_slope_30m_DEM, family = binomial, data = data.frame(.))),
    log_build_Mean_slope_100= map(., ~glm(damage_binary ~ build_Mean_slope_100m_DEM,family = binomial, data = data.frame(.))),
    
    log_build_Mean_aspect_30 = map(., ~glm(damage_binary ~ build_Mean_aspect_30m_DEM, family= binomial, data = data.frame(.))),
    log_build_Mean_aspect_100= map(., ~glm(damage_binary ~ build_Mean_aspect_100m_DEM,family= binomial, data = data.frame(.))),
    
     # land cover
    log_build_p_tree_10 = map(., ~glm(damage_binary ~ build_p_tree_10, family = binomial, data = data.frame(.))),
    log_build_p_tree_100= map(., ~glm(damage_binary ~ build_p_tree_100,family = binomial, data = data.frame(.))),
    log_build_p_tree_200= map(., ~glm(damage_binary ~ build_p_tree_200,family = binomial, data = data.frame(.))),
    log_build_p_tree_300= map(., ~glm(damage_binary ~ build_p_tree_300,family = binomial, data = data.frame(.))),
  
    log_build_p_grass_10 = map(., ~glm(damage_binary ~ build_p_grass_10, family = binomial, data = data.frame(.))),
    log_build_p_grass_100= map(., ~glm(damage_binary ~ build_p_grass_100,family = binomial, data = data.frame(.))),
    log_build_p_grass_200= map(., ~glm(damage_binary ~ build_p_grass_200,family = binomial, data = data.frame(.))),
    log_build_p_grass_300= map(., ~glm(damage_binary ~ build_p_grass_300,family = binomial, data = data.frame(.))),
    
    log_build_p_soil_10 = map(., ~glm(damage_binary ~ build_p_soil_10, family = binomial, data = data.frame(.))),
    log_build_p_soil_100= map(., ~glm(damage_binary ~ build_p_soil_100,family = binomial, data = data.frame(.))),
    log_build_p_soil_200= map(., ~glm(damage_binary ~ build_p_soil_200,family = binomial, data = data.frame(.))),
    log_build_p_soil_300= map(., ~glm(damage_binary ~ build_p_soil_300,family = binomial, data = data.frame(.))),
    
    log_build_p_water_10 = map(., ~glm(damage_binary ~ build_p_water_10, family = binomial, data = data.frame(.))),
    log_build_p_water_100= map(., ~glm(damage_binary ~ build_p_water_100,family = binomial, data = data.frame(.))),
    log_build_p_water_200= map(., ~glm(damage_binary ~ build_p_water_200,family = binomial, data = data.frame(.))),
    log_build_p_water_300= map(., ~glm(damage_binary ~ build_p_water_300,family = binomial, data = data.frame(.))),
    
    log_build_p_buliding_10 = map(., ~glm(damage_binary ~ build_p_building_10, family = binomial, data = data.frame(.))),
    log_build_p_buliding_100= map(., ~glm(damage_binary ~ build_p_building_100,family = binomial, data = data.frame(.))),
    log_build_p_buliding_200= map(., ~glm(damage_binary ~ build_p_building_200,family = binomial, data = data.frame(.))),
    log_build_p_buliding_300= map(., ~glm(damage_binary ~ build_p_building_300,family = binomial, data = data.frame(.))),
    
    log_build_p_road_10 = map(., ~glm(damage_binary ~ build_p_road_10, family = binomial, data = data.frame(.))),
    log_build_p_road_100= map(., ~glm(damage_binary ~ build_p_road_100,family = binomial, data = data.frame(.))),
    log_build_p_road_200= map(., ~glm(damage_binary ~ build_p_road_200,family = binomial, data = data.frame(.))),
    log_build_p_road_300= map(., ~glm(damage_binary ~ build_p_road_300,family = binomial, data = data.frame(.))),
    
    log_build_p_otherpaved_10 = map(., ~glm(damage_binary ~ build_p_otherpaved_10, family = binomial, data = data.frame(.))),
    log_build_p_otherpaved_100= map(., ~glm(damage_binary ~ build_p_otherpaved_100,family = binomial, data = data.frame(.))),
    log_build_p_otherpaved_200= map(., ~glm(damage_binary ~ build_p_otherpaved_200,family = binomial, data = data.frame(.))),
    log_build_p_otherpaved_300= map(., ~glm(damage_binary ~ build_p_otherpaved_300,family = binomial, data = data.frame(.))),
    
    log_build_p_shrub_10 = map(., ~glm(damage_binary ~ build_p_shrub_10, family = binomial, data = data.frame(.))),
    log_build_p_shrub_100= map(., ~glm(damage_binary ~ build_p_shrub_100,family = binomial, data = data.frame(.))),
    log_build_p_shrub_200= map(., ~glm(damage_binary ~ build_p_shrub_200,family = binomial, data = data.frame(.))),
    log_build_p_shrub_300= map(., ~glm(damage_binary ~ build_p_shrub_300,family = binomial, data = data.frame(.))),

    # nearest distance to destroyed building 
    log_build_near_dist_dest= map(., ~glm(damage_binary ~ build_near_dest,family = binomial, data = data.frame(.))),
    
    # nearest distance to any building
    log_build_near_dist_build = map(., ~glm(damage_binary ~ build_dist_to_build_ft_jod,family = binomial, data = data.frame(.)))
    ) %>%
  dplyr::select(-data) %>% 
  rowid_to_column() %>% 
  pivot_longer(-rowid, names_to = 'model_name', values_to = 'model') %>% 
  dplyr::select(-rowid) %>% 
  separate(col = model_name, into = c('trash_1', 'trash_2', 'trash_3', 'var', 'dist'), remove = FALSE, convert = TRUE) %>% 
  dplyr::select(-starts_with('trash_')) %>% 
  mutate(#smry = map(model, summary),
         dsqr = map(model, Dsquared),
         AIC = map(model, AIC),
         r2 = map(model, performance::r2),
         rmse = map(model, performance::rmse)); toc()


# extract goodness of fit measures
(
  gof <- uni_log_mods %>% 
    dplyr::select(-model_name, -model) %>% 
    # dplyr::select(var, dist, AIC, dsqr, r2) %>%
    # unnest(dsqr, AIC, r2) %>% unnest(r2)
    unnest(everything()) %>% 
    unnest(everything())
)


# which distance provides the best fit per variable?
# in the case of build_near_dest and build_dist_to_build_ft_jod, pick between destroyed or not
(
  best_dist <- gof %>% 
    group_by(var) %>% 
    summarise(max_d = dist[which.max(dsqr)],
              max_r = dist[which.max(r2)],
              min_AIC=dist[which.min(AIC)],
              min_rmse=dist[which.min(rmse)]) 
)


(
  best_var <- gof %>% 
    group_by(dist) %>% 
    summarise(max_d = var[which.max(dsqr)],
              max_r = var[which.max(r2)],
              min_AIC= var[which.min(AIC)],
              min_rmse= var[which.min(rmse)]) 
)


# cut out non-land cover variables
(
  best_var_lc <- gof %>%
    filter(var %nin% c('elev', 'slope', 'aspect', 'dist')) %>% 
    group_by(dist) %>% 
    summarise(max_d = var[which.max(dsqr)],
              max_r = var[which.max(r2)],
              min_AIC= var[which.min(AIC)],
              min_rmse= var[which.min(rmse)]) 
)



# # Is this needed or confusing?
# (
#   best_var_by_dist <- gof %>% 
#     group_by(var, dist) %>% 
#     summarise(max_d = var[which.max(dsqr)],
#               max_r = var[which.max(r2)],
#               min_AIC= var[which.min(AIC)],
#               min_rmse= var[which.min(rmse)]) 
# )

# Dexter, near_dest is nearest distance to destroyed building. near_exp is nearest distance to any building with wildfire damage
# that is, exposed
# we have the work showing that destroyed is better. they are also highly correlated in script 03. I think we can just use near_dest
# near_dest - better predictor than near_exposure. 
    log_near_dest <- glm(damage_binary ~ build_near_dest, 
                         family = binomial, data = build)
    log_near_exp <- glm(damage_binary ~ build_near_exp, family = binomial, data = build)
    
    anova(log_near_dest, log_near_exp)

# destroyed is better, *JUST* like Miranda said it was
compare_performance(log_near_dest, log_near_exp, rank = TRUE)



```





### B data prep 
```{r}

#data prep

build_a <- build %>% #retain only the 71 predictors of interest for final analyses and damage_binary as response 
  tidylog::select(damage_binary,
                  build_area    ,
            build_DECKPORCHE    ,
            build_DECKPORCHO    ,
                 build_EAVES    ,
            build_EXTERIORSI    ,
            build_FENCEATTAC    ,
            build_PATIOCOVER    ,
            build_PROPANETAN    ,
            build_ROOFCONSTR    ,
           build_VEGCLEARAN    ,
           build_VENTSCREEN    ,
           build_WINDOWPANE    ,
          parcel_year_built    ,
 build_dist_to_build_ft_jod    ,
    build_has_tree_overhang    ,
       build_min_dist_shrub    ,
        build_min_dist_tree    ,
          build_overhang_ht    ,
        build_perc_overhang    ,
             parcel_Build_P    ,
               parcel_Can_P    ,
             parcel_Grass_P    ,
            parcel_Imperv_P   , #inverse of perv surface
             parcel_Paved_P    ,
            #  parcel_Perv_P    ,#inverse of imp, just need one
              parcel_Road_P    ,
             parcel_Shrub_P    ,
              parcel_Soil_P    ,
             parcel_Water_P    ,
            build_near_dest    ,
        build_p_building_10    ,
       build_p_building_100    ,
       build_p_building_200    ,
       build_p_building_300    ,
           build_p_grass_10    ,
          build_p_grass_100    ,
          build_p_grass_200    ,
          build_p_grass_300    ,
      build_p_otherpaved_10    ,
     build_p_otherpaved_100    ,
     build_p_otherpaved_200    ,
     build_p_otherpaved_300    ,
            build_p_road_10    ,
           build_p_road_100    ,
           build_p_road_200    ,
           build_p_road_300    ,
           build_p_shrub_10    ,
          build_p_shrub_100    ,
          build_p_shrub_200    ,
          build_p_shrub_300    ,
            build_p_soil_10    ,
           build_p_soil_100    ,
         build_p_soil_200    ,
           build_p_soil_300    ,
            build_p_tree_10    ,
           build_p_tree_100    ,
           build_p_tree_200    ,
           build_p_tree_300    ,
           build_p_water_10    ,
          build_p_water_100    ,
          build_p_water_200    ,
          build_p_water_300    ,
                parcel_area    ,
       build_Mean_builddens    ,
    build_Mean_distall_road    ,
        build_Mean_distroad    ,
 build_Mean_aspect_100m_DEM    ,
  build_Mean_aspect_30m_DEM    ,
       build_Mean_elev_100m    ,
        build_Mean_elev_30m    ,
  build_Mean_slope_100m_DEM    ,
   build_Mean_slope_30m_DEM) %>% 
  data.frame()



####Univariate models and deviance calcs
# for building materials we used a logit link and specified a binomial response, then calculated and compared the
# deviance explained (D2), which is analogous to R-squared in linear regression for each variable.
# table1 contains a list of predictor variables for analysis and vectors to store the results for each variable 

 
(table1 <- list(names(build_a)) %>% #created a list of predictors
  data.frame() %>% 
  mutate(dev2 = 0, n2 = 0) %>%
  rename(upvar = c..damage_binary....build_area....build_DECKPORCHE....build_DECKPORCHO...) %>%
  data.frame())

# repurposed from Owne Price
dat.model <- data.frame(y = build_a$damage_binary, x = 0)

i<-0
for (varname in table1$upvar) {
  i<-i+1
  if (varname %in% colnames(build_a)) {
    dat.model$x <- build_a[, varname]
    mod <- glm(y ~ x, data = dat.model, family = binomial())
  } else {
    warning(varname, " not found in build_a", immediate. = TRUE)
    mod <- NULL
  }
  
  if (!is.null(mod)) {
    table1$n2[i] <- nrow(build_a) - sum(is.na(dat.model$x))
    table1$dev2[i] <- 100 * (mod$null.deviance - mod$deviance) / mod$null.deviance
  }
}

# Mockrin: we may cut 4 DINS variables, waiting to hear back from Alex

# TODO drop 'parcel_Perv_P' here or above
#read in variable descriptions
(tab_labs <- readxl::read_xlsx('data/Data LA Study 20211208.xlsx') %>% 
  left_join(.
            , table1 %>% filter(upvar != 'damage_binary')
            , by = c(`Variable name` = 'upvar')) %>% 
  tidylog::select(Type
                  , `Variable name`
                  , Deviance = dev2
                  , n = n2
                  , Scale
                  , Source
                  ) %>% 
  arrange(Type, desc(Deviance)) %>% 
  mutate_if(is.double, round, 3))

tab_labs %>% 
  write_csv(paste0(getwd(), 'data/Table_XX_Deviance_Explained.csv'))

#next steps for getting table to look nice 
#If you already have the variable name, type look up table, why not add a pretty variable/alias name for reporting? build_DECKPORCHE,

#for example, could be in human-friendly English.
# TODO in Data LA Study 20211208.xlsx


#output
# tab_labs %>% 
#   write_csv('data/high_deviance_explained_bivariates.csv')

# ended __________


```




### C Random forest
```{r} 

# binary outcome random forest forall obs, drop DINS columns
tic()
binary_without_dins_cols <- rpart(damage_binary ~ ., 
                                  data = build_a %>% 
                                    tidylog::select( # dropping columns containing specific DINS data
                                            # very detailed but sparse (lots of NAs)
                                      !c(  build_DECKPORCHE
                                         , build_DECKPORCHO
                                         , build_EAVES
                                         , build_EXTERIORSI
                                         , build_FENCEATTAC
                                         , build_PATIOCOVER
                                         , build_PROPANETAN
                                         , build_ROOFCONSTR
                                         , build_VEGCLEARAN
                                         , build_VENTSCREEN
                                         , build_WINDOWPANE    
                                    ))
                                  , method = 'anova'); toc()

plot(binary_without_dins_cols)
summary(binary_without_dins_cols) # 11181  observations
plot(binary_without_dins_cols, branch=0.5); text(binary_without_dins_cols,cex=0.7)

# code from Owen
windows(4.5,4.5)
par(mar=c(1,1,2,1))
binary_without_dins_cols_pruned<-prune(binary_without_dins_cols,cp=0.02)
plot(binary_without_dins_cols_pruned,branch=0.5);text(binary_without_dins_cols_pruned,cex=0.7)
printcp(binary_without_dins_cols_pruned)
print(binary_without_dins_cols_pruned)



# binary outcome for just DINS-surveyed buildings, including those more specific colums
tic()
binary_with_dins_cols <- rpart(damage_binary ~ .
                               , data = build %>% 
                                 filter(build_DINS==1) %>% 
                                # damage_severity
                                tidylog::select(any_of(table1$upvar)),
                              , method = 'anova'); toc()

plot(binary_with_dins_cols)
summary(binary_with_dins_cols) # 11181  observations
plot(binary_with_dins_cols, branch=0.5); text(binary_with_dins_cols,cex=0.7)

# code from Owen
windows(4.5,4.5)
par(mar=c(1,1,2,1))
binary_with_dins_cols_pruned<-prune(binary_with_dins_cols, cp=0.02)
plot(binary_with_dins_cols_pruned,branch=0.5);text(binary_with_dins_cols_pruned,cex=0.7)
printcp(binary_with_dins_cols_pruned)
print(binary_with_dins_cols_pruned)




# severity for just DINS-surveyed buildings, including those more specific colums
tic()
severity_with_dins_cols <- rpart(damage_severity ~ .
                               , data = build %>% 
                                 filter(build_DINS==1) %>% 
                                tidylog::select(damage_severity
                                                , any_of(table1$upvar)
                                                , -damage_binary),
                              , method = 'anova'); toc()

plot(severity_with_dins_cols)
summary(severity_with_dins_cols) # 11181  observations
plot(severity_with_dins_cols, branch=0.5); text(severity_with_dins_cols,cex=0.7)

# code from Owen
windows(4.5,4.5)
par(mar=c(1,1,2,1))
severity_with_dins_cols_pruned<-prune(severity_with_dins_cols,cp=0.02)
plot(severity_with_dins_cols_pruned,branch=0.5);text(severity_with_dins_cols_pruned,cex=0.7)
printcp(severity_with_dins_cols_pruned)
print(severity_with_dins_cols_pruned)


# look at pruned models side by side
print(binary_without_dins_cols_pruned)
print(binary_with_dins_cols_pruned)
print(severity_with_dins_cols_pruned)


summary(binary_without_dins_cols_pruned)
summary(binary_with_dins_cols_pruned)
summary(severity_with_dins_cols_pruned)


TODO model validation/diagnostics
TODO selection
TODO model accuracy


 
#Owen's code OOB accuracy testing
# combdat$predtree<-predict(final3, OOB = TRUE)
# auc(roc(testdat$DAMAGED.x,predict(final2,testdat)))
# auc(roc(moddat$DAMAGED.x,predict(final2,moddat)))
# moddat$pred <- predict(final3, OOB = TRUE)
# moddat$predtrue <- moddat$pred>0.37
# with(moddat,table(DAMAGED.x,predtrue))

#need to divide data into test (25%) and model (75%)
log_build_reg_data$RANDSEL.x<-round(runif(nrow(log_build_reg_data)),2)
testdat<-subset(log_build_reg_data,RANDSEL.x>0.75) #not the same obs every time, and also need to drop randsel?
moddat<-subset(log_build_reg_data,RANDSEL.x<=0.75) #not the same obs every time, and also need to drop randsel?

#can't get the below to work, number of samples wrong
#Bagging with ipred instead? https://uc-r.github.io/regression_trees
log_build_reg_data$predtree<-predict(maximal_rpart, OOB = TRUE) 
log_build_reg_data$predtree<-predict(maximal_rpart, OOB = TRUE)
auc(roc(testdat$DAMAGED.x,predict(final,testdat)))
auc(roc(moddat$DAMAGED.x,predict(final,moddat)))
moddat$pred <- predict(maximal_rpart, OOB = TRUE)
moddat$predtrue <- moddat$pred>0.37
with(moddat,table(DAMAGED.x,predtrue))

# testdat$pred <- predict(final3,testdat, OOB = TRUE)
# testdat$predtrue <- testdat$pred>0.15
# with(testdat,table(DAMAGED.x,predtrue))
 
testdat$pred <- predict(maximal_rpart,testdat, OOB = TRUE)
testdat$predtrue <- testdat$pred>0.15
with(testdat,table(DAMAGED.x,predtrue))




```



### Fit Jeffrey Evan's worked example: randomForest
```{r}
# modeled after and adapted from this page
# from https://evansmurphy.wixsite.com/evansspatial/random-forest-sdm

# abbridged from J Evan's second chunk (chunk 1 accesses data)
# library(randomForest)
# library(rfUtilities)

b <- 1001                                     # Number of Bootstrap replicates
# snip
# chunks 3 and 4 import raster dadta and extract variables from raster to absence/present point locations
# snip

log_build_reg_data

log_build_reg_data %>% tabyl(damage_binary)

# remove build_has_tree_overhang?
log_build_reg_data %<>% mutate(damage_binary = as.factor(damage_binary)) %>% data.frame()# PAY ATTENTION HERE
log_build_reg_data %>% glimpse

rf_collinearity_test <- log_build_reg_data %>% 
  tidylog::select(where(is.double))

(cl <- multi.collinear(rf_collinearity_test[,2:ncol(rf_collinearity_test)], p = 0.05))

# tell us what's got to go!
for(l in cl) {
  cl.test <- rf_collinearity_test[,-which(names(rf_collinearity_test)==l)]
  print(paste("Remove variable", l, sep=": "))
  multi.collinear(cl.test, p=0.05)
}


log_build_reg_data_cl <- log_build_reg_data[,-which(names(log_build_reg_data) %in% cl )] 
# %>% # should not be needed any more
#   data.frame() %>%
#   mutate_if(is.character, as.factor)

# Chunk 8 makes depenent variable categorical (done). BUT it also checks for frequency of presense

# "We observe that the sample balance of presence locations is 33% thus, meeting the 1/3 rule for sample balance."

log_build_reg_data_cl %>% tabyl(damage_binary)
print('12% - is this a problem?!?!')

# model selection
# ( rf.model <- rf.modelSel(x=sdata@data[,3:ncol(sdata@data)], y=sdata@data[,"Present"], imp.scale="mir", ntree=b) )

tic() # clock in
(rf.model <- rf.modelSel(x=log_build_reg_data_cl[,2:ncol(log_build_reg_data_cl)],
                         y=log_build_reg_data_cl[,"damage_binary"],
                         imp.scale="mir", ntree=b))
toc() # clock out, about 3 minutes
beepr::beep()


sel.vars <- rf.model$selvars

# OR, pick a model?
#sel.vars <- rf.model$parameters[[4]] # DECISION POINT

# run a model
tic() # clock in
(rf.fit <- randomForest(y=log_build_reg_data_cl[,"damage_binary"],
                        x=log_build_reg_data_cl[,sel.vars],
                        ntree=b,
                        importance=TRUE, norm.votes=TRUE, proximity=TRUE) )
toc() # clock out, about 3 minutes
beepr::beep()

  
  # run a model with ALL PREDICTORS
  tic() # clock in
  ( rf.fit_all <- randomForest(y=log_build_reg_data_cl[,"damage_binary"],
                               x=log_build_reg_data_cl[,2:ncol(log_build_reg_data_cl)],
                           ntree=b,
                           importance=TRUE, norm.votes=TRUE, proximity=TRUE) )
  toc() # clock out, about 4 minutes
  beepr::beep()


tic() # clock in
( imbal <- randomForestSRC::imbalanced(damage_binary~., data=log_build_reg_data_cl) )
toc() # clock out, about 3 minutes
beepr::beep()

# skipping chunks 13 and 14: predicted raster map.. doesn't really apply here.

# model fit!
rf.pred <- predict(rf.fit, log_build_reg_data_cl[,sel.vars], type="response")

rf.prob <- as.data.frame(predict(rf.fit, log_build_reg_data_cl[,sel.vars], type="prob"))

obs.pred <- data.frame(cbind(Observed=as.numeric(as.character(log_build_reg_data_cl[,"damage_binary"])),
                             PRED=as.numeric(as.character(rf.pred)), Prob1=rf.prob[,2],
                             Prob0=rf.prob[,1]) )

op <- (obs.pred$Observed == obs.pred$PRED)



( pcc <- (length(op[op == "TRUE"]) / length(op))*100 )



# library(verification)

roc.plot(obs.pred[,"Observed"], obs.pred[,"Prob1"])


# model validation
tic() # clock in
( rf.perm <- rf.significance(rf.fit, log_build_reg_data_cl[,sel.vars], nperm = 99, ntree = 1001) )
toc() # clock out, 59 minutes with 99 permutations
beepr::beep()

# saveRDS(rf.perm, file = paste0("saved_sessions/rf.perm",
#                                gsub('[[:punct:]]', '-', Sys.time()), '.rds'))

# cross validation
tic() # clock in
( rf.cv <- rf.crossValidation(rf.fit, log_build_reg_data_cl[,sel.vars], p=0.10, n=99, ntree=1001) )
toc() # clock out, about 143 minutes (2.38 hours) with 999 permutations
beepr::beep()

# so this model isn't very good

saveRDS(rf.perm, file = paste0("saved_sessions/rf.perm",
                               gsub('[[:punct:]]', '-', Sys.time()), '.rds'))


# so the number of trees is probably over kill at 1000? 75 sufficient?
plot(rf.fit, main="Bootstrap Error Convergence")


# variable importance
p <- as.matrix(rf.fit$importance[,3])   
ord <- rev(order(p[,1], decreasing=TRUE)[1:dim(p)[1]]) 


png(file = paste0(getwd(), '/figures/var_imp_', gsub('[[:punct:]]', '_', Sys.time()), '.png'))
dotchart(p[ord,1], main="Scaled Variable Importance", pch=19)  
dev.off()


p <- as.matrix(rf.fit_all$importance[,3])   
ord <- rev(order(p[,1], decreasing=TRUE)[1:dim(p)[1]]) 


png(file = paste0(getwd(), '/figures/var_imp_all_', gsub('[[:punct:]]', '_', Sys.time()), '.png'))
dotchart(p[ord,1], main="Scaled Variable Importance", pch=19)  
dev.off()

(all_vars <- names(log_build_reg_data_cl))

#TODO: PDP don't like categorical predictors.. 
# all_vars <-  all_vars[c(1:9, 11:35)]


`%nin%` <- Negate(`%in%`) # custom function
# 
# # drop the binary
# (all_vars <- all_vars[all_vars %nin% 'build_has_tree_overhang'])

tic()
par(mfrow=c(1,1))
for(i in all_vars[2:length(all_vars)]) {
  print(i)
  png(file = paste0(getwd(), '/figures/', i, '_pdp',
                  gsub('[[:punct:]]', '_', Sys.time()), '.png'))
  rf.partial.prob(rf.fit_all, log_build_reg_data_cl[,all_vars], i, "1", smooth="spline", raw.line=FALSE)
  dev.off()
}; toc()  



# par(mfrow=c(2,2))
# for(i in sel.vars[1:4]) {
#   rf.partial.prob(rf.fit, build_rforest_cat[,sel.vars], i, "1", smooth="spline", raw.line=FALSE)
# }  

tic()
for(i in sel.vars) {
png(file = paste0(getwd(), '/figures/', i, '_pdp_',
                  gsub('[[:punct:]]', '_', Sys.time()), '.png'))
rf.partial.prob(rf.fit,
                log_build_reg_data_cl[,sel.vars], i, "1", smooth="spline", raw.line=FALSE)
dev.off()
  }; toc() 
beep()
```







#### i random forest readings

Thanks Sebastian Martinuzzi

https://evansmurphy.wixsite.com/evansspatial/random-forest-sdm

https://cran.r-project.org/web/packages/rfUtilities/index.html
(Utilities for Random Forest model selection, class balance correction, significance test, cross validation and partial dependency plots.)

https://www.rdocumentation.org/packages/randomForestSRC/versions/2.9.3/topics/imbalanced.rfsrc
(Imbalanced Two Class Problems)

Old, but important
https://statistics.berkeley.edu/sites/default/files/tech-reports/666.pdf

A review paper on "A survey on addressing high-class imbalance in big data"
https://link.springer.com/article/10.1186/s40537-018-0151-6

https://towardsdatascience.com/random-forest-in-r-f66adf80ec9

http://www.sthda.com/english/articles/36-classification-methods-essentials/150-stepwise-logistic-regression-essentials-in-r/#:~:text=The%20stepwise%20logistic%20regression%20can,ref(stepwise%2Dregression))

https://compstat-lmu.github.io/iml_methods_limitations/pdp.html

https://www.blopig.com/blog/2017/04/a-very-basic-introduction-to-random-forests-using-r/





### OLD A a little prep
```{r}
# TODO handle the NA's better than dropping 11%
# a) manual fill, b) impute - see if it matters in the model
# see if year built is even a good predictor

# minor prep for binary 
build_bin <- build %>% 
  st_drop_geometry() %>% 
  select(damage_binary, build_Mean_elev_30m : build_Mean_distall_road,
         build_NEAR_DIST, build_NEAR_ANGLE,
         build_dist_to_build_ft : build_p_shrub_300,
         parcel_UseType: parcel_Imperv_P,
         parcel_year_built) %>% 
  filter(parcel_year_built > 0) %>% 
  drop_na() %>% 
  data.frame #%>% glimpse

# check for NA
map(build_bin, ~sum(is.na(.))) # check for NA's

build_bin %>% filter(parcel_year_built == 0) %>% dim()

```




### OLD data prep/max model
```{r}
# maximal set of predictors after winnowing down among potentially redundant vars
#Dexter see note below, I don't think we need this section to come up with a maximal model for regression. 
log_build_reg_data <- build %>%
  tidylog::select(damage_binary
                  , build_Mean_elev_30m
                  ,  build_Mean_aspect_100m_DEM
                  ,  build_Mean_slope_100m_DEM
                  ,  build_Mean_aspect_100m_DEM 
                  ,  build_Mean_distroad
                  ,  build_Mean_builddens 
                  ,  build_Mean_distall_road 
                  ,  build_min_dist_tree
                  ,  build_min_dist_shrub 
                  
                  , build_has_tree_overhang
                  , build_overhang_ht
                  , build_perc_overhang
                
                  # , build_dist_angle
                   , build_dist_to_build_ft_jod
                  # , build_dist_to_build_ft 
                  , build_near_dest
                  
                  , build_p_tree_100
                  , build_p_grass_300 
                  , build_p_soil_200 
                  , build_p_water_100 
                  , build_p_building_300 
                  , build_p_road_300
                  , build_p_otherpaved_300
                  , build_p_shrub_300
                    
                  , build_area
                  , parcel_UseType
                    # parcel_UseDescription, # colinear with above?
                    # parcel_Roll_ImpValue, # colinear with below?
                  , parcel_Roll_HomeOwnersExemp
                  , parcel_Can_P
                  , parcel_Grass_P
                  , parcel_Soil_P 
                  , parcel_Water_P
                  , parcel_Build_P
                  , parcel_Road_P
                  , parcel_Paved_P
                  , parcel_Shrub_P
                  , parcel_Perv_P
                  , parcel_Imperv_P
                  , parcel_recent # Dexter, fixed this to be parcel_recent
                  , parcel_area,
                  build_EXTERIORSI,build_FENCEATTAC,build_DECKPORCHO,build_DECKPORCHE,build_ROOFCONSTR,build_PATIOCOVER,
                  build_PROPANETAN,build_WINDOWPANE,build_VEGCLEARAN,build_EAVES,build_VENTSCREEN,build_DINS
                  )  

# Miranda do you remember why we have two versions of build?
#Dexter, it was because one of them included land cover data. And bc we were going to do a  big maximal model. I don't think we are anymore - just univariates and Random Forest so should we delete this whole section?
log_build_reg_data_lc <- build %>% #some of these variable names need to be cleaned up if we retain this subset of vars/data
  tidylog::select(damage_binary
                  , build_Mean_elev_30m
                  ,  build_Mean_aspect_100m_DEM
                  ,  build_Mean_slope_100m_DEM
                  ,  build_Mean_aspect_100m_DEM 
                  ,  build_Mean_distroad
                  ,  build_Mean_builddens 
                  ,  build_Mean_distall_road 
                  ,  build_min_dist_tree
                  ,  build_min_dist_shrub 
                  
                  , build_has_tree_overhang
                  , build_overhang_ht
                  , build_perc_overhang
                
                  # , build_dist_angle
                  # , build_dist_to_burned_build_ft
                  , build_dist_to_build_ft_jod
                  , build_near_dest
                  
                  # , build_p_tree_100
                  , build_p_grass_300 
                  # , build_p_soil_200 
                  # , build_p_water_100 
                  , build_p_building_300 
                  # , build_p_road_300
                  # , build_p_otherpaved_300
                  # , build_p_shrub_300
                    
                  , build_area
                  
                  , parcel_UseType
                    # parcel_UseDescription, # colinear with above?
                    # parcel_Roll_ImpValue, # colinear with below?
                  , parcel_Roll_HomeOwnersExemp
                  , parcel_Can_P
                  , parcel_Grass_P
                  , parcel_Soil_P 
                  , parcel_Water_P
                  , parcel_Build_P
                  , parcel_Road_P
                  , parcel_Paved_P
                  , parcel_Shrub_P
                  , parcel_Perv_P
                  , parcel_Imperv_P
                  , parcel_year_built
                  , parcel_area) %>% 
  mutate_if(is.character, as.factor)  # random forest doesn't like characters
  #drop_na() #party is ok with NAs


log_maximal_lc <- glm(damage_binary ~ ., family = binomial, data = log_build_reg_data_lc)

# FIXME examine warning error
tic();log_step_lc <- log_build_reg_data_lc %>% MASS::stepAIC(trace = FALSE); toc() # ~1.5 mins

```



### OLD fits for maximal models examine fits
```{r}
# Null model
log_null <- glm(damage_binary ~ 1, family = binomial, data = log_build_reg_data)

# maximal model 
log_maximal <- glm(damage_binary ~ ., family = binomial, data = log_build_reg_data)
log_maximal %>% check_collinearity()
# step-wise
tic();log_step <- log_maximal %>% MASS::stepAIC(trace = FALSE); toc() # ~1.5 mins

# store chosen terms from stepwise regression
(log_step %>% 
    tidy() %>% 
    filter(term != '(Intercept)') %>% 
    pull(term) -> vars_in_log_step)

summary(log_step)performance::compare_performance(log_null, log_maximal, log_step, rank = TRUE) # chooses stepwise

modEvA::Dsquared(log_maximal)
modEvA::Dsquared(log_step)

# find out limts of odds ratios, to inform graph settings
round(sort(exp(coef(log_step))), 2) %T>% print() %>% range() # 0 to ~1.6

# tab_model(log_maximal, show.std = FALSE)
plot_model(log_step, type = "std", vline.color = 'black', sort.est = TRUE) + 
  ylim(0, 1.65) + theme_bw()

# ggsave(file = paste0(getwd(), '/figures/stepwise_logistic_reg_coefs_',
#                      gsub('[[:punct:]]', '_', Sys.time()), '.png'))

tab_model(log_step
          # , file = paste0(getwd(), '/output_data/stepwise_logistic_reg_coefs_',
          #               gsub('[[:punct:]]', '_', Sys.time()), '.html')
          ); warnings()


# is that regression model any good?
performance::check_model(log_step) # saving isn't so easy

```


http://www.sthda.com/english/articles/36-classification-methods-essentials/151-logistic-regression-essentials-in-r/

### OLD assess missingness and stepwise model
```{r}

# of the variables that made it through the stepwise procedure, which had missing vals?
(
  build %>%
    map(., ~sum(is.na(.))) %>%
    map_dfc(., ~.x) %>% 
    t() %>%
    data.frame() %>%
    rownames_to_column(var = 'var') %>% 
    rename(num_missing = '.') %>% 
    arrange(desc(num_missing)) %>%
    filter(var %in% vars_in_log_step) %>% 
    filter(num_missing > 0) -> missing_data_vars
)

# These are the ones to think about
#                  var num_missing
#1       parcel_year_built        1008 #this is important in RF; impute about median.
#2     build_Mean_distroad          88 #this is important in RF; impute the median. #TODO - Dexter I think we should just drop these, seems weirder to impute a median here.
#3       build_overhang_ht          47 #not important in maximal RF model
#4     build_perc_overhang          47 #not important in maximal RF model
#5 build_Mean_distall_road          12 #not important in maximal RF model 
```



### OLD impute missing values AND drop the variables previously determined to be low-importance
```{r}
build %>% 
  mutate_all(~ifelse(is.na(.), median(., na.rm = TRUE), .)) %>% 
  tidylog::select(-build_overhang_ht, -build_perc_overhang, -build_Mean_distall_road)
  
```




### OLD G fit models with consistent distance (300)
```{r}

# maximimal set of predictors after winnowing down among potentially redundant vars
log_build_reg_data_consitent_dists <- build %>%
  tidylog::select(damage_binary
                  , build_Mean_elev_30m
                  ,  build_Mean_aspect_30m_DEM
                  ,  build_Mean_slope_30m_DEM
                  ,  build_Mean_aspect_30m_DEM 
                  ,  build_Mean_distroad
                  ,  build_Mean_builddens 
                  ,  build_Mean_distall_road 
                  ,  build_min_dist_tree
                  ,  build_min_dist_shrub 
                  , near_dest
                  , build_has_tree_overhang
                  , build_overhang_ht
                  , build_perc_overhang
                  
                  , build_dist_angle
                  , build_dist_to_build_ft_jod
                  
                  , build_p_tree_300 
                  , build_p_grass_300 
                #  , build_p_soil_300 
                  , build_p_water_300 
                  , build_p_building_300 
                  , build_p_road_300
                  , build_p_otherpaved_300
                  , build_p_shrub_300
                    
                  , build_area
                  
                  , parcel_UseType
                    # parcel_UseDescription, # colinear with above?
                    # parcel_Roll_ImpValue, # colinear with below?
                  , parcel_Roll_HomeOwnersExemp
                 # , parcel_Can_P
                #  , parcel_Grass_P
                #  , parcel_Soil_P 
                #  , parcel_Water_P
                #  , parcel_Build_P
                #  , parcel_Road_P
                #  , parcel_Paved_P
                #  , parcel_Shrub_P
                #  , parcel_Perv_P
                #  , parcel_Imperv_P
                  , parcel_year_built
                  , parcel_area) %>% 
  mutate_if(is.character, as.factor) %>% # random forest doesn't like characters
  drop_na()


# _cd for consistent distance
log_maximal_cd <- glm(damage_binary ~ ., family = binomial, data = log_build_reg_data_consitent_dists)
log_maximal_cd %>% check_collinearity()

# step-wise
tic();log_step_cd <- log_maximal_cd %>% MASS::stepAIC(trace = FALSE); toc() # ~1.5 mins
log_step_cd %>% check_collinearity()

# store chosen terms from stepwise regression
(log_step_cd %>% 
    tidy() %>% 
    filter(term != '(Intercept)') %>% 
    pull(term) -> vars_in_log_step)

log_step_cd %>% tab_model
log_step_cd %>% plot_model(., sort.est = TRUE, vline.color = 'black') + 
  ylim(0, 1.65) + theme_bw()

```
### OLD H purposeful models
```{r}

# purposeful models of predictors ; we have a working set of 'non-correlated' variables, create 'intentional' sets of models - 
# Parcel/building level - what individual can control or potentially change (trees overhead, veg on parcel, veg in 10 ft)
# Model ideas 1  - structure age, slope, aspect, elevation; vegetation on roof; vegetation within 10 ft

m1<-glm(damage_binary ~ near_dest+parcel_year_built+build_Mean_slope_30m_DEM+build_Mean_aspect_30m_DEM+build_Mean_elev_30m+build_perc_overhang+build_p_grass_10+build_p_tree_10+build_p_soil_10, family = binomial, data = build)

summary(m1)
m1 %>% tab_model
m1 %>% plot_model(., sort.est = TRUE, vline.color = 'black') + 
  ylim(0, 1.65) + theme_bw()

# Model ideas 2 - structure age, slope, aspect, elevation; vegetation on roof; vegetation within 300 ft (if that distance seems best?)
m2<-glm(damage_binary ~ near_dest+parcel_year_built+build_Mean_slope_30m_DEM+build_Mean_aspect_30m_DEM+build_Mean_elev_30m+build_perc_overhang+build_p_grass_300+build_p_tree_300+build_p_soil_300, family = binomial, data = build)

summary(m2)
m2 %>% tab_model
m2 %>% plot_model(., sort.est = TRUE, vline.color = 'black') + 
  ylim(0, 1.65) + theme_bw()


# Model ideas 3 (just change out veg for parcel) - structure age, slope, aspect, elevation; vegetation on roof; vegetation on parcel
m3<-glm(damage_binary ~ near_dest+parcel_year_built+build_Mean_slope_30m_DEM+build_Mean_aspect_30m_DEM+build_Mean_elev_30m+build_perc_overhang+parcel_Grass_P+parcel_Can_P+parcel_Soil_P, family = binomial, data = build)

summary(m3)
m3 %>% tab_model
m3 %>% plot_model(., sort.est = TRUE, vline.color = 'black') + 
  ylim(0, 1.65) + theme_bw()

AIC(m1,m2,m3) #compare m1,m2,m3 

# Landscape level - what determines fire spread/describes world around you (roads, building density, slope aspect etc)
# Take the parcel/building level model 1, 2, or 3, and add the variables for roads, building density; 
  # TO DO should have ?Structuredensity*Structure age interaction?
  # TO DO which road measure?  
names(build)
m4<-glm(damage_binary ~ parcel_year_built+build_Mean_slope_30m_DEM+build_Mean_aspect_30m_DEM+build_Mean_elev_30m+build_perc_overhang+
          build_p_grass_300+build_p_tree_300+build_p_soil_300+build_Mean_distroad+build_Mean_builddens, family = binomial, data = build)

AIC(m2,m4) #TO DO what's going on w number of observations here? where are missing values?
m4 %>% tab_model
tab_model(m2,m4)
m4 %>% plot_model(., sort.est = TRUE, vline.color = 'black') + 
  ylim(0, 1.65) + theme_bw() 

```


```{r, citations}
lapply(packages, citation)
```


Last knit on `r format(Sys.time())`


```{r}
system.time(save.image(file = paste0('saved_sessions/wui_r_models_', gsub('[[:punct:]]', '-', Sys.time()), '.RData')))
```

