---
title: "04_fit_models"
author: "Dexter H. Locke, PhD"
date: "`r format(Sys.time())`"
output: html_document
editor_options: 
  chunk_output_type: console
---




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This assumes "02_Woosley_combine_data.Rmd" was run



## 0 set up: load libraries, custom functions, set defaults
```{r}
# load libraries
# packages we'll be using
packs <- c('tidyverse'        # a must have!
           , 'tidylog'        # makes things very verbose for 2x checking 
           , 'magrittr'       # all of the pipes
           , 'janitor'        # cleans things up
           , 'sf'             # simple features
           , 'mapview'        # quick webmaps for zoom/pan viz
           #'tidycensus',     # access to Census data in a tidy way
           #'party',          # random forests
           , 'modEvA'         # contains D-squared function
           , 'randomForest', 'rfUtilities', 'verification'
           , 'tictoc'         # times things
           , 'beepr'          # makes noises
           , 'broom'          # tidy up regression models
           , 'performance'    # nice regression diagnostics
           , 'psych'          # describe is very useful for descriptive statistics
           , 'sjPlot'         # useful plotting and regression support
           , 'rpart'          # for random forests
           # , pROC           # for AUC calculation
           , 'pdp'            # partial dep plots
           , 'caret'          #random forest work
           , 'party'          # for random forests using cforest
           )        

# check for all of the libraries
if (length(setdiff(packs, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packs, rownames(installed.packages())))  
}

# lapply(packs, library, character.only = TRUE)
vapply(packs, library, character.only = TRUE, logical(1),
       logical.return = TRUE, quietly = TRUE)


# custom function for "Not In"
`%nin%` <- Negate(`%in%`)


set.seed(19870630)
```


## 1 read in the data
```{r}
# build <- read_csv(paste0(getwd(), '/output_data/building_2021-04-26.csv')) %>% glimpse
# build <- read_csv(paste0(getwd(), '/output_data/building_2021-09-27.csv')) %>% glimpse
# build <- read_csv(paste0(getwd(), '/output_data/building_2021-10-05.csv')) %>% glimpse
# build <- read_csv(paste0(getwd(), '/output_data/building_2021-11-03.csv')) %>% glimpse
#build <- read_csv(paste0(getwd(), '/output_data/building_2021-12-02.csv')) %>% glimpse

build <- read_csv(paste0(getwd(), '/output_data/building_2022-02-01.csv')) %>%
  mutate_if(is.character, as.factor) %>% # need factors for analyses to come
  glimpse()


```


## 2 fit models
### A univariate-logistic regression 
```{r eval=FALSE, include=FALSE}

tic(); uni_log_mods <- build %>%
  filter(parcel_UseType == 'Residential') %>% 
  nest(data=everything()) %>% 
  # nest()%>%
  mutate(
    # ~landscape position
    log_build_Mean_elev_30 = map(., ~glm(damage_binary ~ build_Mean_elev_30m, family = binomial, data = data.frame(.))),
    log_build_Mean_elev_100= map(., ~glm(damage_binary ~ build_Mean_elev_100m,family = binomial, data = data.frame(.))),
    
    log_build_Mean_slope_30 = map(., ~glm(damage_binary ~ build_Mean_slope_30m_DEM, family = binomial, data = data.frame(.))),
    log_build_Mean_slope_100= map(., ~glm(damage_binary ~ build_Mean_slope_100m_DEM,family = binomial, data = data.frame(.))),
    
    log_build_Mean_aspect_30 = map(., ~glm(damage_binary ~ build_Mean_aspect_30m_DEM, family= binomial, data = data.frame(.))),
    log_build_Mean_aspect_100= map(., ~glm(damage_binary ~ build_Mean_aspect_100m_DEM,family= binomial, data = data.frame(.))),
    
     # land cover
    log_build_p_tree_10 = map(., ~glm(damage_binary ~ build_p_tree_10, family = binomial, data = data.frame(.))),
    log_build_p_tree_100= map(., ~glm(damage_binary ~ build_p_tree_100,family = binomial, data = data.frame(.))),
    log_build_p_tree_200= map(., ~glm(damage_binary ~ build_p_tree_200,family = binomial, data = data.frame(.))),
    log_build_p_tree_300= map(., ~glm(damage_binary ~ build_p_tree_300,family = binomial, data = data.frame(.))),
  
    log_build_p_grass_10 = map(., ~glm(damage_binary ~ build_p_grass_10, family = binomial, data = data.frame(.))),
    log_build_p_grass_100= map(., ~glm(damage_binary ~ build_p_grass_100,family = binomial, data = data.frame(.))),
    log_build_p_grass_200= map(., ~glm(damage_binary ~ build_p_grass_200,family = binomial, data = data.frame(.))),
    log_build_p_grass_300= map(., ~glm(damage_binary ~ build_p_grass_300,family = binomial, data = data.frame(.))),
    
    log_build_p_soil_10 = map(., ~glm(damage_binary ~ build_p_soil_10, family = binomial, data = data.frame(.))),
    log_build_p_soil_100= map(., ~glm(damage_binary ~ build_p_soil_100,family = binomial, data = data.frame(.))),
    log_build_p_soil_200= map(., ~glm(damage_binary ~ build_p_soil_200,family = binomial, data = data.frame(.))),
    log_build_p_soil_300= map(., ~glm(damage_binary ~ build_p_soil_300,family = binomial, data = data.frame(.))),
    
    log_build_p_water_10 = map(., ~glm(damage_binary ~ build_p_water_10, family = binomial, data = data.frame(.))),
    log_build_p_water_100= map(., ~glm(damage_binary ~ build_p_water_100,family = binomial, data = data.frame(.))),
    log_build_p_water_200= map(., ~glm(damage_binary ~ build_p_water_200,family = binomial, data = data.frame(.))),
    log_build_p_water_300= map(., ~glm(damage_binary ~ build_p_water_300,family = binomial, data = data.frame(.))),
    
    log_build_p_buliding_10 = map(., ~glm(damage_binary ~ build_p_building_10, family = binomial, data = data.frame(.))),
    log_build_p_buliding_100= map(., ~glm(damage_binary ~ build_p_building_100,family = binomial, data = data.frame(.))),
    log_build_p_buliding_200= map(., ~glm(damage_binary ~ build_p_building_200,family = binomial, data = data.frame(.))),
    log_build_p_buliding_300= map(., ~glm(damage_binary ~ build_p_building_300,family = binomial, data = data.frame(.))),
    
    log_build_p_road_10 = map(., ~glm(damage_binary ~ build_p_road_10, family = binomial, data = data.frame(.))),
    log_build_p_road_100= map(., ~glm(damage_binary ~ build_p_road_100,family = binomial, data = data.frame(.))),
    log_build_p_road_200= map(., ~glm(damage_binary ~ build_p_road_200,family = binomial, data = data.frame(.))),
    log_build_p_road_300= map(., ~glm(damage_binary ~ build_p_road_300,family = binomial, data = data.frame(.))),
    
    log_build_p_otherpaved_10 = map(., ~glm(damage_binary ~ build_p_otherpaved_10, family = binomial, data = data.frame(.))),
    log_build_p_otherpaved_100= map(., ~glm(damage_binary ~ build_p_otherpaved_100,family = binomial, data = data.frame(.))),
    log_build_p_otherpaved_200= map(., ~glm(damage_binary ~ build_p_otherpaved_200,family = binomial, data = data.frame(.))),
    log_build_p_otherpaved_300= map(., ~glm(damage_binary ~ build_p_otherpaved_300,family = binomial, data = data.frame(.))),
    
    log_build_p_shrub_10 = map(., ~glm(damage_binary ~ build_p_shrub_10, family = binomial, data = data.frame(.))),
    log_build_p_shrub_100= map(., ~glm(damage_binary ~ build_p_shrub_100,family = binomial, data = data.frame(.))),
    log_build_p_shrub_200= map(., ~glm(damage_binary ~ build_p_shrub_200,family = binomial, data = data.frame(.))),
    log_build_p_shrub_300= map(., ~glm(damage_binary ~ build_p_shrub_300,family = binomial, data = data.frame(.))),

    # # nearest distance to destroyed building 
    # log_build_near_dist_dest= map(., ~glm(damage_binary ~ build_near_dest,family = binomial, data = data.frame(.))),
    # 
    # # nearest distance to any building
    # log_build_near_dist_build = map(., ~glm(damage_binary ~ build_near_build,family = binomial, data = data.frame(.)))
    ) %>%
  dplyr::select(-data) %>% 
  rowid_to_column() %>% 
  pivot_longer(-rowid, names_to = 'model_name', values_to = 'model') %>% 
  dplyr::select(-rowid) %>% 
  separate(col = model_name, into = c('trash_1', 'trash_2', 'trash_3', 'var', 'dist'), remove = FALSE, convert = TRUE) %>% 
  dplyr::select(-starts_with('trash_')) %>% 
  mutate(#smry = map(model, summary),
         dsqr = map(model, Dsquared),
         AIC = map(model, AIC),
         r2 = map(model, performance::r2),
         rmse = map(model, performance::rmse)); toc()

# # checking out near_dist_dest
# log_build_near_dist_dest<- glm(damage_binary ~ build_near_dest,family = binomial, data=build)
# build %>% ggplot(aes(y=build_near_dest,x=as.factor(damage_binary))) + geom_boxplot()


# extract goodness of fit measures
(
  gof <- uni_log_mods %>% 
    dplyr::select(-model_name, -model) %>% 
    # dplyr::select(var, dist, AIC, dsqr, r2) %>%
    # unnest(dsqr, AIC, r2) %>% unnest(r2)
    unnest(everything()) %>% 
    unnest(everything())
)


# which distance provides the best fit per variable?
# in the case of build_near_dest and build_near_build, pick between destroyed or not
(
  best_dist <- gof %>% 
    group_by(var) %>% 
    summarise(max_d = dist[which.max(dsqr)],
              max_r = dist[which.max(r2)],
              min_AIC=dist[which.min(AIC)],
              min_rmse=dist[which.min(rmse)]) 
)


(
  best_var <- gof %>% 
    group_by(dist) %>% 
    summarise(max_d = var[which.max(dsqr)],
              max_r = var[which.max(r2)],
              min_AIC= var[which.min(AIC)],
              min_rmse= var[which.min(rmse)]) 
)


# cut out non-land cover variables
(
  best_var_lc <- gof %>%
    filter(var %nin% c('elev', 'slope', 'aspect', 'dist')) %>% 
    group_by(dist) %>% 
    summarise(max_d = var[which.max(dsqr)],
              max_r = var[which.max(r2)],
              min_AIC= var[which.min(AIC)],
              min_rmse= var[which.min(rmse)]) 
)


# # Is this needed or confusing?
# (
#   best_var_by_dist <- gof %>% 
#     group_by(var, dist) %>% 
#     summarise(max_d = var[which.max(dsqr)],
#               max_r = var[which.max(r2)],
#               min_AIC= var[which.min(AIC)],
#               min_rmse= var[which.min(rmse)]) 
# )

# Dexter, near_dest is nearest distance to destroyed building. near_exp is nearest distance to any building with wildfire damage
# that is, exposed
# we have the work showing that destroyed is better. they are also highly correlated in script 03. I think we can just use near_dest
# near_dest - better predictor than near_exposure. 

# NEITHER OF THESE WORK, so pick whichever you like
    log_near_dest <- glm(damage_binary ~ build_near_dest, 
                         family = binomial, data = build)
    log_near_exp <- glm(damage_binary ~ build_near_exp, family = binomial, data = build)
    
    anova(log_near_dest, log_near_exp)

# destroyed is STILL better,Feb 2022
compare_performance(log_near_dest, log_near_exp, rank = TRUE)



```





### B data prep 
```{r}

#data prep

build_a <- build %>% #retain only the 71 predictors of interest for final analyses and damage_binary as response 
  tidylog::select(damage_binary,
                  build_area    ,
           # build_DECKPORCHE    , #drop this on 12/20/21
            build_DECKPORCHO    ,
                 build_EAVES    ,
            build_EXTERIORSI    ,
            build_FENCEATTAC    ,
            build_PATIOCOVER    ,
            build_PROPANETAN    ,
            build_ROOFCONSTR    ,
           build_VEGCLEARAN    ,
           build_VENTSCREEN    ,
           build_WINDOWPANE    ,
          parcel_year_built    ,
           build_near_build    ,
    build_has_tree_overhang    ,
       build_min_dist_shrub    ,
        build_min_dist_tree    ,
          build_overhang_ht    ,
        build_perc_overhang    ,
             parcel_Build_P    ,
               parcel_Can_P    ,
             parcel_Grass_P    ,
            parcel_Imperv_P   , #inverse of perv surface
             parcel_Paved_P    ,
            #  parcel_Perv_P    ,#inverse of imp, just need one
              parcel_Road_P    ,
             parcel_Shrub_P    ,
              parcel_Soil_P    ,
             parcel_Water_P    ,
            build_near_dest    ,
        build_p_building_10    ,
       build_p_building_100    ,
       build_p_building_200    ,
       build_p_building_300    ,
           build_p_grass_10    ,
          build_p_grass_100    ,
          build_p_grass_200    ,
          build_p_grass_300    ,
      build_p_otherpaved_10    ,
     build_p_otherpaved_100    ,
     build_p_otherpaved_200    ,
     build_p_otherpaved_300    ,
            build_p_road_10    ,
           build_p_road_100    ,
           build_p_road_200    ,
           build_p_road_300    ,
           build_p_shrub_10    ,
          build_p_shrub_100    ,
          build_p_shrub_200    ,
          build_p_shrub_300    ,
            build_p_soil_10    ,
           build_p_soil_100    ,
           build_p_soil_200    ,
           build_p_soil_300    ,
            build_p_tree_10    ,
           build_p_tree_100    ,
           build_p_tree_200    ,
           build_p_tree_300    ,
           build_p_water_10    ,
          build_p_water_100    ,
          build_p_water_200    ,
          build_p_water_300    ,
                parcel_area    ,
       build_Mean_builddens    ,
    build_Mean_distall_road    ,
        build_Mean_distroad    ,
 build_Mean_aspect_100m_DEM    ,
  build_Mean_aspect_30m_DEM    ,
       build_Mean_elev_100m    ,
        build_Mean_elev_30m    ,
  build_Mean_slope_100m_DEM    ,
   build_Mean_slope_30m_DEM,
          build_DINS) %>% 
  data.frame() %>%
  mutate_if(is.character, as.factor) 


# Line 327 and below--updated and re ran on 2/9/22 w final variable names
####Univariate models and deviance calcs
# WORKING ON commented out this work and read in table of deviance below
# # for building materials we used a logit link and specified a binomial response, then calculated and compared the
# # deviance explained (D2), which is analogous to R-squared in linear regression for each variable.
# # table1 contains a list of predictor variables for analysis and vectors to store the results for each variable 
# 
# 
# 
# (table1 <- list(names(build_a)) %>% #created a list of predictors
#   data.frame() %>%
#   mutate(dev2 = 0, n2 = 0) %>%
#   rename(upvar = c..damage_binary....build_area....build_DECKPORCHO....build_EAVES...) %>%
#   data.frame())
# 
# # # repurposed from Owne Price
#  dat.model <- data.frame(y = build_a$damage_binary, x = 0)
# # 
# i<-0
# for (varname in table1$upvar) {
#   i<-i+1
#   if (varname %in% colnames(build_a)) {
#     dat.model$x <- build_a[, varname]
#     mod <- glm(y ~ x, data = dat.model, family = binomial())
#   } else {
#     warning(varname, " not found in build_a", immediate. = TRUE)
#     mod <- NULL
#   }
# 
#   if (!is.null(mod)) {
#     table1$n2[i] <- nrow(build_a) - sum(is.na(dat.model$x))
#     table1$dev2[i] <- 100 * (mod$null.deviance - mod$deviance) / mod$null.deviance
#   }
# }
# # 
# 
#  
# # read in variable descriptions
# (tab_labs <- readxl::read_xlsx('data/Data LA Study 20220209.xlsx') %>%
#   mutate(Type =
#            case_when(
#                Type == 'CON' ~ 'Construction'
#              , Type == 'DEF' ~ 'Defensible Space'
#              , Type == 'LAND'~ 'Landscape Attributes'
#              , Type == 'TOPO'~ 'Topography'
#              , Type == 'EXP' ~ 'Exposure'
#              , TRUE ~ 'na')) %>% # Miranda to add last category, something meaningful
#   left_join(.
#             , table1 %>% filter(upvar != 'damage_binary' & upvar!= 'build_DINS')
#             , by = c(`Variable name` = 'upvar')) %>%
#   tidylog::select(Type
#                   , `Variable name`
#                   , Alias # added this
#                   , Deviance = dev2
#                   , n = n2
#                   , Scale
#                   , Source
#                   ) %>%
# #     arrange(desc(Deviance))%>%
#   arrange(Type, desc(Deviance)) %>%
#   mutate_if(is.double, round, 3))
# #  
# # export
# # redone Feb  9 2022
#   tab_labs %>%
#     drop_na()%>%
#    write_csv(., paste0(getwd(), '/data/Table_Deviance_Explained_', Sys.Date(), '.csv')) 
#    
#    
#reading back in deviance explained
(tab_labs <- 
  read_csv(paste0(getwd(), '/data/Table_Deviance_Explained_2022-02-09.csv'))) 

# next steps for getting table to look nice  type look up table ??

 
# ended __________


```



suggested organization (put one full model in a chunk then repeat with second model)

### C Random forest
```{r eval=FALSE, include=FALSE}

build <- read_csv(paste0(getwd(), '/output_data/building_2022-02-01.csv')) %>%
  tidylog::select(damage_binary
                  , build_area   
                  # build_DECKPORCHE    , #drop this on 12/20/21
                  , build_DECKPORCHO
                  , build_EAVES
                  , build_EXTERIORSI
                  , build_FENCEATTAC
                  , build_PATIOCOVER
                  , build_PROPANETAN
                  , build_ROOFCONSTR
                  , build_VEGCLEARAN 
                  , build_VENTSCREEN 
                  , build_WINDOWPANE 
                  , parcel_year_built 
                  , build_near_build 
                  , build_has_tree_overhang 
                  , build_min_dist_shrub 
                  , build_min_dist_tree 
                  , build_overhang_ht 
                  , build_perc_overhang 
                  , parcel_Build_P 
                  , parcel_Can_P 
                  , parcel_Grass_P 
                  , parcel_Imperv_P    #inverse of perv surface
                  , parcel_Paved_P    
                  #  parcel_Perv_P    ,#inverse of imp, just need one
                  , parcel_Road_P
                  , parcel_Shrub_P  
                  , parcel_Soil_P  
                  , parcel_Water_P  
                  , build_near_dest  
                  , build_p_building_10  
                  , build_p_building_100  
                  , build_p_building_200  
                  , build_p_building_300  
                  , build_p_grass_10  
                  , build_p_grass_100  
                  , build_p_grass_200  
                  , build_p_grass_300  
                  , build_p_otherpaved_10  
                  , build_p_otherpaved_100  
                  , build_p_otherpaved_200  
                  , build_p_otherpaved_300  
                  , build_p_road_10  
                  , build_p_road_100  
                  , build_p_road_200  
                  , build_p_road_300  
                  , build_p_shrub_10  
                  , build_p_shrub_100  
                  , build_p_shrub_200  
                  , build_p_shrub_300  
                  , build_p_soil_10  
                  , build_p_soil_100  
                  , build_p_soil_200  
                  , build_p_soil_300  
                  , build_p_tree_10  
                  , build_p_tree_100  
                  , build_p_tree_200  
                  , build_p_tree_300  
                  , build_p_water_10  
                  , build_p_water_100  
                  , build_p_water_200  
                  , build_p_water_300  
                  , parcel_area  
                  , build_Mean_builddens  
                  , build_Mean_distall_road  
                  , build_Mean_distroad  
                  , build_Mean_aspect_100m_DEM  
                  , build_Mean_aspect_30m_DEM  
                  , build_Mean_elev_100m  
                  , build_Mean_elev_30m  
                  , build_Mean_slope_100m_DEM  
                  , build_Mean_slope_30m_DEM
                  , build_DINS
                  ) %>%
  mutate_if(is.character, as.factor) %>% 
  droplevels() %>% 
  mutate(damage_binary = as.factor(damage_binary)) %>% # randomForest::randomForest
  data.frame()

# Miranda: do these NA's surprise you? OK to drop non-DINS-associated NA's?
# where are the NA's
build %>%  map(~sum(is.na(.))) %>% bind_rows() %>% t() %>% View() # check for NA's


build_no_dins <- build %>% 
  tidylog::select(# dropping columns containing specific DINS data
                  # very detailed but sparse (lots of NAs)
    !c(  build_DECKPORCHO
         , build_EAVES
         , build_EXTERIORSI
         , build_FENCEATTAC
         , build_PATIOCOVER
         , build_PROPANETAN
         , build_ROOFCONSTR
         , build_VEGCLEARAN
         , build_VENTSCREEN
         , build_WINDOWPANE
         , build_DINS)
  ) #%>% drop_na()

 
# fit random forest model
n_tree <- 500 # ~20 seconds
# n_tree <- 100 # (100 ~5 seconds, 200 ~7.5 sec, 300 ~12 sec)
tic(); rf_no_dins <- randomForest::randomForest(  damage_binary ~ .
                                                , data = build_no_dins
                                                , type = 'classification'
                                                , mtry = 5
                                                , ntree = n_tree); toc()

library(pdp)           # for partial dependence plots
library(vip)           # for variable importance plots

# # modified from first chunk here:
# # https://bgreenwell.github.io/pdp/articles/pdp.html#other-vignettes
# # Variable importance plot (compare to randomForest::varImpPlot(boston_rf))
# vip(boston_rf, bar = FALSE, horizontal = FALSE, size = 1.5)  # Figure 1

vip(rf_no_dins
    # , bar = FALSE      # doesn't seem to work "help(vip)" showed that it changed to "geom"
    # , geom = 'point'    # try "col" instead
    , geom = 'col'     # try "point" instead
    , horizontal = TRUE # vignette example had this as FALSE (label easier rotated)
    , size = 1.5        # plausibly pertains to point size
    # see "num_features"
    # "Integer specifying the number of variable importance scores to plot. Default is 10."
    ) + 
  theme_bw(16)          # added some flare (ok just bigger axis text and black/white theme)


# if we want to use color/shapes or facets to indicate the variable TYPE
# like we did with the cforest object before, it looks like vip::vi can be used
# to calculate the variable importance scores, then we can re-purpose the old
# code to add the colors symbols, etc.. . 'help(vip)' has an example starting with 
# "# Better yet, store the variable importance scores and then plot
# # vi_scores <- vi(model, method = "firm")". That's how I learned to extract importance
# from randomForest::randomForest models 

# single base-graphics partial dependency plot, modeled after Figure 2 here:
# https://bgreenwell.github.io/pdp/articles/pdp.html#other-vignettes
# partialPlot(boston_rf, pred.data = boston, x.var = "lstat")  # Figure 2
randomForest::partialPlot(rf_no_dins
                          , pred.data = build_no_dins
                          , x.var = "build_near_dest"
                          ) # ugly!

# # building off of the third chunk from
# # https://bgreenwell.github.io/pdp/articles/pdp.html#other-vignettes
# # AND third chunk from this vignette
# # https://bgreenwell.github.io/pdp/articles/pdp-computation.html
# # Switch to ggplot2
# p2 <- partial(boston_rf, pred.var = "lstat", plot = TRUE,
#               plot.engine = "ggplot2")

pdp::partial(rf_no_dins                      # random forest model
             , pred.var = "build_near_dest"  # predictor variable
             , plot = TRUE                   # if FALSE returns prediction data
             , plot.engine = "ggplot2"       # plot with ggplot2 or not?
             , rug = TRUE                    # adds the univariate y-axis summary (aka "rug")
             , progress = "text"             # prints progress, sets users expectations
             , quantiles = TRUE              # see help(pdp)
             , probs = 0:20/20               # probabilities, "0:20/20" gives 5% increments
             , ice = TRUE                    # Individual Conditional Expectations
             , center = TRUE                 # for graphical layout, pertains to ice
             , alpha = .1                    # line transparency
             ) + 
  theme_bw(16) +                             # ggplot adjustment for black/white & large text size 
  # scale_y_continuous(expand = c(0, 0)) +
  NULL -> test_pdp                           # makes the plot

test_pdp # accesses plot



```




#### i binary outcome-all obs, no DINS
```{r} 

# binary outcome random forest for all obs, drop DINS columns

# # code from Owen, this time using party
# n_tree <- 2000 #use this for final analyses
# # n_tree <- 100 #testing number of trees
# tic(); binary_without_dins_cols <-cforest(damage_binary ~ .,
#                                   data = build_a %>%
#                                     tidylog::select( # dropping columns containing specific DINS data
#                                             # very detailed but sparse (lots of NAs)
#                                       !c(  build_DECKPORCHO
#                                          , build_EAVES
#                                          , build_EXTERIORSI
#                                          , build_FENCEATTAC
#                                          , build_PATIOCOVER
#                                          , build_PROPANETAN
#                                          , build_ROOFCONSTR
#                                          , build_VEGCLEARAN
#                                          , build_VENTSCREEN
#                                          , build_WINDOWPANE
#                                          , build_DINS
#                                     ))
#                                   ,controls=cforest_control(mtry=5, ntree = n_tree, mincriterion=0)); toc() #takes 8 min with full data set, settings here from Owen (DHL 7 mins with n_tree = 2000 )
# 
# # #use this to save this Random Forest 
# # tic(); save(binary_without_dins_cols, file="../Massive_forests/binary_without_dins_cols.Rdata"); toc()

tic(); load(file="../Massive_forests/binary_without_dins_cols.Rdata"); toc() # ~100 seconds
forest <- binary_without_dins_cols; rm(binary_without_dins_cols) # keeping Owen's naming conventions

# # generating predicted values and saving output
# tic(); preds <- predict(forest, OOB = TRUE); toc() #with 100 trees, time is 180 sec, ~20mins with 2000 trees
# tic(); save(preds, file="../Massive_forests/preds_binary_without_dins_cols.Rdata"); toc()
tic(); load(file="../Massive_forests/preds_binary_without_dins_cols.Rdata"); toc() #this writes back in as 'preds'
preds %>% hist()
preds %>% summary()

# # OOB accuracy assessment.
# build_a_df <- build_a  %>% data.frame()
# build_a_df$predfor <- preds #save predicted values in whole data frame
# # what proportion of buildings destroyed?
# test <- table(build_a_df$damage_binary)
# (cutoff <- (test[2]/(test[1]+test[2]))) #0.1170289 prop destroyed
# build_a_df$predtrue <- build_a_df$predfor > cutoff

# save whole data file
# tic(); save(build_a_df, file = "../Massive_forests/build_a_df_withoutdins.Rdata"); toc() # FYI could have saved as csv
tic(); load(file = "../Massive_forests/build_a_df_withoutdins.Rdata"); toc() # ~2 seconds (DHL: 0.034 seconds something not right)

blob <- with(build_a_df, table(damage_binary, predtrue))
blob
round(100*(blob[1]+blob[4])/sum(blob),1) #overall accuracy
round(100*(blob[3]/sum(blob)),1) # false negative rate
round(100*(blob[2]/sum(blob)),1) # false pos rate
# with 2000 trees,the model had 76% accuracy with 23.1% false negative and 0.8% false positive rate - just checking is it ok that dataset unbalanced?

# https://www.r-bloggers.com/2019/08/in-search-of-the-perfect-partial-plot/
# # Add predicted values to data frame
# df_rf <- df_rf %>% 
#   mutate(predicted = predict(fit_rf))
# # Get performance measures
# confusionMatrix(df_rf$predicted, df_rf$Class, positive = "R")

build_a_df %>%  glimpse()
build_a_df %>%  names()
#Dexter check on this? 2/15/2022
caret::confusionMatrix(build_a_df$predtrue, build_a_df$damage_binary) 


# # Variable importance plots
# tic(); varimp_withoutdins <- varimp(forest);toc() # ~90 seconds with 100 trees, takes 52 min with 2000 trees (DHL 22 mins)
# # save 
# tic(); save(varimp_withoutdins, file = "../Massive_forests/varimp_withoutdins.Rdata"); toc() # consider csv
tic(); load(file = "../Massive_forests/varimp_withoutdins.Rdata"); toc() # ~40 seconds (DHL '0.001 sec elapsed')



# Turned code below off - variable importance run above instead
# from Owen and ?https://favorableoutcomes.wordpress.com/2014/12/19/r-function-for-plotting-variable-importance-results-from-cforest-imlementatio
#n-of-random-forest-model/ ?
# cforestImpPlot <- function(x) {
#   cforest_importance <<- v <- varimp(x)
#   dotchart(v[order(v)])
# } 
# also don't need this "cforestImpPlot" call  if using ggplot (below)
#tic();cforest_importance <- cforestImpPlot(forest);toc() 
# 
(
   varimp_withoutdins %>% 
    data.frame() %>% 
    rownames_to_column(var = 'Variable name') %>% 
    tibble() %>% 
    rename('Variable Importance' = ".") %>% 
    left_join(
      tab_labs %>% 
        tidylog::select(`Variable name`, Alias, Type, Scale)) %>% 
    arrange(desc('Variable Importance')) -> cforest_importance_to_graph)

cforest_importance_to_graph %>% tail()

# graph importance by type and scale
(cforest_importance_to_graph %>%
  ggplot(aes(  x = `Variable Importance`
             , y = reorder(Alias, `Variable Importance`)
             , color  = Scale)) +
  geom_point(aes(shape = Type)) +
  theme_bw() +
  NULL -> importance_graph
  )
# 
# ggsave(file = paste0(getwd(),
#                      '/figures/rf_importance_',
#                      gsub('[[:punct:]]', '_', Sys.Date()), '.png')
#        , width = 5*2
#        , height = 6.5*1.5)



# # graph importance by type and scale - faceted
(cforest_importance_to_graph %>%
  ggplot(aes(  x = `Variable Importance`
             , y = reorder(Alias, `Variable Importance`)
             , color  = Type)) +
  geom_point(aes(shape = Type)) +
  theme_bw() +
  # theme(legend.position = 'bottom')
  facet_wrap(~Type, scales = 'free_y', ncol = 1) +
  NULL -> importance_graph)
# 
# ggsave(file = paste0(getwd(),
#                      '/figures/rf_importance_facet_',
#                      gsub('[[:punct:]]', '_', Sys.Date()), '.png')
#        , width = 5*2
#        , height = 6.5*1.5)


# graph importance by type and scale, top n
# color for type and symbol for scale
top_n <- 20
(
  cforest_importance_to_graph %>% 
    slice(1:top_n) %>% 
    ggplot(aes(  x = `Variable Importance`
               , y = reorder(Alias, `Variable Importance`)
               , color  = Type)) + 
    # geom_point(aes(shape = Scale), size = 3) + 
    geom_point(size = 3) + 
    labs(y = 'Variable') + 
    scale_color_brewer(palette = 'Paired'
                       , direction = -1
                       ) +
    theme_bw() +
    theme(  legend.position = c(0.8, 0.2)
          , axis.text.y = element_text(size = 12)) + 
    # facet_wrap(~Type, scales = 'free', ncol = 1) + 
    NULL -> importance_graph
  )

# # save out
# ggsave(file = paste0(getwd(),
#                      '/figures/rf_importance_facet_top_n_',
#                      gsub('[[:punct:]]', '_', Sys.Date()), '.png')
#        , width = 5*2
#        , height = 6.5*1.5)


# # key variables: build_near_dest, build_Mean_distroad, build_p_building_300, build_Mean_elev_30m, build_Mean_elev_100m, build_area
# # how Owen codes partial plots
# # hung for both of us, 
# tic(); forest %>% 
#   partial(pred.var = "build_near_dest") %>%
#   plotPartial(smooth = FALSE, lwd = 2, ylab = "Prob. of Destruction", xlim=c(0,150),ylim=c(0,0.5), xlab="Axis label"); toc()


#pdp attempt from Miranda on 2/16/2022- I don't think this likes forest
library(pdp)
partial(forest, pred.var = "build_near_dest")  # Figure 2


# # https://www.r-bloggers.com/2019/08/in-search-of-the-perfect-partial-plot/
pd_df <- partial_dependence(fit = fit_rf,
                         vars = nm,
                         data = df_rf,
                         n = c(100, 200))

# edarf doesn't work for either of our versions of R
# you'll need "install.packages('edarf')" first, and "library(edarf)"
test <- edarf::partial_dependence(fit = forest)


library(moreparty)

tic(); Fast_binary_without_dins_cols <-fastcforest(damage_binary ~ .,
                                  data = build_a %>%
                                    tidylog::select( # dropping columns containing specific DINS data
                                            # very detailed but sparse (lots of NAs)
                                      !c(  build_DECKPORCHO
                                         , build_EAVES
                                         , build_EXTERIORSI
                                         , build_FENCEATTAC
                                         , build_PATIOCOVER
                                         , build_PROPANETAN
                                         , build_ROOFCONSTR
                                         , build_VEGCLEARAN
                                         , build_VENTSCREEN
                                         , build_WINDOWPANE
                                         , build_DINS
                                    ))
                                  ,controls=cforest_control(mtry=5, ntree = n_tree, mincriterion=0)); toc() 
#takes 8 min with full data set, settings here from Owen (DHL 7 mins with n_tree = 2000 )








# doesn't work to save # Dexter, stopped here
# SUGGEST DELETGIN THIS. What is now lines 494 is faster and prettier.
# #Dexter when I run line 489 it creates a plot I can view but cforest_importance is null ?
# #MHM stopped here on 2/8/22
# tic(); cforest_importance <- cforestImpPlot(forest);toc() # ~165 seconds with 100 trees, takes  DHL: 26 mins with 2000
# tic(); save(cforest_importance, file="../Massive_forests/cforest_importance"); toc()
# tic(); load(file="../Massive_forests/cforest_importance.Rdata"); toc()

# graph importance
# cforest_importance <- varimp_withoutdins; rm(varimp_withoutdins)

# 
# # 1. Open jpeg file
# jpeg("rplot.jpg", width = 350, height = "350")
# # 2. Create the plot
# plot(x = my_data$wt, y = my_data$mpg,
#      pch = 16, frame = FALSE,
#      xlab = "wt", ylab = "mpg", col = "#2E9FDF")
# # 3. Close the file
# dev.off()
```
 
#### ii binary outcome for DINS data 
```{r} 


# code from Owen, this time using party
n_tree <- 2000 #use this for final analyses
#n_tree <- 100 #testing number of trees
tic(); binary_with_dins_cols <-cforest(damage_binary ~ .,
                                  data = build_a %>% tidylog::select(!build_DINS)
                                  , controls = cforest_control(mtry = 5, ntree = n_tree, mincriterion = 0)); toc() #15 min

# #when finalized use this to save this Random Forest 
# # ~3.6 Gb - yikes
 tic(); save(binary_with_dins_cols, file="../Massive_forests/binary_with_dins_cols.Rdata"); toc() # ~ 75 seconds

# #when finalized use this to load Random Forest
# tic(); load(file="../Massive_forests/binary_with_dins_cols.Rdata"); toc() # ~ 30 seconds

forest<-binary_with_dins_cols; rm(binary_with_dins_cols) # keeping Owen's naming conventions

#generating predicted values and saving output
#can comment off once done
 tic();preds <- predict(forest, OOB = TRUE);toc() #with 100 trees, time is 180 sec, ~45 mins with 2000 trees
 tic(); save(preds, file="../Massive_forests/preds_binary_with_dins_cols.Rdata"); toc()
# tic(); load(file="../Massive_forests/preds_binary_with_dins_cols.Rdata"); toc() #this writes back in as 'preds'
 preds %>% hist()
 preds %>% summary()

#OOB accuracy assessment.
#
build_a_df_dins <- build_a  %>% data.frame()
build_a_df_dins$predfor<-preds #save predicted values in whole data frame
#what proportion of buildings destroyed?
test<-table(build_a_df_dins$damage_binary)
cutoff<-(test[2]/(test[1]+test[2])) #0.1170289 prop destroyed
build_a_df_dins$predtrue <- build_a_df_dins$predfor>cutoff 

#save whole data file
tic(); save(build_a_df_dins, file="../Massive_forests/build_a_df_dins.Rdata"); toc()
tic(); load(file="../Massive_forests/build_a_df_dins.Rdata"); toc() # ~40 seconds

blob<-with(build_a_df_dins, table(damage_binary, predtrue))
blob
round(100*(blob[1]+blob[4])/sum(blob),1) #overall accuracy
round(100*(blob[3]/sum(blob)),1) #false negative rate
round(100*(blob[2]/sum(blob)),1) #false pos rate
# with 2000 trees,the model had XX% accuracy with XX% false negative and XX% false positive rate - just checking is it ok that dataset unbalanced?


#Variable importance plots
#
tic();varimp_withdins<-varimp(forest);toc() # ~90 seconds with 100 trees, takes 52 min with 2000 trees 
#save
tic(); save(varimp_withdins, file="../Massive_forests/varimp_withdins.Rdata"); toc()
#tic(); load(file="../Massive_forests/varimp_withdins.Rdata"); toc() # ~40 seconds

#from Owen and ?https://favorableoutcomes.wordpress.com/2014/12/19/r-function-for-plotting-variable-importance-results-from-cforest-imlementatio
#n-of-random-forest-model/ ?
cforestImpPlot <- function(x) {
  cforest_importance <<- v <- varimp(x)
  dotchart(v[order(v)])
} 


tic(); cforest_importance <- cforestImpPlot(forest);toc() # ~165 seconds with 100 trees, takes  DHL: 30 mins with 2000
tic(); save(cforest_importance, file="../Massive_forests/cforest_importance_dins"); toc()
#tic(); load(file="../Massive_forests/cforest_importance_dins.Rdata"); toc()

# graph importance
cforest_importance
(
  cforest_importance %>% 
    data.frame() %>% 
    rownames_to_column(var = 'Variable name') %>% 
    tibble() %>% 
    rename('Variable Importance' = cforest_importance) %>% 
    left_join(
      tab_labs %>% 
        tidylog::select(`Variable name`, Alias, Type, Scale)) %>% 
    arrange(desc('Variable Importance')) -> cforest_importance_to_graph)

cforest_importance_to_graph %>% tail()

## NEED TO INSERT OTHER GRAPHICS


## OLDER
#older classification tree
tic()
binary_with_dins_cols <- rpart(damage_binary ~ .
                               , data = build %>% 
                                 filter(build_DINS==1) %>% 
                                # damage_severity
                                tidylog::select(any_of(table1$upvar))  
                              , method = 'anova'); toc()

plot(binary_with_dins_cols)
summary(binary_with_dins_cols) # 11181  observations
plot(binary_with_dins_cols, branch=0.5); text(binary_with_dins_cols,cex=0.7)

# code from Owen
windows(4.5,4.5)
par(mar=c(1,1,2,1))
binary_with_dins_cols_pruned<-prune(binary_with_dins_cols, cp=0.02)
plot(binary_with_dins_cols_pruned,branch=0.5);text(binary_with_dins_cols_pruned,cex=0.7)
printcp(binary_with_dins_cols_pruned)
print(binary_with_dins_cols_pruned) 

#attempting Owen's code on AUC - from 12/23/2021
library(pROC) #if we keep move up
test$predtree<-predict(binary_with_dins_cols_pruned, OOB = TRUE) #create predicted values
model_data = build %>% filter(build_DINS==1) #filtering to just our data - feel free to condense into code below
auc(roc(model_data$damage_binary,predict(binary_with_dins_cols_pruned,model_data))) #attempt at AUC - using pruned tree  
 
# # this is a classification tree, not sure we need this
# tic()
# binary_without_dins_cols <- rpart(damage_binary ~ ., 
#                                   data = build_a %>% 
#                                     tidylog::select( # dropping columns containing specific DINS data
#                                             # very detailed but sparse (lots of NAs)
#                                       !c(  build_DECKPORCHO
#                                          , build_EAVES
#                                          , build_EXTERIORSI
#                                          , build_FENCEATTAC
#                                          , build_PATIOCOVER
#                                          , build_PROPANETAN
#                                          , build_ROOFCONSTR
#                                          , build_VEGCLEARAN
#                                          , build_VENTSCREEN
#                                          , build_WINDOWPANE    
#                                     ))
#                                   , method = 'anova'); toc()
# 
# plot(binary_without_dins_cols); text(binary_without_dins_cols,cex=0.7)
# summary(binary_without_dins_cols) # 11181  observations
# plot(binary_without_dins_cols, branch=0.5); text(binary_without_dins_cols,cex=0.7)





# severity for just DINS-surveyed buildings, including those more specific columns for damage
tic()
severity_with_dins_cols <- rpart(damage_severity ~ .
                               , data = build %>% 
                                 filter(build_DINS==1) %>% 
                                tidylog::select(damage_severity
                                                , any_of(table1$upvar)
                                                , -damage_binary),
                              , method = 'anova'); toc()

plot(severity_with_dins_cols)
summary(severity_with_dins_cols) # 11181  observations
plot(severity_with_dins_cols, branch=0.5); text(severity_with_dins_cols,cex=0.7)

# code from Owen
windows(4.5,4.5)
par(mar=c(1,1,2,1))
severity_with_dins_cols_pruned<-prune(severity_with_dins_cols,cp=0.02)
plot(severity_with_dins_cols_pruned,branch=0.5);text(severity_with_dins_cols_pruned,cex=0.7)
printcp(severity_with_dins_cols_pruned)
print(severity_with_dins_cols_pruned)

# look at pruned models side by side
print(binary_without_dins_cols_pruned)
print(binary_with_dins_cols_pruned)
print(severity_with_dins_cols_pruned)


summary(binary_without_dins_cols_pruned)
summary(binary_with_dins_cols_pruned)
summary(severity_with_dins_cols_pruned)


# TODO model validation/diagnostics
# TODO selection
# TODO model accuracy


 
#Owen's code OOB accuracy testing
# combdat$predtree<-predict(final3, OOB = TRUE)
# auc(roc(testdat$DAMAGED.x,predict(final2,testdat)))
# auc(roc(moddat$DAMAGED.x,predict(final2,moddat)))
# moddat$pred <- predict(final3, OOB = TRUE)
# moddat$predtrue <- moddat$pred>0.37
# with(moddat,table(DAMAGED.x,predtrue))

#need to divide data into test (25%) and model (75%)
log_build_reg_data$RANDSEL.x<-round(runif(nrow(log_build_reg_data)),2)
testdat<-subset(log_build_reg_data,RANDSEL.x>0.75) #not the same obs every time, and also need to drop randsel?
moddat<-subset(log_build_reg_data,RANDSEL.x<=0.75) #not the same obs every time, and also need to drop randsel?

#can't get the below to work, number of samples wrong
#Bagging with ipred instead? https://uc-r.github.io/regression_trees
log_build_reg_data$predtree<-predict(maximal_rpart, OOB = TRUE) 
log_build_reg_data$predtree<-predict(maximal_rpart, OOB = TRUE)
auc(roc(testdat$DAMAGED.x,predict(final,testdat)))
auc(roc(moddat$DAMAGED.x,predict(final,moddat)))
moddat$pred <- predict(maximal_rpart, OOB = TRUE)
moddat$predtrue <- moddat$pred>0.37
with(moddat,table(DAMAGED.x,predtrue))

# testdat$pred <- predict(final3,testdat, OOB = TRUE)
# testdat$predtrue <- testdat$pred>0.15
# with(testdat,table(DAMAGED.x,predtrue))
 
testdat$pred <- predict(maximal_rpart,testdat, OOB = TRUE)
testdat$predtrue <- testdat$pred>0.15
with(testdat,table(DAMAGED.x,predtrue))




```

#### iii multivariate outcome for just DINS-surveyed
```{r}
#TODO 

```


###OLD Fit Jeffrey Evan's worked example: randomForest
```{r}
# modeled after and adapted from this page
# from https://evansmurphy.wixsite.com/evansspatial/random-forest-sdm

# abbridged from J Evan's second chunk (chunk 1 accesses data)
# library(randomForest)
# library(rfUtilities)

b <- 1001                                     # Number of Bootstrap replicates
# snip
# chunks 3 and 4 import raster dadta and extract variables from raster to absence/present point locations
# snip

log_build_reg_data

log_build_reg_data %>% tabyl(damage_binary)

# remove build_has_tree_overhang?
log_build_reg_data %<>% mutate(damage_binary = as.factor(damage_binary)) %>% data.frame()# PAY ATTENTION HERE
log_build_reg_data %>% glimpse

rf_collinearity_test <- log_build_reg_data %>% 
  tidylog::select(where(is.double))

(cl <- multi.collinear(rf_collinearity_test[,2:ncol(rf_collinearity_test)], p = 0.05))

# tell us what's got to go!
for(l in cl) {
  cl.test <- rf_collinearity_test[,-which(names(rf_collinearity_test)==l)]
  print(paste("Remove variable", l, sep=": "))
  multi.collinear(cl.test, p=0.05)
}


log_build_reg_data_cl <- log_build_reg_data[,-which(names(log_build_reg_data) %in% cl )] 
# %>% # should not be needed any more
#   data.frame() %>%
#   mutate_if(is.character, as.factor)

# Chunk 8 makes depenent variable categorical (done). BUT it also checks for frequency of presense

# "We observe that the sample balance of presence locations is 33% thus, meeting the 1/3 rule for sample balance."

log_build_reg_data_cl %>% tabyl(damage_binary)
print('12% - is this a problem?!?!')

# model selection
# ( rf.model <- rf.modelSel(x=sdata@data[,3:ncol(sdata@data)], y=sdata@data[,"Present"], imp.scale="mir", ntree=b) )

tic() # clock in
(rf.model <- rf.modelSel(x=log_build_reg_data_cl[,2:ncol(log_build_reg_data_cl)],
                         y=log_build_reg_data_cl[,"damage_binary"],
                         imp.scale="mir", ntree=b))
toc() # clock out, about 3 minutes
beepr::beep()


sel.vars <- rf.model$selvars

# OR, pick a model?
#sel.vars <- rf.model$parameters[[4]] # DECISION POINT

# run a model
tic() # clock in
(rf.fit <- randomForest(y=log_build_reg_data_cl[,"damage_binary"],
                        x=log_build_reg_data_cl[,sel.vars],
                        ntree=b,
                        importance=TRUE, norm.votes=TRUE, proximity=TRUE) )
toc() # clock out, about 3 minutes
beepr::beep()

  
  # run a model with ALL PREDICTORS
  tic() # clock in
  ( rf.fit_all <- randomForest(y=log_build_reg_data_cl[,"damage_binary"],
                               x=log_build_reg_data_cl[,2:ncol(log_build_reg_data_cl)],
                           ntree=b,
                           importance=TRUE, norm.votes=TRUE, proximity=TRUE) )
  toc() # clock out, about 4 minutes
  beepr::beep()


tic() # clock in
( imbal <- randomForestSRC::imbalanced(damage_binary~., data=log_build_reg_data_cl) )
toc() # clock out, about 3 minutes
beepr::beep()

# skipping chunks 13 and 14: predicted raster map.. doesn't really apply here.

# model fit!
rf.pred <- predict(rf.fit, log_build_reg_data_cl[,sel.vars], type="response")

rf.prob <- as.data.frame(predict(rf.fit, log_build_reg_data_cl[,sel.vars], type="prob"))

obs.pred <- data.frame(cbind(Observed=as.numeric(as.character(log_build_reg_data_cl[,"damage_binary"])),
                             PRED=as.numeric(as.character(rf.pred)), Prob1=rf.prob[,2],
                             Prob0=rf.prob[,1]) )

op <- (obs.pred$Observed == obs.pred$PRED)



( pcc <- (length(op[op == "TRUE"]) / length(op))*100 )



# library(verification)

roc.plot(obs.pred[,"Observed"], obs.pred[,"Prob1"])


# model validation
tic() # clock in
( rf.perm <- rf.significance(rf.fit, log_build_reg_data_cl[,sel.vars], nperm = 99, ntree = 1001) )
toc() # clock out, 59 minutes with 99 permutations
beepr::beep()

# saveRDS(rf.perm, file = paste0("saved_sessions/rf.perm",
#                                gsub('[[:punct:]]', '-', Sys.time()), '.rds'))

# cross validation
tic() # clock in
( rf.cv <- rf.crossValidation(rf.fit, log_build_reg_data_cl[,sel.vars], p=0.10, n=99, ntree=1001) )
toc() # clock out, about 143 minutes (2.38 hours) with 999 permutations
beepr::beep()

# so this model isn't very good

saveRDS(rf.perm, file = paste0("saved_sessions/rf.perm",
                               gsub('[[:punct:]]', '-', Sys.time()), '.rds'))


# so the number of trees is probably over kill at 1000? 75 sufficient?
plot(rf.fit, main="Bootstrap Error Convergence")


# variable importance
p <- as.matrix(rf.fit$importance[,3])   
ord <- rev(order(p[,1], decreasing=TRUE)[1:dim(p)[1]]) 


png(file = paste0(getwd(), '/figures/var_imp_', gsub('[[:punct:]]', '_', Sys.time()), '.png'))
dotchart(p[ord,1], main="Scaled Variable Importance", pch=19)  
dev.off()


p <- as.matrix(rf.fit_all$importance[,3])   
ord <- rev(order(p[,1], decreasing=TRUE)[1:dim(p)[1]]) 


png(file = paste0(getwd(), '/figures/var_imp_all_', gsub('[[:punct:]]', '_', Sys.time()), '.png'))
dotchart(p[ord,1], main="Scaled Variable Importance", pch=19)  
dev.off()

(all_vars <- names(log_build_reg_data_cl))

#TODO: PDP don't like categorical predictors.. 
# all_vars <-  all_vars[c(1:9, 11:35)]


`%nin%` <- Negate(`%in%`) # custom function
# 
# # drop the binary
# (all_vars <- all_vars[all_vars %nin% 'build_has_tree_overhang'])

tic()
par(mfrow=c(1,1))
for(i in all_vars[2:length(all_vars)]) {
  print(i)
  png(file = paste0(getwd(), '/figures/', i, '_pdp',
                  gsub('[[:punct:]]', '_', Sys.time()), '.png'))
  rf.partial.prob(rf.fit_all, log_build_reg_data_cl[,all_vars], i, "1", smooth="spline", raw.line=FALSE)
  dev.off()
}; toc()  



# par(mfrow=c(2,2))
# for(i in sel.vars[1:4]) {
#   rf.partial.prob(rf.fit, build_rforest_cat[,sel.vars], i, "1", smooth="spline", raw.line=FALSE)
# }  

tic()
for(i in sel.vars) {
png(file = paste0(getwd(), '/figures/', i, '_pdp_',
                  gsub('[[:punct:]]', '_', Sys.time()), '.png'))
rf.partial.prob(rf.fit,
                log_build_reg_data_cl[,sel.vars], i, "1", smooth="spline", raw.line=FALSE)
dev.off()
  }; toc() 
beep()
```







#### i random forest readings

Thanks Sebastian Martinuzzi

https://evansmurphy.wixsite.com/evansspatial/random-forest-sdm

https://cran.r-project.org/web/packages/rfUtilities/index.html
(Utilities for Random Forest model selection, class balance correction, significance test, cross validation and partial dependency plots.)

https://www.rdocumentation.org/packages/randomForestSRC/versions/2.9.3/topics/imbalanced.rfsrc
(Imbalanced Two Class Problems)

Old, but important
https://statistics.berkeley.edu/sites/default/files/tech-reports/666.pdf

A review paper on "A survey on addressing high-class imbalance in big data"
https://link.springer.com/article/10.1186/s40537-018-0151-6

https://towardsdatascience.com/random-forest-in-r-f66adf80ec9

http://www.sthda.com/english/articles/36-classification-methods-essentials/150-stepwise-logistic-regression-essentials-in-r/#:~:text=The%20stepwise%20logistic%20regression%20can,ref(stepwise%2Dregression))

https://compstat-lmu.github.io/iml_methods_limitations/pdp.html

https://www.blopig.com/blog/2017/04/a-very-basic-introduction-to-random-forests-using-r/





### OLD A a little prep
```{r}
# TODO handle the NA's better than dropping 11%
# a) manual fill, b) impute - see if it matters in the model
# see if year built is even a good predictor

# minor prep for binary 
build_bin <- build %>% 
  st_drop_geometry() %>% 
  select(damage_binary, build_Mean_elev_30m : build_Mean_distall_road,
         build_NEAR_DIST, build_NEAR_ANGLE,
         build_dist_to_build_ft : build_p_shrub_300,
         parcel_UseType: parcel_Imperv_P,
         parcel_year_built) %>% 
  filter(parcel_year_built > 0) %>% 
  drop_na() %>% 
  data.frame #%>% glimpse

# check for NA
map(build_bin, ~sum(is.na(.))) # check for NA's

build_bin %>% filter(parcel_year_built == 0) %>% dim()

```




### OLD data prep/max model
```{r}
# maximal set of predictors after winnowing down among potentially redundant vars
#Dexter see note below, I don't think we need this section to come up with a maximal model for regression. 
log_build_reg_data <- build %>%
  tidylog::select(damage_binary
                  , build_Mean_elev_30m
                  ,  build_Mean_aspect_100m_DEM
                  ,  build_Mean_slope_100m_DEM
                  ,  build_Mean_aspect_100m_DEM 
                  ,  build_Mean_distroad
                  ,  build_Mean_builddens 
                  ,  build_Mean_distall_road 
                  ,  build_min_dist_tree
                  ,  build_min_dist_shrub 
                  
                  , build_has_tree_overhang
                  , build_overhang_ht
                  , build_perc_overhang
                
                  # , build_dist_angle
                   , build_near_build
                  # , build_dist_to_build_ft 
                  , build_near_dest
                  
                  , build_p_tree_100
                  , build_p_grass_300 
                  , build_p_soil_200 
                  , build_p_water_100 
                  , build_p_building_300 
                  , build_p_road_300
                  , build_p_otherpaved_300
                  , build_p_shrub_300
                    
                  , build_area
                  , parcel_UseType
                    # parcel_UseDescription, # colinear with above?
                    # parcel_Roll_ImpValue, # colinear with below?
                  , parcel_Roll_HomeOwnersExemp
                  , parcel_Can_P
                  , parcel_Grass_P
                  , parcel_Soil_P 
                  , parcel_Water_P
                  , parcel_Build_P
                  , parcel_Road_P
                  , parcel_Paved_P
                  , parcel_Shrub_P
                  , parcel_Perv_P
                  , parcel_Imperv_P
                  , parcel_recent # Dexter, fixed this to be parcel_recent
                  , parcel_area,
                  build_EXTERIORSI,build_FENCEATTAC,build_DECKPORCHO,build_DECKPORCHE,build_ROOFCONSTR,build_PATIOCOVER,
                  build_PROPANETAN,build_WINDOWPANE,build_VEGCLEARAN,build_EAVES,build_VENTSCREEN,build_DINS
                  )  

# Miranda do you remember why we have two versions of build?
#Dexter, it was because one of them included land cover data. And bc we were going to do a  big maximal model. I don't think we are anymore - just univariates and Random Forest so should we delete this whole section?
log_build_reg_data_lc <- build %>% #some of these variable names need to be cleaned up if we retain this subset of vars/data
  tidylog::select(damage_binary
                  , build_Mean_elev_30m
                  ,  build_Mean_aspect_100m_DEM
                  ,  build_Mean_slope_100m_DEM
                  ,  build_Mean_aspect_100m_DEM 
                  ,  build_Mean_distroad
                  ,  build_Mean_builddens 
                  ,  build_Mean_distall_road 
                  ,  build_min_dist_tree
                  ,  build_min_dist_shrub 
                  
                  , build_has_tree_overhang
                  , build_overhang_ht
                  , build_perc_overhang
                
                  # , build_dist_angle
                  # , build_dist_to_burned_build_ft
                  , build_near_build
                  , build_near_dest
                  
                  # , build_p_tree_100
                  , build_p_grass_300 
                  # , build_p_soil_200 
                  # , build_p_water_100 
                  , build_p_building_300 
                  # , build_p_road_300
                  # , build_p_otherpaved_300
                  # , build_p_shrub_300
                    
                  , build_area
                  
                  , parcel_UseType
                    # parcel_UseDescription, # colinear with above?
                    # parcel_Roll_ImpValue, # colinear with below?
                  , parcel_Roll_HomeOwnersExemp
                  , parcel_Can_P
                  , parcel_Grass_P
                  , parcel_Soil_P 
                  , parcel_Water_P
                  , parcel_Build_P
                  , parcel_Road_P
                  , parcel_Paved_P
                  , parcel_Shrub_P
                  , parcel_Perv_P
                  , parcel_Imperv_P
                  , parcel_year_built
                  , parcel_area) %>% 
  mutate_if(is.character, as.factor)  # random forest doesn't like characters
  #drop_na() #party is ok with NAs


log_maximal_lc <- glm(damage_binary ~ ., family = binomial, data = log_build_reg_data_lc)

# FIXME examine warning error
tic();log_step_lc <- log_build_reg_data_lc %>% MASS::stepAIC(trace = FALSE); toc() # ~1.5 mins

```



### OLD fits for maximal models examine fits
```{r}
# Null model
log_null <- glm(damage_binary ~ 1, family = binomial, data = log_build_reg_data)

# maximal model 
log_maximal <- glm(damage_binary ~ ., family = binomial, data = log_build_reg_data)
log_maximal %>% check_collinearity()
# step-wise
tic();log_step <- log_maximal %>% MASS::stepAIC(trace = FALSE); toc() # ~1.5 mins

# store chosen terms from stepwise regression
(log_step %>% 
    tidy() %>% 
    filter(term != '(Intercept)') %>% 
    pull(term) -> vars_in_log_step)

summary(log_step)performance::compare_performance(log_null, log_maximal, log_step, rank = TRUE) # chooses stepwise

modEvA::Dsquared(log_maximal)
modEvA::Dsquared(log_step)

# find out limts of odds ratios, to inform graph settings
round(sort(exp(coef(log_step))), 2) %T>% print() %>% range() # 0 to ~1.6

# tab_model(log_maximal, show.std = FALSE)
plot_model(log_step, type = "std", vline.color = 'black', sort.est = TRUE) + 
  ylim(0, 1.65) + theme_bw()

# ggsave(file = paste0(getwd(), '/figures/stepwise_logistic_reg_coefs_',
#                      gsub('[[:punct:]]', '_', Sys.time()), '.png'))

tab_model(log_step
          # , file = paste0(getwd(), '/output_data/stepwise_logistic_reg_coefs_',
          #               gsub('[[:punct:]]', '_', Sys.time()), '.html')
          ); warnings()


# is that regression model any good?
performance::check_model(log_step) # saving isn't so easy

```


http://www.sthda.com/english/articles/36-classification-methods-essentials/151-logistic-regression-essentials-in-r/

### OLD assess missingness and stepwise model
```{r}

# of the variables that made it through the stepwise procedure, which had missing vals?
(
  build %>%
    map(., ~sum(is.na(.))) %>%
    map_dfc(., ~.x) %>% 
    t() %>%
    data.frame() %>%
    rownames_to_column(var = 'var') %>% 
    rename(num_missing = '.') %>% 
    arrange(desc(num_missing)) %>%
    filter(var %in% vars_in_log_step) %>% 
    filter(num_missing > 0) -> missing_data_vars
)

# These are the ones to think about
#                  var num_missing
#1       parcel_year_built        1008 #this is important in RF; impute about median.
#2     build_Mean_distroad          88 #this is important in RF; impute the median. #TODO - Dexter I think we should just drop these, seems weirder to impute a median here.
#3       build_overhang_ht          47 #not important in maximal RF model
#4     build_perc_overhang          47 #not important in maximal RF model
#5 build_Mean_distall_road          12 #not important in maximal RF model 
```



### OLD impute missing values AND drop the variables previously determined to be low-importance
```{r}
build %>% 
  mutate_all(~ifelse(is.na(.), median(., na.rm = TRUE), .)) %>% 
  tidylog::select(-build_overhang_ht, -build_perc_overhang, -build_Mean_distall_road)
  
```




### OLD G fit models with consistent distance (300)
```{r}

# maximimal set of predictors after winnowing down among potentially redundant vars
log_build_reg_data_consitent_dists <- build %>%
  tidylog::select(damage_binary
                  , build_Mean_elev_30m
                  ,  build_Mean_aspect_30m_DEM
                  ,  build_Mean_slope_30m_DEM
                  ,  build_Mean_aspect_30m_DEM 
                  ,  build_Mean_distroad
                  ,  build_Mean_builddens 
                  ,  build_Mean_distall_road 
                  ,  build_min_dist_tree
                  ,  build_min_dist_shrub 
                  , near_dest
                  , build_has_tree_overhang
                  , build_overhang_ht
                  , build_perc_overhang
                  
                  , build_dist_angle
                  , build_near_build
                  
                  , build_p_tree_300 
                  , build_p_grass_300 
                #  , build_p_soil_300 
                  , build_p_water_300 
                  , build_p_building_300 
                  , build_p_road_300
                  , build_p_otherpaved_300
                  , build_p_shrub_300
                    
                  , build_area
                  
                  , parcel_UseType
                    # parcel_UseDescription, # colinear with above?
                    # parcel_Roll_ImpValue, # colinear with below?
                  , parcel_Roll_HomeOwnersExemp
                 # , parcel_Can_P
                #  , parcel_Grass_P
                #  , parcel_Soil_P 
                #  , parcel_Water_P
                #  , parcel_Build_P
                #  , parcel_Road_P
                #  , parcel_Paved_P
                #  , parcel_Shrub_P
                #  , parcel_Perv_P
                #  , parcel_Imperv_P
                  , parcel_year_built
                  , parcel_area) %>% 
  mutate_if(is.character, as.factor) %>% # random forest doesn't like characters
  drop_na()


# _cd for consistent distance
log_maximal_cd <- glm(damage_binary ~ ., family = binomial, data = log_build_reg_data_consitent_dists)
log_maximal_cd %>% check_collinearity()

# step-wise
tic();log_step_cd <- log_maximal_cd %>% MASS::stepAIC(trace = FALSE); toc() # ~1.5 mins
log_step_cd %>% check_collinearity()

# store chosen terms from stepwise regression
(log_step_cd %>% 
    tidy() %>% 
    filter(term != '(Intercept)') %>% 
    pull(term) -> vars_in_log_step)

log_step_cd %>% tab_model
log_step_cd %>% plot_model(., sort.est = TRUE, vline.color = 'black') + 
  ylim(0, 1.65) + theme_bw()

```
### OLD H purposeful models
```{r}

# purposeful models of predictors ; we have a working set of 'non-correlated' variables, create 'intentional' sets of models - 
# Parcel/building level - what individual can control or potentially change (trees overhead, veg on parcel, veg in 10 ft)
# Model ideas 1  - structure age, slope, aspect, elevation; vegetation on roof; vegetation within 10 ft

m1<-glm(damage_binary ~ near_dest+parcel_year_built+build_Mean_slope_30m_DEM+build_Mean_aspect_30m_DEM+build_Mean_elev_30m+build_perc_overhang+build_p_grass_10+build_p_tree_10+build_p_soil_10, family = binomial, data = build)

summary(m1)
m1 %>% tab_model
m1 %>% plot_model(., sort.est = TRUE, vline.color = 'black') + 
  ylim(0, 1.65) + theme_bw()

# Model ideas 2 - structure age, slope, aspect, elevation; vegetation on roof; vegetation within 300 ft (if that distance seems best?)
m2<-glm(damage_binary ~ near_dest+parcel_year_built+build_Mean_slope_30m_DEM+build_Mean_aspect_30m_DEM+build_Mean_elev_30m+build_perc_overhang+build_p_grass_300+build_p_tree_300+build_p_soil_300, family = binomial, data = build)

summary(m2)
m2 %>% tab_model
m2 %>% plot_model(., sort.est = TRUE, vline.color = 'black') + 
  ylim(0, 1.65) + theme_bw()


# Model ideas 3 (just change out veg for parcel) - structure age, slope, aspect, elevation; vegetation on roof; vegetation on parcel
m3<-glm(damage_binary ~ near_dest+parcel_year_built+build_Mean_slope_30m_DEM+build_Mean_aspect_30m_DEM+build_Mean_elev_30m+build_perc_overhang+parcel_Grass_P+parcel_Can_P+parcel_Soil_P, family = binomial, data = build)

summary(m3)
m3 %>% tab_model
m3 %>% plot_model(., sort.est = TRUE, vline.color = 'black') + 
  ylim(0, 1.65) + theme_bw()

AIC(m1,m2,m3) #compare m1,m2,m3 

# Landscape level - what determines fire spread/describes world around you (roads, building density, slope aspect etc)
# Take the parcel/building level model 1, 2, or 3, and add the variables for roads, building density; 
  # TO DO should have ?Structuredensity*Structure age interaction?
  # TO DO which road measure?  
names(build)
m4<-glm(damage_binary ~ parcel_year_built+build_Mean_slope_30m_DEM+build_Mean_aspect_30m_DEM+build_Mean_elev_30m+build_perc_overhang+
          build_p_grass_300+build_p_tree_300+build_p_soil_300+build_Mean_distroad+build_Mean_builddens, family = binomial, data = build)

AIC(m2,m4) #TO DO what's going on w number of observations here? where are missing values?
m4 %>% tab_model
tab_model(m2,m4)
m4 %>% plot_model(., sort.est = TRUE, vline.color = 'black') + 
  ylim(0, 1.65) + theme_bw() 

```


```{r, citations}
lapply(packages, citation)
```


Last knit on `r format(Sys.time())`


```{r}
system.time(save.image(file = paste0('saved_sessions/wui_r_models_', gsub('[[:punct:]]', '-', Sys.time()), '.RData')))
```

